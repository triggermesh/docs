{"config":{"lang":["en"],"separator":"[\\s\\-]+"},"docs":[{"title":"TriggerMesh documentation","text":"<p>TriggerMesh is free open-source software that lets you easily build event-driven applications.</p>  <ul> <li> <p> Your first events in 5 minutes</p>  <p>Install the TriggerMesh command line interface <code>tmctl</code> and get up and running in minutes on a standard laptop.</p> <p> Getting started</p> </li> <li> <p> Deploy natively on Kubernetes</p>  <p>TriggerMesh runs natively on Kubernetes with its <code>custom resource definitions</code> and controllers.</p> <p> K8s install</p> </li> <li> <p> What is TriggerMesh</p>  <p>Learn why TriggerMesh is part of a new generation of EDA solutions native to the cloud and built for developers.</p> <p> Concepts</p> </li> <li> <p> Open Source, Apache 2.0</p>  <p>TriggerMesh  open source. Issues, pull requests, and thoughtful discussion are always welcome.</p> <p> GitHub</p> </li> </ul>","location":""},{"title":"Brokers and Triggers","text":"","location":"brokers/"},{"title":"What are Brokers?","text":"<p>TriggerMesh provides components called Brokers that act as intermediaries that route events from event producers to consumers. Brokers are responsible for guaranteeing that events are delivered to their destinations, and enable the publish-subscribe model in which multiple consumers can be notified of the same events.</p> <p>Different Broker types will provide different guarantees and tradeoffs:</p> <ul> <li><code>Memory Broker</code> uses ephemeral memory to store events, and is best used for development and non-mission-critical use cases where event loss is acceptable in the case of crashes or restarts</li> <li><code>Redis Broker</code> uses a backing Redis instance to store events, thereby providing durability that is suitable for production uses cases where event loss in not acceptable during crashes or restarts</li> </ul>","location":"brokers/#what-are-brokers"},{"title":"What are Triggers?","text":"<p>The TriggerMesh Brokers run Triggers which listen for events, and evaluate them against the Trigger's filters, and if they match deliver the events to their defined targets.</p>","location":"brokers/#what-are-triggers"},{"title":"Handling failed delivery of events","text":"<p>The Broker is the component responsible for guaranteeing delivery of events, and provides what is commonly referred to as at-least-once delivery guarantees. Read more about at-least-once in the dedicated guide.</p> <p>This guide talks about the configuration options available on Triggers that let you define how the system should behave in the case of failed delivery.</p> <p>You can configure how events are delivered for each Trigger by adding a <code>delivery</code> spec to the <code>Trigger</code> object, as shown at the end of the following example:</p> <pre><code>apiVersion: eventing.triggermesh.io/v1alpha1\nkind: Trigger\nmetadata:\n  name: mytrigger\nspec:\n  broker:\n      group: eventing.triggermesh.io\n      kind: RedisBroker\n      name: mybroker\n  filters:\n      - exact:\n          type: mytype1\n  target:\n      ref:\n          apiVersion: targets.triggermesh.io/v1alpha1\n          kind: cloudeventstarget\n          name: cloudeventstarget\n  delivery:\n    retry: 5\n    backoffDelay: PT5S\n    backoffPolicy: constant\n    deadLetterSink:\n      uri: https://mycompany.com/deadletter\n</code></pre> <p>Where</p> <ul> <li><code>retry</code> specifies the number of times that event delivery is retried before the event is sent to the dead letter sink.</li> <li>The <code>backoffDelay</code> delivery parameter specifies the time delay before an event delivery retry is attempted after a failure. The duration of the <code>backoffDelay</code> parameter is specified using the ISO 8601 duration format. For example, <code>PT1S</code> specifies a 1 second delay.</li> <li>The <code>backoffPolicy</code> delivery parameter can be used to specify the retry back off policy. The policy can be specified as either <code>linear</code> or <code>exponential</code>. When using the <code>linear</code> back off policy, the back off delay is the time interval specified between retries. When using the <code>exponential</code> back off policy, the back off delay is equal to <code>backoffDelay*2^&lt;numberOfRetries&gt;</code>.</li> <li>The <code>deadLetterSink</code> spec contains configuration settings to enable using a dead letter sink. This tells the Subscription what happens to events that cannot be delivered to the subscriber. When this is configured, events that fail to be delivered are sent to the dead letter sink destination. The destination can be a reference to any TriggerMesh target, meaning anything could potentially be used to store dead lettered events. The destatination can also be URI. In the example above a URI is used.</li> </ul>","location":"brokers/eventdelivery/"},{"title":"Memory Broker","text":"<p>Memory Broker is the simplest Broker implementation provided by TriggerMesh and is used by default by <code>tmctl</code>. The Redis Broker provides event durability and is used by default with TriggerMesh on Kubernetes.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create broker &lt;broker name&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: eventing.triggermesh.io/v1alpha1\nkind: MemoryBroker\nmetadata:\n  name: &lt;broker instance name&gt;\nspec:\n  memory:\n    bufferSize: &lt;maximum number of events&gt;\n  broker:\n    port: &lt;HTTP port for ingesting events&gt;\n    observability:\n      valueFromConfigMap: &lt;kubernetes ConfigMap that contains observability configuration&gt;\n</code></pre> <p>The only <code>MemoryBroker</code> specific parameter is <code>spec.memory.bufferSize</code> which indicates the available size of the internal queue that the broker manages. When the maximum number of items is reached, new ingest requests will block and might eventually time out. This parameter is optional and defaults to 10000.</p> <p>The <code>spec.broker</code> section contains generic Broker parameters:</p> <ul> <li><code>spec.broker.port</code> that the Broker service will be listening at. Optional, defaults to port 80.</li> <li><code>spec.broker.observability</code> can be set to the name of a ConfigMap at the same namespace that contains observability settings (documentation coming soon). This parameter is optional.</li> </ul>","location":"brokers/memorybroker/"},{"title":"Getting Started guide with the Memory Broker on Kubernetes","text":"<p>In this introduction tutorial we are going to setup a MemoryBroker with a Trigger that sends events to a Target endpoint, and if the delivery faisl to a Dead Letter Sink endpoint.</p>","location":"brokers/memorybroker/#getting-started-guide-with-the-memory-broker-on-kubernetes"},{"title":"Instructions","text":"<p>This guide uses 2 TriggerMesh components:</p> <ul> <li>MemoryBroker, which uses ephemeral memory to store events and routes them via Triggers.</li> <li>Trigger, which subscribes to events and push them to your targets.</li> </ul> <p>Events must conform to CloudEvents spec using the HTTP binding.</p> <p>Create a MemoryBroker named <code>demo</code>.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-memory/broker.yaml\n</code></pre> <p>Wait until the MemoryBroker is ready. It will inform in its status of the URL where events can be ingested.</p> <pre><code>kubectl get memorybroker demo\n\nNAME   URL                                                        AGE   READY   REASON\ndemo   http://demo-mb-broker.default.svc.cluster.local   10s   True\n</code></pre> <p>To be able to use the broker we will create a Pod that allow us to send events inside the Kubernetes cluster.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre> <p>It is possible now to send events to the broker address by issuing curl commands. The response for ingested events must be an <code>HTTP 200</code> which means that the broker has received it and will try to deliver them to configured triggers.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-mb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test1\":\"no trigger configured yet\"}'\n</code></pre> <p>Unfortunately we haven't configured any trigger yet, which means any ingested event will not be delivered. <code>event_display</code> is a CloudEvents consumer that logs to console the list of events received. We will be creating 2 instances of <code>event_display</code>, one as the target for consumed events and another one for the Dead Letter Sink. A Dead Letter Sink, abbreviated DLS is a destination that consumes events that a subscription was not able to deliver to the intended target.</p> <pre><code># Target service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml\n\n# DLS service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-deadlettersink.yaml\n</code></pre> <p>The Trigger object configures the broker to consume events and send them to a target. The Trigger object can include filters that select which events should be forwarded to the target, and delivery options to configure retries and fallback targets when the event cannot be delivered.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-memory/trigger.yaml\n</code></pre> <p>The Trigger created above filters by CloudEvents containing <code>type: demo.type1</code> attribute and delivers them to <code>display-target</code> service, if delivery fails it will issue 3 retries and then forward the CloudEvent to the <code>display-deadlettersink</code> service.</p> <p>Using the <code>curl</code> Pod again we can send this CloudEvent to the broker.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-mb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test 2\":\"message for display target\"}'\n</code></pre> <p>The target display Pod will show the delivered event.</p> <pre><code>kubectl logs -l app=display-target --tail 100\n\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: demo.type1\n  source: curl\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  triggermeshbackendid: 1666613846441-0\nData,\n  {\n    \"test\": \"value2\"\n  }\n</code></pre> <p>To simulate a target failure we will reconfigure the target display service to make it point to a non existing Pod set:</p> <pre><code>kubectl delete -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml\n</code></pre> <p>Any event that pass the filter will try to be sent to the target, and upon failing will be delivered to the DLS.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-mb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test 3\":\"not delivered, will be sent to DLS\"}'\n</code></pre> <pre><code>kubectl logs -l app=display-deadlettersink --tail 100\n\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: demo.type1\n  source: curl\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  triggermeshbackendid: 1666613846441-0\nData,\n  {\n    \"test\": \"value3\"\n  }\n</code></pre>","location":"brokers/memorybroker/#instructions"},{"title":"Clean Up","text":"<p>To clean up the getting started guide, delete each of the created assets:</p> <pre><code># Removal of display-target not in this list, since it was deleted previously.\nkubectl delete -f \\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-memory/trigger.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-deadlettersink.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-memory/broker.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre>","location":"brokers/memorybroker/#clean-up"},{"title":"Redis Broker","text":"<p>The Redis Broker uses a backing Redis instance to store events, thereby providing durability that is suitable for production uses cases where event loss in not acceptable during crashes or restarts.</p> <p>The management of the Redis instance is greatly simplified by TriggerMesh. It is also possible to point the Broker to any Redis instance, such as a managed instance from a cloud provider.  </p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>. By default, Brokers created with <code>tmctl</code> are Memory Brokers. However, when you export your configuration to Kubernetes manifests using <code>tmctl dump</code>, TriggerMesh will export a <code>Redis Broker</code>, thereby providing message durability by default. You can switch to a Memory Broker if you prefer by updating the exported manifest.</p> <p>TriggerMesh will add support for Redis Broker in <code>tmctl</code> in the future.  </p>  <p>On Kubernetes:</p> <pre><code>apiVersion: eventing.triggermesh.io/v1alpha1\nkind: RedisBroker\nmetadata:\n  name: &lt;broker instance name&gt;\nspec:\n  redis:\n    connection: &lt;Provides a connection to an external Redis instance. Optional&gt;\n        url: &lt;redis URL. Required&gt;\n        username: &lt;redis username, referenced using a Kubernetes secret&gt;\n          secretKeyRef:\n            name: &lt;Kubernetes secret name&gt;\n            key: &lt;Kubernetes secret key&gt;\n        password: &lt;redis password, referenced using a Kubernetes secret&gt;\n          secretKeyRef:\n            name: &lt;Kubernetes secret name&gt;\n            key: &lt;Kubernetes secret key&gt;\n        tlsEnabled: &lt;boolean that indicates if the Redis server is TLS protected. Optional, defaults to false&gt;\n        tlsSkipVerify: &lt;boolean that skips verifying TLS certificates. Optional, defaults to false&gt;\n    stream: &lt;Redis stream name. Optional, defaults to a combination of namespace and broker name&gt;\n    streamMaxLen: &lt;maximum number of items the Redis stream can host. Optional, defaults to unlimited&gt;\n  broker:\n    port: &lt;HTTP port for ingesting events&gt;\n    observability:\n      valueFromConfigMap: &lt;kubernetes ConfigMap that contains observability configuration&gt;\n</code></pre> <p>The only <code>RedisBroker</code> specific parameters are:</p> <ul> <li><code>spec.redis.connection</code>. When not used the broker will spin up a managed Redis Deployment. However for production scenarios that require HA and hardened security it is recommended to provide the connection to a user managed Redis instance.</li> <li><code>spec.stream</code> is the Redis stream name to be used by the broker. If it doesn't exists the Broker will create it.</li> <li><code>spec.streamMaxLen</code> is the maximum number of elements that the stream will contain.</li> </ul> <p>The <code>spec.broker</code> section contains generic Broker parameters:</p> <ul> <li><code>spec.broker.port</code> that the Broker service will be listening at. Optional, defaults to port 80.</li> <li><code>spec.broker.observability</code> can be set to the name of a ConfigMap at the same namespace that contains observability settings (documentation coming soon). This parameter is optional.</li> </ul>","location":"brokers/redisbroker/"},{"title":"Getting Started with the Redis Broker on Kubernetes","text":"<p>In this introduction tutorial we are going to setup a RedisBroker with a Trigger that sends events to a Target endpoint, and if the delivery faisl to a Dead Letter Sink endpoint.</p>","location":"brokers/redisbroker/#getting-started-with-the-redis-broker-on-kubernetes"},{"title":"Instructions","text":"<p>TriggerMesh Core includes 2 components:</p> <ul> <li>RedisBroker, which uses a backing Redis instance to store events and routes them via Triggers.</li> <li>Trigger, which subscribes to events and push them to your targets.</li> </ul> <p>Events must conform to CloudEvents spec using the HTTP binding.</p> <p>Create a RedisBroker named <code>demo</code>.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-redis/broker.yaml\n</code></pre> <p>Wait until the RedisBroker is ready. It will inform in its status of the URL where events can be ingested.</p> <pre><code>kubectl get redisbroker demo\n\nNAME   URL                                                        AGE   READY   REASON\ndemo   http://demo-rb-broker.default.svc.cluster.local   10s   True\n</code></pre> <p>To be able to use the broker we will create a Pod that allow us to send events inside the Kubernetes cluster.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre> <p>It is possible now to send events to the broker address by issuing curl commands. The response for ingested events must be an <code>HTTP 200</code> which means that the broker has received it and will try to deliver them to configured triggers.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-rb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test1\":\"no trigger configured yet\"}'\n</code></pre> <p>Unfortunately we haven't configured any trigger yet, which means any ingested event will not be delivered. <code>event_display</code> is a CloudEvents consumer that logs to console the list of events received. We will be creating 2 instances of <code>event_display</code>, one as the target for consumed events and another one for the Dead Letter Sink. A Dead Letter Sink, abbreviated DLS is a destination that consumes events that a subscription was not able to deliver to the intended target.</p> <pre><code># Target service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml\n\n# DLS service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-deadlettersink.yaml\n</code></pre> <p>The Trigger object configures the broker to consume events and send them to a target. The Trigger object can include filters that select which events should be forwarded to the target, and delivery options to configure retries and fallback targets when the event cannot be delivered.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-redis/trigger.yaml\n</code></pre> <p>The Trigger created above filters by CloudEvents containing <code>type: demo.type1</code> attribute and delivers them to <code>display-target</code> service, if delivery fails it will issue 3 retries and then forward the CloudEvent to the <code>display-deadlettersink</code> service.</p> <p>Using the <code>curl</code> Pod again we can send this CloudEvent to the broker.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-rb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test 2\":\"message for display target\"}'\n</code></pre> <p>The target display Pod will show the delivered event.</p> <pre><code>kubectl logs -l app=display-target --tail 100\n\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: demo.type1\n  source: curl\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  triggermeshbackendid: 1666613846441-0\nData,\n  {\n    \"test\": \"value2\"\n  }\n</code></pre> <p>To simulate a target failure we will reconfigure the target display service to make it point to a non existing Pod set:</p> <pre><code>kubectl delete -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml\n</code></pre> <p>Any event that pass the filter will try to be sent to the target, and upon failing will be delivered to the DLS.</p> <pre><code>kubectl exec -ti curl -- curl -v http://demo-rb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.type1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test 3\":\"not delivered, will be sent to DLS\"}'\n</code></pre> <pre><code>kubectl logs -l app=display-deadlettersink --tail 100\n\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: demo.type1\n  source: curl\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  triggermeshbackendid: 1666613846441-0\nData,\n  {\n    \"test\": \"value3\"\n  }\n</code></pre>","location":"brokers/redisbroker/#instructions"},{"title":"Clean Up","text":"<p>To clean up the getting started guide, delete each of the created assets:</p> <pre><code># Removal of display-target not in this list, since it was deleted previously.\nkubectl delete -f \\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-redis/trigger.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-deadlettersink.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/getting-started-redis/broker.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre>","location":"brokers/redisbroker/#clean-up"},{"title":"Trigger filters","text":"<p>Events flowing through a Broker can be filtered before being sent to targets by means of Trigger filters. TriggerMesh filters are based on the CloudEvents Subscriptions API filters, which allow for fairly complex filtering against event metadata, known as CloudEvent context attributes. Filters are not supported for the event payload (i.e. the <code>data</code> attribute of an event). Content-based filtering of entire payload will be added in the future.</p> <p>As described below, TriggerMesh on Kubernetes provides full control over Trigger filters through its Kubernetes CRD. On the other hand, <code>tmctl</code> provides a simpler abstraction over filters as described in the Trigger documentation.</p>","location":"brokers/triggerfilters/"},{"title":"Filter operators","text":"<p>Filter operators fall under two categories: string matching functions <code>exact</code>, <code>prefix</code> and <code>suffix</code>, and logical operators <code>all</code>, <code>any</code> and <code>not</code> to combine them. The string matching functions can be used at the root of the <code>filters</code> attribute without requiring a logical operator.</p> <ul> <li><code>exact</code>: the key must exist and exactly match the provided value</li> <li><code>prefix</code> the key must exist and the value include the provided value as a prefix</li> <li><code>suffix</code> the key must exist and the value include the provided value as a suffix</li> <li><code>all</code> all operators must evaluate to <code>true</code></li> <li><code>any</code> at least one operator must evaluate to <code>true</code></li> <li><code>not</code> all operators must evaluate to <code>false</code></li> </ul>","location":"brokers/triggerfilters/#filter-operators"},{"title":"Examples","text":"<p>Filter for events whose <code>type</code> attribute is set to <code>io.triggermesh.demo</code></p> <pre><code>filters:\n- exact:\n    type: my.demo.type\n</code></pre> <p>Filter for events whose <code>type</code> attribute is set to <code>io.triggermesh.demo</code> and <code>category</code> is set to <code>test</code></p> <pre><code>filters:\n- all:\n  - exact:\n      type: io.triggermesh.demo\n  - exact:\n      category: test\n</code></pre> <p>Filter for events whose <code>type</code> attribute starts with <code>io.triggermesh.</code> or <code>type</code> is set to <code>io.tm.demo</code></p> <pre><code>filters:\n- any:\n  - prefix:\n      type: io.triggermesh.\n  - exact:\n      type: io.tm.demo\n</code></pre> <p>Filter for events whose <code>type</code> attribute does not ends with <code>.avoid.me</code> or <code>.avoid.me.too</code>.</p> <pre><code>filters:\n- not:\n  - any:\n    - suffix:\n        type: .avoid.me\n    - suffix:\n        type: .avoid.me.too\n</code></pre>","location":"brokers/triggerfilters/#examples"},{"title":"Triggers","text":"<p>A Trigger belongs to a broker, and is used to route events from a Broker to a Target. A Broker can have multiple Triggers, and each Trigger has its own filters which are used to determine if an event should fire the trigger. When an event lands on a Broker, it is evaluated against all that Broker's Triggers and will fire every Trigger whose filters are a match. This allows for publish-subscribe style communication.</p>","location":"brokers/triggers/"},{"title":"<code>tmctl</code>","text":"<pre><code>tmctl create trigger --eventTypes &lt;type1,type2&gt; --target &lt;targetname&gt;\n</code></pre> <p><code>tmctl</code> provides easy definition of Triggers. Just like any other TriggerMesh component, <code>tmctl</code> assumes that the Trigger should be assigned to the current Broker, but a different Broker can be specified with the <code>--broker</code> parameter.</p> <p>The only required parameter for a Trigger with <code>tmctl</code> is <code>--target</code> which specifies the name of the target that should be used to deliver the event to an external consumer.</p> <p>The <code>--eventTypes</code> parameter is used to specify which event types should match this Trigger's filter. If an array of types is provided, for example <code>--eventTypes mytype1, mytype2</code> then events matching either type will fire the Trigger (<code>OR</code> logic). If no <code>--eventTypes</code> are provided, a catch-all Trigger will be created, that fires against every event that lands on the Broker.  Warning: catch-all Triggers can create event loops when used incorrectly and are generally best avoided.</p> <p>As a shortcut, you can also use <code>--source</code> to specify the name of the source component that you want to use to fire the Trigger. Under the hood, <code>tmctl</code> will figure our the right filter to create based on the types of events emitted by that source.</p>","location":"brokers/triggers/#tmctl"},{"title":"Kubernetes","text":"<p>The Trigger custom resource definition lets you create Trigger objects on Kubernetes. Below is an example of a Trigger object definition:</p> <pre><code>apiVersion: eventing.triggermesh.io/v1alpha1\nkind: Trigger\nmetadata:\n  name: mytrigger\nspec:\n  broker:\n    group: eventing.triggermesh.io\n    kind: RedisBroker\n    name: mybroker\n  target: targets.triggermesh.io/v1alpha1\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: cloudeventstarget\n      name: cloudeventstarget\n  filters: &lt;Filter specification. See 'Filtering Events' section in this doc&gt;\n</code></pre> <p>The key elements of a Trigger object are:</p> <ul> <li>The Broker on which the Trigger will run</li> <li>The Target to which events will be delivered. It must be set to either a Kubernetes object that can be resolved to an URL, or simply a URL.</li> <li>The filters which contain a set of filter expressions that evaluate which events should fire the Trigger. The absence of a filter results in a catch-all Trigger. See Trigger filters for details.</li> <li>The optional Delivery section to configure retries and dead-lettering. See delivery for details on configuring event delivery.</li> </ul>","location":"brokers/triggers/#kubernetes"},{"title":"TriggerMesh's architecture","text":"","location":"get-started/architecture/"},{"title":"TriggerMesh components","text":"<p>TriggerMesh's main functionality is provided by individual components such as Brokers, Sources, Targets, and Transformations. Each component is a provided as container which can be configured declaratively to customise its behaviour. For example, the SQS Source takes the SQS queue ARN as a configuration. Brokers are the most complex of these containers: they include Triggers, and have the option of being backed by Redis for event durability.</p>","location":"get-started/architecture/#triggermesh-components"},{"title":"Working with TriggerMesh components","text":"<p>There are two \"user interfaces\" that you can use to configure and run TriggerMesh components.</p> <p><code>tmctl</code> is a command line interface that both lets you easily configure the components in a developer-friendly way, and also runs the containers on your machine using Docker.</p> <p>TriggerMesh components can also run natively on Kubernetes. This is made possible by the TriggerMesh custom resource definitions (CRDs) and controllers. Each TriggerMesh component has its own CRD. Sources, targets, transformations, and others all share one controller, and the Broker has its own controller. This means you can configure and operate TriggerMesh just like any other Kubernetes-native application and reap the associated benefits.</p>","location":"get-started/architecture/#working-with-triggermesh-components"},{"title":"How do events flow through TriggerMesh?","text":"<p>TriggerMesh components communicate over the network according to the CloudEvents standard. CloudEvents provide a standard envelope for events which means they can be manipulated in a uniform way: routing, transformations, etc... become possible regardless of where the event comes from.</p> <p>CloudEvents also comes with protocol bindings which govern how components can exchange events over the network. Inside TriggerMesh, events are exchanged using the CloudEvents HTTP protocol binding.</p>","location":"get-started/architecture/#how-do-events-flow-through-triggermesh"},{"title":"GitHub repos","text":"<ul> <li>Brokers and Triggers: these are the TriggerMesh eventing components. The source code for the Kubernetes controller can be found at TriggerMesh Core.</li> <li>Sources, Targets, Transformations, and other components: these let you connect to external systems and process events. Their source code can be found at TriggerMesh.</li> <li><code>tmctl</code>: the command line interface, which makes the components from <code>triggermesh-core</code> and <code>triggermesh</code> easy to configure and run on Docker. The source code can be found tmctl.</li> <li>The TriggerMesh documentation can be found at docs.</li> </ul>","location":"get-started/architecture/#github-repos"},{"title":"Dependency on Knative Serving","text":"<p>TriggerMesh relies on Knative Serving to run on Kubernetes. TriggerMesh sources and targets use Knative Serving to run as addressable services and to scale. We plan on relaxing this dependency in the future.</p>","location":"get-started/architecture/#dependency-on-knative-serving"},{"title":"Configure autocompletion for <code>tmctl</code>","text":"<p>Work in progress</p> <p>We are still working to stabilise these instructions for various configurations. Please let us know if you encounter difficulties.</p>  <p>With autocompletion with <code>tmctl</code>, you'll be able to hit the Tab key to get contextual recommendations for CLI commands and their parameters.</p> <p>If you used <code>brew install</code> to install <code>tmctl</code> then autocompletion should already be configured. For other methods, please follow the instructions below.</p> Bash (Linux, Windows WSL)ZSH (MacOS, Linux)   <pre><code>echo 'source &lt;(tmctl completion bash)' &gt;&gt;~/.bash_profile\n</code></pre>   <p>If shell completion is not already enabled in your environment you will need to enable it by adding the following two commands to your <code>.zshrc</code>:</p> <pre><code>autoload -Uz compinit\ncompinit\n</code></pre> <p>With autocomplete for ZSH configured, you can proceed to configure autocomplete for <code>tmctl</code> with the following commands:</p> <pre><code>source &lt;(tmctl completion zsh)\ncompdef _tmctl tmctl\n</code></pre> <p>For autocomplete to load automatically in a new terminal, you should also add the two previous commands to your <code>.zshrc</code>.</p>     <p>For other shells than those shown above, please try:</p> <pre><code>tmctl completion --help   \n</code></pre> <p>And then for example:</p> <pre><code>tmctl completion fish --help\n</code></pre>","location":"get-started/autocompletion/"},{"title":"TriggerMesh Concepts","text":"<p>TriggerMesh lets you capture events with Sources, route and transform them using Transformations, Brokers, and Triggers, and deliver them to consumers using Targets. TriggerMesh provides a unified eventing experience meaning all events can be centralised to a single Broker with a common format called CloudEvents.</p> <p></p>","location":"get-started/concepts/"},{"title":"Events","text":"<p>In TriggerMesh, an Event is described using a common format that defines the structure and metadata description of events.</p> <p>The format is based on a subset of the CloudEvents specification. TriggerMesh supports the JSON format of CloudEvents and uses the HTTP protocol binding to transport CloudEvents over HTTP.</p> <p>A TriggerMesh Event is composed of the following elements:</p> <ul> <li><code>id</code>: Identifies the event</li> <li><code>specversion</code>: The version of the CloudEvents specification which the event uses. This enables the interpretation of the context</li> <li><code>type</code>: This attribute contains a value describing the type of event related to the originating occurrence. Often this attribute is used for routing, observability, policy enforcement, etc.</li> <li>(optional) <code>dataschema</code>: Identifies the schema that data adheres to. When using the Registry, this can be an explicit reference to a schema version in the Registry.</li> <li>(optional) <code>subject</code>: This describes the subject of the event, for example a filename if the event is \u201cS3 object created\u201d</li> <li>(optional) <code>time</code>: timestamp of when the occurrence happened</li> <li>(optional) <code>datacontenttype</code>: Content type of data value. For now TriggerMesh only supports JSON for Transformations and Advanced filters.</li> </ul> <p>Events may include any number of additional attributes with distinct names, known as extension attributes.</p> <p>The <code>data</code> attribute carries the event payload encoded into a media format specified by datacontenttype (e.g. application/json). It and adheres to the dataschema format if present.</p> <p>Example event:</p> <pre><code>{\n  \"specversion\" : \"1.0\",\n  \"type\" : \"com.aws.s3.objectcreated\",\n  \"source\" : \"aws.s3\",\n  \"subject\" : \"mynewfile.jpg\",\n  \"id\" : \"A234-1234-1234\",\n  \"time\" : \"2018-04-05T17:31:00Z\",\n  \"extension1\" : \"value\",\n  \"datacontenttype\" : \"application/json\",\n  \"dataschema\": \"http://schemas.myorg.com/schemagroups/awsS3/schemas/com.aws.s3.objectcreated@aws.s3/versions/2\",\n  \"data\" : \"{\\\"hello\\\":\\\"world\\\"}\"\n}\n</code></pre>","location":"get-started/concepts/#events"},{"title":"Sources","text":"<p>Sources are the origin of data and events. These may be on-premises or cloud-based. Examples include databases, message queues, logs, and events from applications or services.</p> <p>All sources are listed and documented in the sources documentation and in the API Reference.</p>","location":"get-started/concepts/#sources"},{"title":"Brokers, Triggers and Filters","text":"<p>TriggerMesh provides a Broker that acts as an intermediary between between event producers and consumers, decoupling them from each other and providing delivery guarantees to ensure that no events are lost along the way.</p> <p>Brokers behave like an event bus, meaning all events are buffered together as a group. Triggers are used to determine which events go to which targets. A Trigger is attached to a Broker, and contains a Filter which specifies which events should cause the Trigger to fire. These filters are based on event metadata or payload contents. If a Trigger fires, it sends the event to the Target defined in the Trigger.</p> <p>There are two flavours of the TriggerMesh Broker: MemoryBroker and RedisBroker. The former has no persistence, whereas the later is able to recover from failure scenarios without losing events.</p>","location":"get-started/concepts/#brokers-triggers-and-filters"},{"title":"Targets","text":"<p>Targets are the destination for the processed events or data. Examples include databases, message queues, monitoring systems, and cloud services.</p> <p>In some cases, a Target may in turn reply with another event (acknowledgment, error, ...). These response events can be handled with additional Triggers. Typically, the event <code>type</code>of a response event is the same as the original event type with <code>.response</code> appended to the end.</p> <p>All targets are listed and documented in the targets documentation and in the API Reference</p>","location":"get-started/concepts/#targets"},{"title":"Transformations","text":"<p>Transformations are a set of modifications to incoming events. Examples include annotating incoming events with timestamps, dropping fields, or rearranging data to fit an expected format.</p> <p>TriggerMesh provides a few ways to transform events:</p> <ul> <li>using the low-code TriggerMesh transformation language called Bumblebee</li> <li>using functions written Python, NodeJS, and Ruby</li> </ul>","location":"get-started/concepts/#transformations"},{"title":"From tmctl to Kubernetes","text":"<p>The TriggerMesh command line interface <code>tmctl</code> is an easy to start working with events in your development environment with minimal dependencies.</p> <p>But if you'd like to take your local TriggerMesh configuration and deploy it to a Kubernetes cluster, you can use the <code>tmctl dump</code> command for this, which produces a Kubernetes YAML manifest that can be used to instantiate the same configuration on a Kubernetes cluster that has TriggerMesh installed.</p>  <p>Important considerations</p> <ul> <li>If you delete resources in tmctl, it also deletes any backing infrastructure that it created (e.g. AWS SQS queues)</li> <li>If you don't stop tmctl on your machine, there could be race conditions with the Kubernetes environment, because tmctl and TriggerMesh on K8s will share the same external resources</li> </ul>  <p>Please refer to the <code>tmctl dump</code> reference documentation for more information.</p>","location":"get-started/moving-from-dev-to-K8s/"},{"title":"Quickstart","text":"<p>This quickstart will take you through the fastest and easiest way to start using events with TriggerMesh's command line interface, <code>tmctl</code>. <code>tmctl</code> makes it easy to create, configure and run TriggerMesh on any machine that has Docker.</p> <p>By the end of this quickstart you will have done the following:</p> <ol> <li>captured events an external service by polling it over HTTP. It generates text that will be used as the event payload.</li> <li>Transformed the event by adding a new attribute to it</li> <li>Routed the event to an external Target: the TriggerMesh Console</li> <li>Throughout the quickstart, you'll monitor everything happening inside the Broker with the <code>watch</code>command</li> </ol> <p></p>  <p>Docker required</p> <p>Please make sure you are able to run docker containers on your machine before proceeding.</p>","location":"get-started/quickstart/"},{"title":"Installation","text":"<p> Install <code>tmctl</code></p> <p><code>tmctl</code> is the TriggerMesh command line interface (CLI) that makes it easy to work with events from the safety of your office (or couch).</p> <p>TriggerMesh CLI can be installed from different sources: brew repository, pre-built binary, or compiled from source.</p> BrewPre-built binary (Linux, MacOS)Pre-built binary (Windows)From source   <pre><code>brew install triggermesh/cli/tmctl\n</code></pre>   <p>Use the following one-liner to automatically download and install the CLI:</p> <pre><code>curl -sSfL https://raw.githubusercontent.com/triggermesh/tmctl/HEAD/hack/install.sh | sh\n</code></pre> <p>Alternatively, visit the releases page to manually download the latest version for your platform and make sure the path of the downloaded binary is configured in the <code>PATH</code> environment variable.</p>   <p>Visit the releases page to manually download the latest version for your platform and make sure the path of the downloaded binary is configured in the <code>PATH</code> environment variable.</p>   <p>The most recent version of the <code>go</code> compiler is recommended to build <code>tmctl</code> binary from source:</p> <pre><code>git clone git@github.com:triggermesh/tmctl.git\ncd tmctl\ngo install\n</code></pre> <p>Make sure that the binary's location is configured in the <code>PATH</code> environment variable, like so:</p> <pre><code>export PATH=\"$HOME/go/bin:$PATH\"\n</code></pre> <p>Verify that the binary has been successfully installed:</p> <pre><code>tmctl --help\n</code></pre>    <p>To configure autocompletion for <code>tmctl</code>, please refer to the dedicated guide.</p>","location":"get-started/quickstart/#installation"},{"title":"Create a Broker and send it an event","text":"<p> Create a Broker</p> <p>Your Broker will reliably route and deliver events from producers to consumers:</p> <pre><code>tmctl create broker foo\n</code></pre> <p> Watch events sent to the Broker</p> <p>Open a second terminal to display all events passing through the broker. Keep this second terminal open throughout the quickstart.</p> <p>Type:</p> <pre><code>tmctl watch\n</code></pre> <p>Wait for this command to say complete and print <code>Watching...</code>.</p> <p> Send it an event</p> <p>Back to the 1st terminal, and send an event to the Broker with JSON data:</p> <pre><code>tmctl send-event '{\"hello\":\"world\"}'\n</code></pre> <p>In the <code>Watching...</code>terminal, you should see the event received by your Broker, something like this:</p> <pre><code>tmctl % tmctl watch\n2022/11/08 16:35:33 Watching...\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: triggermesh-local-event\n  source: triggermesh-cli\n  id: 93dbed08-fb66-43d7-811b-2725f0e1d74e\n  time: 2022-11-08T15:38:35.507676Z\n  datacontenttype: application/json\nData,\n  {\n    \"hello\": \"world\"\n  }\n</code></pre>  <p>Doesn't work?</p> <p>Copy any output and PLEASE TELL US NOW .</p>","location":"get-started/quickstart/#create-a-broker-and-send-it-an-event"},{"title":"Add an external event source","text":"<p> Poll an external HTTP endpoint for events</p> <p>Let's create external source: <pre><code>tmctl create source httppoller \\\n    --endpoint https://corporatebs-generator.sameerkumar.website/ \\\n    --eventType buzzword.phrase \\\n    --interval 20s \\\n    --method GET\n</code></pre></p> <p>With the <code>eventType</code> parameter we're saying that events from this source should be given the type <code>buzzword.phrase</code>. This can be used later on for routing.</p> <p> Watch the events</p> <p>In the second terminal that is <code>Watching...</code>the Broker, you should be regularly receiving some generated text:</p> <pre><code>2022/11/09 16:17:38 Watching...\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: buzzword.phrase\n  source: local.foo-httppollersource\n  id: c3cf14c5-8228-4366-8a33-c42c8e5847cb\n  time: 2022-11-22T13:07:51.659171708Z\n  datacontenttype: application/json\nData,\n  {\n    \"phrase\": \"Rapidiously Brand Covalent Architectures\"\n  }\n</code></pre>","location":"get-started/quickstart/#add-an-external-event-source"},{"title":"Route events from the Broker to the TriggerMesh Console","text":"<p> Create a target</p> <p>Now let's send those events somewhere.</p> <p>We're going to run a local service called TriggerMesh Console that is used to view events in the browser. Create a Target that points to this service and runs the necessary container with the following command:</p> <pre><code>tmctl create target \\\n    --name console \\\n    --from-image gcr.io/triggermesh/triggermesh-console:v0.0.1 \\\n    --source foo-httppollersource\n</code></pre> <p>After running this command, it should output a URL that you can open in your browser:</p> <pre><code>Listening on:     http://localhost:&lt;port&gt;\n</code></pre> <p> View events in TriggerMesh Console</p> <p>Open this in your browser, and watch as a new event appears every 20 seconds:</p> <p></p> <p>If you still have <code>tmctl watch</code> running in a second terminal, you'll also see events there when they hit the Broker, before passing on to the Console.</p>","location":"get-started/quickstart/#route-events-from-the-broker-to-the-triggermesh-console"},{"title":"Transform the event","text":"<p>Lets transform the incoming events before they are passed to the Console.</p> <p> Create a transformation</p> <p>Using TriggerMesh's Bumbleebee transformation component, we can easily modify an event as it passes through the TriggerMesh.</p> <pre><code>tmctl create transformation --target console &lt;&lt;EOF\ndata:\n- operation: add\n  paths:\n  - key: new-field\n    value: hello from Transformation!\nEOF\n</code></pre> <p>This simple transformation adds a new key to the event's JSON payload. We're using the <code>--target</code> parameter to indicate that the transformed events should be passed along to the Console.</p> <p> Send an event</p> <p>Although you can wait till the HTTPPoller fetches an another event, you can also simulate you own event with the following command:</p> <pre><code>tmctl send-event '{\"hello\":\"triggermesh\"}' --eventType buzzword.phrase\n</code></pre> <p>Notice how events displayed in the Console now include the additional field that was added by the transformation.</p> <p></p> <p> View your TriggerMesh configuration</p> <p>Run the following command:</p> <pre><code>tmctl describe\n</code></pre> <p>As you can see, <code>tmctl describe</code> displays useful info about your current configuration. It lists all the sources, targets, triggers, and other components you've defined, and their properties.</p> <pre><code>~ % tmctl describe\nBroker     Status\nfoo        online(http://localhost:53053)\n\nTrigger                  Target                 Filter\nfoo-trigger-a73dcb65     foo-transformation     type is buzzword.phrase\nfoo-trigger-0a1c285d     console                type is foo-transformation.output\n\nTransformation         EventTypes                    Status\nfoo-transformation     foo-transformation.output     online(http://localhost:53205)\n\nSource                   Kind                 EventTypes          Status\nfoo-httppollersource     httppollersource     buzzword.phrase     online(http://localhost:53069)\n\nTarget      Kind                                                        Expected Events     Status\nconsole     service (gcr.io/triggermesh/triggermesh-console:v0.0.1)     *                   online(http://localhost:53098)\n</code></pre>","location":"get-started/quickstart/#transform-the-event"},{"title":"Next steps","text":"<p>Now that you know what a source, target, and transformation are, you can start doing more things! Like creating your own Trigger, or adding new sources and targets that make sense to you.</p> <p> create your first Trigger:</p> <ul> <li>head to the Trigger guide to learn about Triggers.</li> </ul> <p> AWS users:</p> <ul> <li>try ingesting AWS events by using an SQS source</li> <li>or trigger a Lambda function with the Lambda target</li> </ul> <p> Azure users:</p> <ul> <li>try ingesting Azure events by using the Azure Event Hubs source</li> <li>or sending events to Azure Sentinel for threat analysis</li> </ul> <p> Google Cloud users:</p> <ul> <li>try ingesting Google events using the Google Pub/Sub Source</li> <li>or sending events to Google Cloud Workflows</li> </ul> <p> Kafka users:</p> <ul> <li>you can read and write to kafka easily using our Kafka Source and Kafka Target</li> </ul> <p> HTTP users:</p> <ul> <li>try ingesting events over standard HTTP with the Webhook Source or with CloudEvents over HTTP with the CloudEvents Source</li> <li>or sending events over HTTP with fine control over HTTP parameters with the HTTP Target, or using CloudEvents over HTTP with the CloudEvents Target.</li> </ul> <p> Kubernetes users:</p> <ul> <li>try exporting your local configuration as a Kubernetes manifest by using <code>tmctl dump</code>, and deploying to a cluster. You can learn more about it in the dedicated guide.</li> </ul>","location":"get-started/quickstart/#next-steps"},{"title":"Clean up","text":"<p>After running through this quickstart guide, you'll have a number of containers running on Docker.</p> <p>You can stop all TriggerMesh-related containers with:</p> <pre><code>tmctl stop\n</code></pre> <p>To delete you local configuration (all sources, targets, brokers, transformations) and stop all containers, you can try:</p> <pre><code>tmctl delete --broker foo\n</code></pre> <p>Replace <code>foo</code> with the name of your broker. Be careful, you can't go back once you've deleted everything.</p>","location":"get-started/quickstart/#clean-up"},{"title":"Event flow and delivery guarantees","text":"","location":"get-started/reliabledelivery/"},{"title":"TL;DR","text":"<p>TriggerMesh does its best to provide at-least-once delivery guarantees:</p> <ul> <li>Events passing through TriggerMesh are not lost in the case of service or machine restarts, thanks to persistence provided by the Redis Broker</li> <li>Source components only acknowledge event receipt to event producers (where relevant) once the Broker has safely acknowledged an event. For example, SQSSource will only tell SQS to remove an event from a queue once the Broker has confirmed it has received it.</li> <li>Brokers do their best to deliver events to external consumers through Target components. This means they will retry sending events under certain conditions, and will also use dead-lettering to save events that could not be delivered. These behaviours can be configured on Triggers.</li> <li>Event consumers can potentially receive events more than once. Its is up to consumers to be idempotent, meaning the effects of a duplicate event either do not cause side effects or duplicate messages are ignored.</li> </ul>","location":"get-started/reliabledelivery/#tldr"},{"title":"From event Sources to Brokers","text":"<p>As a general rule a source will not consider a produced message delivered until the destination have acknowledged reception. Depending on the source nature this means that it will either notify a failure to the message origin, or will mark the message as undelivered.</p> <p>The SQSSource is an example of a polling source that works by polling the AWS SQS queue. It locks an SQS message for the duration of a visibilityTimeout which avoids the same message being processed by another consumer. Once the SQSSource has received an acknowledgement that the event has been received by the Broker, it tells the SQS queue to delete that message. If the Broker does not acknowledge receipt of the event, the SQSSource does not acknowledge the message from SQS, thereby allowing it to be consumed by another consumer.</p>","location":"get-started/reliabledelivery/#from-event-sources-to-brokers"},{"title":"From Brokers to Targets via Triggers","text":"<p>When an event is delivered to the Broker, it is evaluated against all the Broker\u2019s Triggers. All Triggers that match will forward the event to their associated Target(s).</p> <p>Matching is based on the filters defined on the Trigger.</p> <p>If an event matches multiple Triggers, the event won\u2019t be removed by the Broker until each Target associated with those Triggers acknowledges the event. The Broker achieves this by maintaining context about the state of delivery to each of those Targets.</p> <p>The Broker has a timeout so if a Trigger doesn\u2019t acknowledge within that time, then the event is not acknowledged and will be retried again for that Trigger.</p>","location":"get-started/reliabledelivery/#from-brokers-to-targets-via-triggers"},{"title":"From Targets to external consumers, incl. retries and dead lettering","text":"<p>A Target, such as an HTTP Target, is responsible for passing an event to the consumer, e.g. an HTTP service.</p> <p>When an event is delivered, the outcome is either a completed delivery or a failed delivery.</p> <p>Completed delivery means the Target can send an acknowledgement to the Broker, letting it know that message has been delivered. Completed delivery does not necessarily mean that the Consumer has successfully received the event.</p> <p>Below are some examples of the conditions under which completed delivery occurs:</p> <ul> <li>the external service responds with a 200 response</li> <li>the external service responds with a 401 response (unauthorised)</li> </ul> <p>The idea behind 401 being considered as a completed delivery is that retrying the call won't improve chances of success.</p> <p>Failed delivery means that a recoverable error occurred during delivery by the Target to the external consumer, such as a network issue or temporarily unavailable consumer. In this case, the Target behaves according to the delivery configuration it has (retries and dead lettering). When a Target has exhausted all efforts to deliver the event to no avail (the final step being saving it as a dead letter), then the event is acknowledged to the Broker.</p>","location":"get-started/reliabledelivery/#from-targets-to-external-consumers-incl-retries-and-dead-lettering"},{"title":"Display events in TriggerMesh Console","text":"<p>TriggerMesh Console provides a web GUI to display events and their metadata and filter for specific events. It is something you host locally and can display in your browser.</p> <p>To use it, you can define it as an event Target and Route events to it using Triggers.</p> <pre><code>tmctl create target --from-image gcr.io/triggermesh/triggermesh-console:v0.0.1\n</code></pre> <p>After running this command, a URL should be display that you can open in your browser:</p> <pre><code>open http://localhost:&lt;port&gt;\n</code></pre> <p>This is what it looks like:</p> <p></p>","location":"get-started/triggermesh-console/"},{"title":"Connecting TriggerMesh Clusters","text":"<p>Installation</p> <p>Make sure you have completed the installation procedure before proceeding with any of the guides.</p>  <p>In this guide we will connect 2 TriggerMesh clusters that will be able to interchange CloudEvents flowing through them. You might want to connect multiple TriggerMesh instances to:</p> <ul> <li>Move events between environments. For example from production to staging in order to perform tests with actual events.</li> <li>Geographically distribute events among clusters.</li> <li>Perform Cluster migrations.</li> <li>Integrate heterogenous applications through real time events.</li> </ul>","location":"guides/connectingclusters/"},{"title":"Scenario","text":"<p>For this scenario we will need to setup 2 TriggerMesh clusters that we will call at this document <code>ClusterSender</code> and <code>ClusterReceiver</code>.</p> <p>ClusterSender components:</p> <ul> <li><code>Broker</code> is the temporary storage for CloudEvents.</li> <li><code>PingSource</code> is a peridic CloudEvents producer that will send them to the Broker.</li> <li><code>CloudEventsTarget</code> will listen to CloudEvents and send them to an external location.</li> <li><code>Trigger</code> will subscribe to CloudEvents at the Broker and send them to the CloudEventsTarget.</li> </ul> <p>ClusterReceiver components:</p> <ul> <li><code>Broker</code> is the temporary storage for CloudEvents.</li> <li><code>CloudEventsSource</code> will listen to CloudEvents from remote locations and send them to the Broker.</li> <li><code>event-display</code> service will listen to CloudEvents and log them at the output console.</li> <li><code>Trigger</code> will subscribe to CloudEvents at the Broker and send them to the EventDisplay.</li> </ul> <p></p> <p>Events produced at the PingSource will flow as depicted above until they reach the EventDisplay at the second cluster.</p>","location":"guides/connectingclusters/#scenario"},{"title":"Setup","text":"<p>Local setup</p> <p>You can use a local setup by creating 2 kind clusters.</p> <pre><code>$ kind create cluster --name clustersender\n...\n\n$ kind create cluster --name clusterreceiver\n...\n</code></pre> <p>Add LoadBalancer support to the receiver cluster by following kind instructions.</p> <p>You can switch to each configured cluster using <code>kubectl config use-context</code> command.</p> <pre><code>$ kubectl config use-context kind-clustersender\n\n$ kubectl config use-context kind-clusterreceiver\n</code></pre>","location":"guides/connectingclusters/#setup"},{"title":"Receiver Cluster","text":"<p>Receiver cluster</p> <p>Make sure your kubectl configuration is pointing to the receiver cluster.</p>  <p>Create the Broker as the host for this cluster's CloudEvents:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: receiver\n</code></pre> <p>Create a Knative service that runs the <code>event_display</code> image. We will look for received events by looking at the logs of this service.</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-display\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>Using a Trigger we can link the <code>event-display</code> service with the broker to subscribe to all events flowing through it.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: all-events-to-event-display\nspec:\n  broker: receiver\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n</code></pre> <p>The <code>CloudEventsSource</code> component will expose an HTTP endpoint that ingest CloudEvents from external systems. We will configure this component to send ingested CloudEvents to the broker.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: CloudEventsSource\nmetadata:\n  name: gateway-in\nspec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: receiver\n</code></pre> <p>After completing the setup for all the receiver cluster components, any CloudEvent sent to the <code>CloudEventsSource</code> public endpoint will flow throw the broker and be delivered to the <code>event-display</code> service.</p> <p>We will retrieve and take note of the exposed URL at the <code>CloudEventsSource</code>, it will be used later at the the sender cluster.</p> <pre><code>kubectl get cloudeventssources.sources.triggermesh.io gateway-in -ojsonpath='{.status.address.url}'\n</code></pre>","location":"guides/connectingclusters/#receiver-cluster"},{"title":"Sender Cluster","text":"<p>Sender cluster</p> <p>Make sure your kubectl configuration is pointing to the sender cluster.</p>  <p>Create the Broker that as the host for this cluster's CloudEvents:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: sender\n</code></pre> <p>A <code>PingSource</code> produces periodic events based on a cron expression. We will send the produced events to the broker object.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: periodic-event-producer\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\"message\": \"greetings from sender cluster\"}'\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: sender\n</code></pre> <p>The <code>CloudEventsTarget</code> component is able to subscribe to a broker (using a trigger), and forward events to a remote destination. We will configure this component using the endpoint exposed by the <code>CloudEventsSource</code> at the destination cluster, make sure you replace the placeholder text at the following command.</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: CloudEventsTarget\nmetadata:\n  name: gateway-out\nspec:\n  endpoint: &lt;REPLACE-WITH-CLOUDEVENTSSOURCE-HTTP-ENDPOINT&gt;\n</code></pre> <p>Subscribing the <code>CloudEventsTarget</code> to CloudEvents flowing through a broker is done via a trigger.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: all-events-to-cloudeventstarget\nspec:\n  broker: sender\n  subscriber:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: CloudEventsTarget\n      name: gateway-out\n</code></pre>","location":"guides/connectingclusters/#sender-cluster"},{"title":"Receiving Events","text":"<p>With all components being setup CloudEvents should be flowing from <code>PingSource</code> at the sender cluster to the <code>event-display</code> service at the receiver cluster. We can make sure by looking at the receiving service logs.</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-display -c user-container -f\n...\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/periodic-event-producer\n  id: eddd0d10-64ef-4c82-bfc0-c0caea63a510\n  time: 2022-05-26T12:44:00.265933805Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-26T12:44:00.272805675Z\nData,\n  {\n    \"message\": \"greetings from sender cluster\"\n  }\n...\n</code></pre>","location":"guides/connectingclusters/#receiving-events"},{"title":"Further improvements","text":"<p>Triggers can be configured with filters to make sure only allowed CloudEvents travels between clusters. Refer to trigger's documentation for configuration options.</p> <p>CloudEventsSource and CloudEventsTarget can be configured with HTTP Basic Authentication.</p>  <p>HTTP Basic Authentication</p> <p>HTTP Basic Authentication is not enctrypted. When used it is thoroughly recommended that Knative Serving is configured with TLS capabilities.</p>","location":"guides/connectingclusters/#further-improvements"},{"title":"Creating a Wiretap","text":"<p>In this guide we will create a Wiretap to monitor the Cloudevent traffic happening within our bridge.</p>","location":"guides/createawiretap/"},{"title":"What is a Wiretap?","text":"<p>A Wiretap is a powerful debugging tool/methodology that can be used to understand the flow of events through the system by subscribing to all of the events that pass through the associated <code>Broker</code>. This is accomplished by the use of a <code>Trigger</code> to route all of the events into a logging service.</p> <p>Consider the following illustration:</p> <p></p>","location":"guides/createawiretap/#what-is-a-wiretap"},{"title":"Implementing a Wiretap","text":"","location":"guides/createawiretap/#implementing-a-wiretap"},{"title":"Creating an Example Bridge","text":"<p>Lets consider this example Bridge as a starting point. This example is currently configured with a <code>PingSource</code> and a <code>Broker</code>.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: events\n\n---\n\napiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ping-sockeye\nspec:\n  data: '{\"name\": \"triggermesh\"}'\n  schedule: \"*/1 * * * *\"\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: events\n</code></pre>","location":"guides/createawiretap/#creating-an-example-bridge"},{"title":"Implement a Wiretap","text":"<p>Now that we have a bridge to work with, lets go ahead and modify our manifest to include a Wiretap. We can do this by adding a <code>Trigger</code> and a <code>Service</code> to our manifest. The <code>Service</code> we will be using will be using is called Sockeye, this is a simple web application that will log the events it receives.</p> <p>We can accomplish this by adding the following to the manifest under the <code>PingSource</code> object:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: sockeye\nspec:\n  broker: events\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n\n---\n\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre>","location":"guides/createawiretap/#implement-a-wiretap"},{"title":"Using the Wiretap","text":"<p>Now that we have all the parts in place, we can utilize our <code>Wiretap</code> to monitor the events that are being sent through our bridge by the <code>PingSource</code> Object. We can do this in two ways.</p> <ol> <li>View the pod logs of the <code>sockeye</code> service:</li> <li><code>kubectl get pods</code> will show the pods that are running. Retrieve the sockeye pod name from the output.</li> <li> <p><code>kubectl logs &lt;SOCKEYE_POD_NAME&gt; user-container</code> By replacing the <code>&lt;SOCKEYE_POD_NAME&gt;</code> with the pod name you can view the logs of the sockeye pod.</p> </li> <li> <p>View the web service exposed by the <code>sockeye</code> service:</p> </li> <li><code>kubectl get ksvc</code> will show the KSVC's that are running. Retrieve the sockeye public URL from the <code>URL</code> column and navigate to it in your browser.</li> </ol>","location":"guides/createawiretap/#using-the-wiretap"},{"title":"Creating a Bridge With a Dead Letter Sink (DLS)","text":"","location":"guides/creatingadls/"},{"title":"What is a Dead Letter Sink?","text":"<p>A Dead Letter Sink is a Knative construct that allows the user to configure a destination for events that would otherwise be dropped due to some delivery failure. This is useful for scenarios where you want to ensure that events are not lost due to a failure in the underlying system.</p>","location":"guides/creatingadls/#what-is-a-dead-letter-sink"},{"title":"Scenario Debriefing","text":"<p>In this example we are going to create a Bridge that contains a PingSource object that will emit an event on a regular basis to a Broker named <code>demo</code>. A Service, named <code>event-success-capture</code> will subscribe to PingSource events flowing through the Broker using a Trigger.</p> <p>The Broker delivery options will be set to use a Dead Letter Sink so that in the case of a delivery error the event will be forwarded to another Service named <code>event-failure-capture</code> instead of being lost into the void.</p> <p></p> <p>We will test the bridge to make sure events are delivered to <code>event-success-capture</code>, then we will break the bridge by removing the <code>event-success-capture</code> service, in which case we expect the Dead Letter Sink to receive all events that were not delivered.</p>","location":"guides/creatingadls/#scenario-debriefing"},{"title":"Creating a Bridge with a Dead Letter Sink","text":"<p>Creating objects</p> <p>All objects mentioned at this guide are intended to be created at kubernetes. When using <code>kubectl</code> write the provided YAML manifests to a file and write at a console:</p> <pre><code>$ kubectl apply -f my-file.yaml\n</code></pre> <p>Alternatively if you don't want to write the manifests to a file you can use this command:</p> <pre><code>$ kubectl apply -f - &lt;&lt;EOF\napiVersion: some.api/v1\nkind: SomeObject\nmetadata:\n  name: some-name\nspec:\n  some: property\nEOF\n</code></pre>   <p>Bridge manifest</p> <p>The next steps configure and explain the Bridge to build to demonstrate the usage of the Dead Letter Sink. A single manifest containing all the objects in the bridge can be downloaded here.</p>","location":"guides/creatingadls/#creating-a-bridge-with-a-dead-letter-sink"},{"title":"Step 1: Create the Broker","text":"<p>Create a new Broker with following configuration:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\nspec:\n  delivery:\n    deadLetterSink:\n      ref:\n          apiVersion: serving.knative.dev/v1\n          kind: Service\n          name: event-failure-capture\n    backoffDelay: \"PT0.5S\"     # ISO8601 duration\n    backoffPolicy: exponential # exponential or linear\n    retry: 2\n</code></pre> <p>Here a Broker named <code>demo</code> is configured with the following delivery options:</p> <ul> <li>2 retries on failure, backing off exponentialy with a 0.5 seconds factor. This is not the focus of this article but it is recommended to setup retries before giving up on delivery and sending to the DLS.</li> <li>Dead Letter Sink pointing to a service named <code>event-failure-capture</code>. Kubernetes can be requested the creation of this object even if the DLS service does not exists yet.</li> </ul>","location":"guides/creatingadls/#step-1-create-the-broker"},{"title":"Step 2: Create the PingSource","text":"<p>Create a PingSource object with the following configuration:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: say-hi\nspec:\n  data: '{\"hello\": \"triggermesh\"}'\n  schedule: \"*/1 * * * *\"\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: demo\n</code></pre> <p>This object will emit an event every minute to the Broker created in the previous step.</p>","location":"guides/creatingadls/#step-2-create-the-pingsource"},{"title":"Step 3: Create the <code>event-success-capture</code> Service","text":"<p>Create a Service named <code>event-success-capture</code> with the following configuration:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-success-capture\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>That service will write to its standard output any CloudEvent received. We will use a Trigger to subscribe to all events flowing through the Broker.</p>","location":"guides/creatingadls/#step-3-create-the-event-success-capture-service"},{"title":"Step 4: Create the <code>demo-to-display</code> Trigger","text":"<p>Create a Trigger to route events to the <code>event-success-capture</code> Service with the following configuration:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: demo-to-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-success-capture\n</code></pre> <p>This Trigger configures the Broker to send all flowing events to the <code>event-success-capture</code> service.</p>","location":"guides/creatingadls/#step-4-create-the-demo-to-display-trigger"},{"title":"Step 5: Create the <code>event-failure-capture</code> Service","text":"<p>Create the Service named <code>event-failure-capture</code> that was configured at the Broker as the Dead Letter Sink parameter:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-failure-capture\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>This service should only receive messages that could not be delivered to a destination.</p>","location":"guides/creatingadls/#step-5-create-the-event-failure-capture-service"},{"title":"Test the Bridge","text":"<p>Make sure that all created objects are ready by inspecting the <code>READY</code> column after this command:</p> <pre><code>$ kubectl get ksvc,broker,trigger\n\nNAME                                                URL                                                          LATESTCREATED                 LATESTREADY                   READY   REASON\nservice.serving.knative.dev/event-failure-capture   http://event-failure-capture.default.192.168.49.2.sslip.io   event-failure-capture-00001   event-failure-capture-00001   True\nservice.serving.knative.dev/event-success-capture   http://event-success-capture.default.192.168.49.2.sslip.io   event-success-capture-00001   event-success-capture-00001   True\n\nNAME                               URL                                                                     AGE     READY   REASON\nbroker.eventing.knative.dev/demo   http://broker-ingress.knative-eventing.svc.cluster.local/default/demo   3m20s   True\n\nNAME                                           BROKER   SUBSCRIBER_URI                                           AGE     READY   REASON\ntrigger.eventing.knative.dev/demo-to-display   demo     http://event-success-capture.default.svc.cluster.local   3m20s   True\n</code></pre> <p>Each minute a CloudEvent should be produced by PingSource and sent to the Broker, which in turns would deliver it to the <code>event-success-capture</code>, while <code>event-failure-capture</code> should not be receiving any event. We can confirm that by reading each of those services output:</p>  <p>Retrieving logs command</p> <p>Kubernetes generates dynamic Pod names, but we can use <code>kubectl</code> with the <code>-l</code> flag to filter by a label that identifies the Service.</p> <p>We also add the <code>-f</code> flag to keep receiving logs as they are produced, this way we can see the live feed of events arriving at the Service.</p>  <pre><code>$ kubectl logs -l serving.knative.dev/service=event-success-capture  -c user-container -f\n\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/say-hi\n  id: efcaa3b7-bcdc-4fa9-a0b3-05d9a3c4a9f9\n  time: 2022-06-01T19:54:00.339597948Z\nExtensions,\n  knativearrivaltime: 2022-06-01T19:54:00.340295729Z\nData,\n  {\"hello\": \"triggermesh\"}\n</code></pre> <p>As expected the <code>event-success-capture</code> is receiving events produced by PingSource.</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-failure-capture  -c user-container -f\n2022/06/01 19:36:45 Failed to read tracing config, using the no-op default: empty json tracing config\n</code></pre> <p>Meanwhile <code>event-failure-capture</code> is not showing any event.</p>","location":"guides/creatingadls/#test-the-bridge"},{"title":"Test Failing Bridge","text":"<p>To make the Bridge fail will be removing the <code>event-success-capture</code> service. That will make the delivery fail and (after 2 retries) be sent to the Dead Letter Queue.</p> <pre><code>$ kubectl delete ksvc event-success-capture\nservice.serving.knative.dev \"event-success-capture\" deleted\n</code></pre> <p>After doing so, all events not delivered by Broker through the configured Trigger will be shown at the <code>event-failure-capture</code>:</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-failure-capture  -c user-container -f\n\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/say-hi\n  id: 7e11c3ac-2b00-49af-9602-59575f410b9f\n  time: 2022-06-01T20:14:00.054244562Z\nExtensions,\n  knativearrivaltime: 2022-06-01T20:14:00.055027909Z\n  knativebrokerttl: 255\n  knativeerrorcode: 500\n  knativeerrordata:\n  knativeerrordest: http://broker-filter.knative-eventing.svc.cluster.local/triggers/default/demo-to-display/bd303253-c341-4d43-b5e2-bc3adf70122a\nData,\n  {\"hello\": \"triggermesh\"}\n</code></pre>","location":"guides/creatingadls/#test-failing-bridge"},{"title":"Clean up","text":"<p>Clean up the remaining resources by issuing this command:</p> <pre><code>kubectl delete ksvc event-failure-capture\nkubectl delete triggers demo-to-display\nkubectl delete pingsource say-hi\nkubectl delete broker demo\n</code></pre>","location":"guides/creatingadls/#clean-up"},{"title":"Filters","text":"<p>Filters are an important part of TriggerMesh's event routing mechanism. They allow for filtering events based on the content of the payload. This content-based event filtering is expressed with Google's Common Expression Language within the TriggerMesh <code>Filter</code> API specification.</p>","location":"guides/creatingafilter/"},{"title":"Tutorial for Filters on Kubernetes","text":"<p>Tip</p> <p>You can verify that the API is available with the following command:</p> <p><pre><code>$ kubectl get crd filters.routing.triggermesh.io\nNAME                             CREATED AT\nfilters.routing.triggermesh.io   2021-10-06T09:01:33Z\n</code></pre> You can also explore the API specification with: <pre><code>$ kubectl explain filter\n</code></pre></p>  <p>To demonstrate filtering in TriggerMesh we are going to create the event flow depicted in the diagram below. Two sources of kind <code>PingSource</code> will send events on a repeating schedule, and only the events which pass the filter will be displayed on the final event target. The target is the Sockeye application, a microservice which displays the content of a CloudEvent.</p> <p></p> <p>Let's create all the required objects:</p> <ul> <li> The <code>sockeye</code> target which serves as an event display.</li> <li> Two <code>PingSource</code> to produce events.</li> <li> The <code>Filter</code> to discard unwanted events.</li> </ul>","location":"guides/creatingafilter/#tutorial-for-filters-on-kubernetes"},{"title":"Event display","text":"<p>First we need to have a tool to see our filter results. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL found with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"guides/creatingafilter/#event-display"},{"title":"Event producers","text":"<p>Next, create the two PingSources to produce CloudEvents by saving the following YAML manifests in two separate files and applying them to your Kubernetes cluster with <code>kubectl apply</code>:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-filter-demo-1\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n   \"name\": \"TriggerMesh\",\n    \"sub\": {\n        \"array\": [\"hello\", \"Filter\"]\n        }\n    }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-demo\n</code></pre> <p>The second source uses a different payload to show you how the <code>Filter</code> expression may be used to express complex filtering rules.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-filter-demo-2\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n      \"answer\": 42\n    }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-demo\n</code></pre>","location":"guides/creatingafilter/#event-producers"},{"title":"Filter events","text":"<p>Finally, create the <code>Filter</code> object to filter out events from the first PingSource. Once again save the following YAML manifest in a file and apply it to your Kubernetes cluster with <code>kubectl apply</code>.</p> <pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Filter\nmetadata:\n  name: filter-demo\nspec:\n  expression: $sub.array.0.(string) == \"hello\" &amp;&amp; $name.(string) != \"TriggerMesh\" || $answer.(int64) == 42\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre> <p>Verify that your filter is ready with <code>kubectl</code> like so:</p> <pre><code>$ kubectl get filter\nNAME          ADDRESS                                                      READY   REASON\nfilter-demo   http://filter-adapter.sebgoa.svc.cluster.local/filter-demo   True\n</code></pre> <p>Only events from the second source should appear in the <code>sockeye</code> web interface as shown in the screenshot below:</p> <p></p>  <p>Test your Filter as Code</p> <p>You can test modifying the filter expression and re-applying it with <code>kubectl</code>. This gives you a declarative event filter which you can manage with your GitOps workflow</p>","location":"guides/creatingafilter/#filter-events"},{"title":"Another filter on Kubernetes example","text":"<pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Filter\nmetadata:\n  name: filter-test\nspec:\n  expression: |-\n    ($id.first.(int64) + $id.second.(int64) &gt;= 8) || $company.(string) == \"bar\" || $0.name.first.(string) == \"Jo\"\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n---\napiVersion: sources.knative.dev/v1beta2\nkind: PingSource\nmetadata:\n  name: ps1\nspec:\n  contentType: application/json\n  data: '{\"id\":{\"first\":5,\"second\":3}}'\n  schedule: '*/1 * * * *'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-test\n---\napiVersion: sources.knative.dev/v1beta2\nkind: PingSource\nmetadata:\n  name: ps2\nspec:\n  contentType: application/json\n  data: '{\"id\":{\"first\":2,\"second\":3}}'\n  schedule: '*/1 * * * *'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-test\n---\napiVersion: sources.knative.dev/v1beta2\nkind: PingSource\nmetadata:\n  name: ps3\nspec:\n  contentType: application/json\n  data: '{\"foo\":\"bar\"}'\n  schedule: '*/1 * * * *'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-test\n---\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n      - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre>","location":"guides/creatingafilter/#another-filter-on-kubernetes-example"},{"title":"Splitter","text":"","location":"guides/creatingasplitter/"},{"title":"Splitter overview","text":"<p>An event <code>Splitter</code> is part of the TriggerMesh routing solution. It has the simple purpose of splitting JSON arrays into multiple CloudEvents for further processing.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <pre><code>$ kubectl get crd splitters.routing.triggermesh.io\nNAME                               CREATED AT\nsplitters.routing.triggermesh.io   2021-10-06T09:01:38Z\n</code></pre> <p>You can also explore the API specification with: <pre><code>$ kubectl explain splitter\n</code></pre></p>","location":"guides/creatingasplitter/#splitter-overview"},{"title":"Splitter tutorial on Kubernetes","text":"<p></p> <p>Let's create the required objects:</p> <ul> <li> The <code>sockeye</code> target which serves as an event display.</li> <li> The <code>PingSource</code> which produces a JSON array in its payload.</li> <li> The <code>Splitter</code> to generate the multiple events.</li> </ul>","location":"guides/creatingasplitter/#splitter-tutorial-on-kubernetes"},{"title":"Event display","text":"<p>First of all, we need to have a tool to see the split events. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL found with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"guides/creatingasplitter/#event-display"},{"title":"Events producer","text":"<p>Next we create the PingSource which produces CloudEvents that contain a list in their payload. Save the following YAML manifest in a file and apply it to your Kubernetes cluster with <code>kubectl apply</code>.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-splitter-demo\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n      \"message\":\"hello\",\n      \"items\":[\n          {\n              \"id\":5,\n              \"name\":\"foo\"\n          },{\n              \"id\":10,\n              \"name\":\"bar\"\n          }\n        ]\n      }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Splitter\n      name: splitter-demo\n</code></pre>","location":"guides/creatingasplitter/#events-producer"},{"title":"The Splitter","text":"<p>Finally, create the <code>Splitter</code> that will produce two events from every single CloudEvent received from the PingSource by saving the following YAML manifest and applying it to your Kubernetes cluster.</p> <pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Splitter\nmetadata:\n  name: splitter-demo\nspec:\n  path: items\n  ceContext:\n    type: foo.bar.type\n    source: splitter\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre> <p>Note that you define the path where you are going to find a list in the incoming event and you define the CloudEvent attributes of the generated events (i.e splitter as the source and foo.bar.type as the type).</p> <p>Verify that your splitter is ready with <code>kubectl</code> like so:</p> <pre><code>$ kubectl get splitter\nNAME            ADDRESS                                                          READY   REASON\nsplitter-demo   http://splitter-adapter.sebgoa.svc.cluster.local/splitter-demo   True\n</code></pre> <p>In the sockeye application you will see two individual events that have been generated from the original list emitted by the source. The snapshot below shows you what you should see:</p> <p></p>  <p>Play with your Splitter as Code</p> <p>You can play around by modifying the <code>Splitter</code> object and re-applying it with <code>kubectl</code>. This gives you a declarative event splitter which you can manage with your GitOps workflow</p>","location":"guides/creatingasplitter/#the-splitter"},{"title":"Another Splitter example for Kubernetes","text":"<pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Splitter\nmetadata:\n  name: splitter-test\nspec:\n  path: items\n  ceContext:\n    type: foo.bar.type\n    source: splitter\n    extensions:\n      key1: value1\n      key2: value2\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n---\napiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  annotations:\n    eventing.knative.dev/broker.class: MTChannelBasedBroker\n  name: default\nspec:\n---\napiVersion: sources.knative.dev/v1beta2\nkind: PingSource\nmetadata:\n  name: ps-splitter-demo\nspec:\n  contentType: application/json\n  data: '{\"message\":\"hello\",\"items\":[{\"id\":5,\"name\":\"foo\"},{\"id\":10,\"name\":\"bar\"}]}'\n  schedule: '*/1 * * * *'\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n---\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: to-splitter\nspec:\n  broker: default\n  filter:\n    attributes:\n      type: dev.knative.sources.ping\n  subscriber:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Splitter\n      name: splitter-test\n---\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n      - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n---\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: to-sockeye\nspec:\n  broker: default\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre>","location":"guides/creatingasplitter/#another-splitter-example-for-kubernetes"},{"title":"Using Kong with TriggerMesh","text":"<p>The Kong Ingress Controller can be configured as the network layer for TriggerMesh, enabling it to perform internal and external routing.</p> <p>The steps in this article guide you through the installation and configuration process, referring to external links when information beyond this scope is needed.</p>","location":"guides/kong-ingress/"},{"title":"Pre-requisite","text":"<p>Knative Serving needs to be installed on a Kubernetes cluster, follow the instructions at the documentation to install it, skipping the network layer.</p>  <p>Knative networking layer</p> <p>Kong is a networking layer option for Knative, you don't need to install any of the other choices at the project's documentation.</p>  <p>This guide was written using:</p> <ul> <li>Kubernetes <code>v1.22</code></li> <li>Knative <code>v1.0.0</code></li> <li>Kong Ingress Controller <code>2.3.1</code> (includes Kong <code>2.8</code>)</li> </ul>","location":"guides/kong-ingress/#pre-requisite"},{"title":"Install Kong Ingress Controller","text":"<p>Kong Ingress Controller can be installed using either the YAML manifest at their repository or helm charts.</p> <p>When using YAML, apply the provided manifest:</p> <pre><code>kubectl apply -f https://bit.ly/k4k8s\n</code></pre> <p>When using Helm follow their installation instructions.</p> <p>Once Kong is installed take note of the IP address or public CNAME of the <code>kong-proxy</code> service at the <code>kong</code> namespace.</p> <pre><code>kubectl -n kong get svc kong-proxy\n\nNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nkong-proxy   LoadBalancer   10.98.223.191   35.141.22.45     80:30119/TCP,443:31585/TCP   1m\n</code></pre> <p>In the example above the external IP address <code>35.141.22.45</code> was provisioned.</p>","location":"guides/kong-ingress/#install-kong-ingress-controller"},{"title":"Configure Kong Network Layer For Knative","text":"","location":"guides/kong-ingress/#configure-kong-network-layer-for-knative"},{"title":"Knative Ingress Class","text":"<p>We will configure Knative to use <code>kong</code> as the Ingress class:</p> <pre><code>kubectl patch configmap/config-network \\\n  --namespace knative-serving \\\n    --type merge \\\n      --patch '{\"data\":{\"ingress.class\":\"kong\"}}'\n</code></pre>","location":"guides/kong-ingress/#knative-ingress-class"},{"title":"Setup Knative Domain","text":"<p>Use the Kong Ingress external IP or CNAME to configure your the domain name resolution as explained at Knative's documentation.</p> <p>In this example we are not configuring a real DNS but using free wildcard domain tools like sslip.io or nip.io</p> <pre><code>kubectl patch configmap/config-domain \\\n  --namespace knative-serving \\\n  --type merge \\\n  --patch '{\"data\":{\"35.141.22.45.nip.io\":\"\"}}'\n</code></pre> <p>Once this is done, the setup is complete.</p>","location":"guides/kong-ingress/#setup-knative-domain"},{"title":"Try It","text":"","location":"guides/kong-ingress/#try-it"},{"title":"Test Connectivity","text":"<p>Send a request to the configured domain and make sure that a 404 response is returned:</p> <pre><code>curl -i http://35.141.22.45.nip.io/\nHTTP/1.1 404 Not Found\nDate: Wed, 11 May 2022 12:01:21 GMT\nContent-Type: application/json; charset=utf-8\nConnection: keep-alive\nContent-Length: 48\nX-Kong-Response-Latency: 0\nServer: kong/2.8.1\n\n{\"message\":\"no Route matched with those values\"}\n</code></pre> <p>The 404 response is expected since we have not configured any services yet.</p>","location":"guides/kong-ingress/#test-connectivity"},{"title":"Test Service","text":"<p>Deploy a Knative Service:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: TriggerMesh\nEOF\n</code></pre> <p>Wait for the service to be ready, then get it's exposed URL. The URL should be a sub-domain of the configured CNAME:</p> <pre><code>kubectl get ksvc\nNAME            URL                                             LATESTCREATED         LATESTREADY           READY   REASON\nhelloworld-go   http://helloworld-go.default.35.141.22.45.nip.io   helloworld-go-00001   helloworld-go-00001   True\n</code></pre> <p>A call to the URL using a web browser or <code>curl</code> should return a successful text response:</p> <pre><code>curl -v http://helloworld-go.default.35.141.22.45.nip.io\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nContent-Length: 20\nConnection: keep-alive\nDate: Wed, 11 May 2022 12:10:26 GMT\nX-Kong-Upstream-Latency: 16\nX-Kong-Proxy-Latency: 1\nVia: kong/2.8.1\n\nHello TriggerMesh!\n</code></pre> <p>By inspecting the returned headers for the request above we can tell that it was proxied by Kong, latency headers being added to the response.</p>","location":"guides/kong-ingress/#test-service"},{"title":"Test Kong Plugins For Knative Services","text":"<p>Kong supports plugins to customize knative services requests and responses.</p> <p>First, let's create a KongPlugin resource:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: configuration.konghq.com/v1\nkind: KongPlugin\nmetadata:\n  name: add-response-header\nconfig:\n  add:\n    headers:\n    - 'demo: injected-by-kong'\nplugin: response-transformer\nEOF\n</code></pre> <p>Next, we will update the Knative service created before and add an annotation to the template:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    metadata:\n      annotations:\n        konghq.com/plugins: add-response-header\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: TriggerMesh\nEOF\n</code></pre>  <p>Kubernetes namespace</p> <p>Note that the annotation <code>konghq.com/plugins</code> is not added to the Service definition itself but to the <code>spec.template.metadata.annotations</code>.</p>  <p>Let's make the request again:</p> <pre><code>curl -i http://helloworld-go.default.35.241.22.45.nip.io/\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nContent-Length: 20\nConnection: keep-alive\nDate: Wed, 11 May 2022 13:48:53 GMT\ndemo:  injected-by-kong\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 0\nVia: kong/2.8.1\n\nHello TriggerMesh!\n</code></pre> <p>As we can see, the response has the <code>demo</code> header injected.</p>","location":"guides/kong-ingress/#test-kong-plugins-for-knative-services"},{"title":"Tips for using TriggerMesh on Kubernetes","text":"","location":"guides/kubernetestips/"},{"title":"Using kubectl explain","text":"<p>You can explore the specification of any TriggerMesh object using the <code>kubectl explain</code> command. For example applying the command to the AWS SQS Source, you will see that you need the ARN (i.e Amazon Resource Name) of your AWS SQS queue and the AWS API keys that give you access to SQS.</p> <pre><code>$ kubectl explain awssqssource.spec\nKIND:     AWSSQSSource\nVERSION:  sources.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the event source.\n\nFIELDS:\n   adapterOverrides     &lt;Object&gt;\n     Kubernetes object parameters to apply on top of default adapter values.\n\n   arn  &lt;string&gt; -required-\n     ARN of the Amazon SQS queue to consume messages from. The expected format\n     is documented at\n     https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies.\n\n   auth &lt;Object&gt;\n     Authentication method to interact with the Amazon SQS API.\n\n   endpoint     &lt;Object&gt;\n     Customizations of the AWS REST API endpoint.\n\n   messageProcessor     &lt;string&gt;\n     Name of the message processor to use for converting SQS messages to\n     CloudEvents. Supported values are \"default\" and \"s3\".\n\n   receiveOptions       &lt;Object&gt;\n     Options that control the behavior of message receivers.\n\n   sink &lt;Object&gt; -required-\n     The destination of events sourced from Amazon SQS.\n</code></pre>","location":"guides/kubernetestips/#using-kubectl-explain"},{"title":"Using Kuma Service Mesh with TriggerMesh","text":"<p>Kuma can be configured as a Service Mesh for TriggerMesh, providing security, observability and routing among other features.</p> <p>The steps in this article guide you through the installation and configuration process, referring to external links when information beyond this scope is needed.</p>","location":"guides/kuma/"},{"title":"Pre-requisites","text":"<p>Knative Serving needs to be installed on a Kubernetes cluster. We will also install Kong as the networking layer for Knative Serving since it is an ideal companion for Kuma.</p> <p>To install Knative Serving with Kong follow our guide at the documentation.</p> <p>This guide was written using:</p> <ul> <li>Kubernetes <code>v1.22</code></li> <li>Knative <code>v1.0.0</code></li> <li>Kong Ingress Controller <code>2.3.1</code> (includes Kong <code>2.8</code>)</li> <li>Kuma <code>v1.5</code></li> </ul>","location":"guides/kuma/#pre-requisites"},{"title":"Install Kuma Service Mesh","text":"<p>Kuma can be installed using their command line tool. Follow the instructions at the documentation to install <code>kumactl</code>.</p> <p>Once installed execute this command to deploy Kuma Service Mesh in the cluster.</p> <pre><code>kumactl install control-plane --version=1.5.0 --env-var KUMA_RUNTIME_KUBERNETES_VIRTUAL_PROBES_ENABLED=false| kubectl apply -f -\n</code></pre>  <p>Kuma Virtual Probes</p> <p>The command provided at this guide disables Kuma Virtual Probes. If you have an existing Kuma installation make sure virtual probes are disabled.</p>  <p>Once Kuma Service Mesh is installed you should see the pod running in the <code>kuma-system</code> namespace:</p> <pre><code>kumactl -n kuma-system get pods\nNAME                                 READY   STATUS    RESTARTS   AGE\nkuma-control-plane-bd98c89dc-kwj97   1/1     Running   0          19s\n</code></pre>","location":"guides/kuma/#install-kuma-service-mesh"},{"title":"Add Kong to Kuma Mesh","text":"<p>We will add the label <code>kuma.io/sidecar-injection</code> to the kong namespace, so kong will be running in the mesh:</p> <pre><code>kubectl label namespace kong kuma.io/sidecar-injection=enabled\n</code></pre> <p>The kong-ingress deployment needs the following annotation to be running as a Kuma gateway.</p> <pre><code>annotations: \n  kuma.io/gateway: enabled \n</code></pre> <p>Make sure that the annotation exists by issuing this command:</p> <pre><code>kubectl -n kong patch deploy ingress-kong --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/kuma.io~1gateway\", \"value\":\"enabled\"}]'\n</code></pre> <p>We should restart kong to be running in the mesh and acting as the kuma gateway.</p> <pre><code>kubectl -n kong rollout restart deployment ingress-kong\n</code></pre> <p>After the restart the respawned Kong pods will be running inside the Kuma mesh.</p>","location":"guides/kuma/#add-kong-to-kuma-mesh"},{"title":"Add Knative Serving to Kuma Mesh","text":"<p>We will add the label <code>kuma.io/sidecar-injection</code> to the knative-serving namespace, so knative-serving will be running in the mesh:</p> <pre><code>kubectl label namespace knative-serving kuma.io/sidecar-injection=enabled\n</code></pre>","location":"guides/kuma/#add-knative-serving-to-kuma-mesh"},{"title":"Configure Kuma service Mesh to Strict mode","text":"<p>Knative needs some pre-requisites to be able to work in the Kuma Mesh with mTLS set to <code>STRICT</code>. We are going to add some port-exclusions</p> <pre><code>kubectl -n knative-serving patch deploy webhook --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8443\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy domainmapping-webhook --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8443\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy autoscaler --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8080\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy activator --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8012\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy activator --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-outbound-ports\", \"value\":\"8080\"}]'\n</code></pre> <p>Now we should restart the only two pods that we haven't added the port-exclusion to add them to the mesh like the rest:</p> <pre><code>kubectl -n knative-serving rollout restart deployment controller domain-mapping\n</code></pre> <pre><code>kubectl -n knative-serving get pods\nNAME                                     READY   STATUS    RESTARTS   AGE\nactivator-554875ff7c-hqb8t               2/2     Running   0          69s\nautoscaler-698589b568-qrjk9              2/2     Running   0          78s\ncontroller-6956c9bb6-spqpm               2/2     Running   0          57s\ndomain-mapping-8548c6cfdf-m2m66          2/2     Running   0          57s\ndomainmapping-webhook-7ff76f9bfb-6jdgz   2/2     Running   0          81s\nwebhook-564974959d-vpd42                 2/2     Running   0          86s\n</code></pre> <p>Now the knative-serving pods are running in the mesh and ready to work with mtls Strict.</p>","location":"guides/kuma/#configure-kuma-service-mesh-to-strict-mode"},{"title":"Configure Kuma mTLS to Strict mode","text":"<p>We are going to modify the Kuma Mesh to enable the mTLS with Strict mode:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF                            \napiVersion: kuma.io/v1alpha1\nkind: Mesh\nmetadata:\n  name: default\nspec:\n  mtls:\n    enabledBackend: ca-1\n    backends:\n      - name: ca-1\n        type: builtin\n        mode: STRICT\nEOF\n</code></pre>","location":"guides/kuma/#configure-kuma-mtls-to-strict-mode"},{"title":"Test Service","text":"<p>Deploy a Knative Service:</p>  <p>Knative Services</p> <p>The knative services also needs port-exclusions</p>  <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    metadata:\n      annotations:\n        traffic.kuma.io/exclude-inbound-ports: \"8012\"\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: Go Sample v1\nEOF\n</code></pre> <p>Wait for the service to be ready, then get it's exposed URL. The URL should be a sub-domain of the configured CNAME:</p> <pre><code>kubectl get ksvc\nNAME URL LATESTCREATED LATESTREADY READY REASON\nhelloworld-go   http://helloworld-go.default.10.101.62.158.nip.io   helloworld-go-00001   helloworld-go-00001   True \n</code></pre> <p>A call to the URL using a web browser or <code>curl</code> should return a successful text response:</p> <pre><code>curl -v http://helloworld-go.default.10.101.62.158.nip.io\n*   Trying 10.101.62.158:80...\n* Connected to helloworld-go.default.10.101.62.158.nip.io (10.101.62.158) port 80 (#0)\n&gt; GET / HTTP/1.1\n&gt; Host: helloworld-go.default.10.101.62.158.nip.io\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 OK\n&lt; Content-Type: text/plain; charset=utf-8\n&lt; Content-Length: 20\n&lt; Connection: keep-alive\n&lt; Date: Wed, 30 Mar 2022 11:22:29 GMT\n&lt; X-Kong-Upstream-Latency: 1\n&lt; X-Kong-Proxy-Latency: 1\n&lt; Via: kong/2.7.1\n&lt; \nHello Go Sample v1!\n* Connection #0 to host helloworld-go.default.10.101.62.158.nip.io left intact\n</code></pre>","location":"guides/kuma/#test-service"},{"title":"Kuma UI","text":"<p>Kuma includes a dashboard that shows information about mesh, gateway and proxies status. You can use <code>kubectl</code> to forward the exposed port locally.</p> <pre><code>kubectl port-forward svc/kuma-control-plane -n kuma-system 5681:5681\n</code></pre> <p>To access the UI opening http://localhost:5681/gui with a web browser:</p> <p></p>","location":"guides/kuma/#kuma-ui"},{"title":"Component Scaling","text":"<p>TriggerMesh Components that are able to spin up replicas without leading to missing or duplicated events will scale under heavy load.</p> <p>In contrast those components whose external system imposes a model where multiple instances of a client are not allowed or require distributed coordination won't scale.</p> <p>As a general rule scaling per component type defaults to:</p>    Type Scalable Exceptions     Source No SlackSource, TwilioSource, WebhookSource and ZendeskSource   Target Yes    Transformation Yes    Routing Yes      <p>Tip</p> <p>When a component that does not support scaling reaches its maximum capacity it is usually a good practice to partition the external service/data and configure multiple components.</p>","location":"guides/scaling/"},{"title":"Scaling behavior","text":"<p>Scaling components are configured with the following parameters:</p> <ul> <li>Scaler metrics: requests per second (RPS).</li> <li>Minimum scale: 0, allows scale to zero.</li> <li>Maximum scale: 30 instances.</li> <li>Scale down delay: 5m, an scaled up instance will wait for 5m before being considered for retiring.</li> <li>Requests per second: 300.</li> <li>Time window: 1m, the window to aggregate metrics and take actions.</li> </ul> <p>As an example a load test for a single TriggerMesh component looks like this:</p>  <p>Scale to 0</p> <p>Components that are able to scale are also able to scale to zero, saving resources when there is no load. A scaled to zero component can still receive data, that will be buffered by an activator agent while the backend is created (which usually takes ~ 1 second).</p> <p>A component that has received no data for the last minute is a candidate for downscaling.</p>   <p>Example</p> <p></p> <ul> <li>Ramp up: the load for the first half of the test, the autoscaler creates replicas of the component based on demand.</li> <li>Stabilizing requests: there are some adjustments but the number of replicas is kept around 16 in the example.</li> <li>Ramp down: replicas start to be removed as long as they are not needed.</li> <li>Zero load: replicas are kept for 5 minutes receiving no requests, then they are removed.</li> </ul>","location":"guides/scaling/#scaling-behavior"},{"title":"Creating a PrivateLink to TriggerMesh Services","text":"<p>PrivateLink is a service that enables you to establish private connectivity  between VPCs and services hosted on Amazon Web Services (AWS) or on-premises,  without exposing data to the internet. Let\u2019s look at the configuration required to access TriggerMesh services deployed on an AWS Elastic Kubernetes Service (AWS)  cluster across AWS accounts over a PrivateLink connection.</p>","location":"guides/triggermesh-privatelink/"},{"title":"Configuring the Istio Ingress Gateway","text":"<p>The Istio networking layer (or others such as Kourier) creates an Elastic Load  Balancer (ELB) allowing public access to the TriggerMesh services running in the cluster.  However, let\u2019s consider a use-case where we want to disable the public access and  instead make the services accessible over a PrivateLink. </p> <p>The first thing we need to do is to configure the Istio Ingress Gateway to use  a Network Load Balancer (NLB) instead of an ELB using the annotation  <code>service.beta.kubernetes.io/aws-load-balancer-type: nlb</code> and to specify that  the NLB will be internal we need to add the annotation  <code>service.beta.kubernetes.io/aws-load-balancer-internal: internal</code> as shown in  the snippet below:</p> <pre><code>apiVersion: install.istio.io/v1alpha1\nkind: IstioOperator\n...\nspec:\n  ...\n  components:\n    ingressGateways:\n    - enabled: true\n      name: istio-ingressgateway\n      k8s:\n        serviceAnnotations:\n          service.beta.kubernetes.io/aws-load-balancer-internal: \"true\"\n          service.beta.kubernetes.io/aws-load-balancer-type: nlb\n</code></pre> <p>After the configuration has been applied successfully, we can see that the Istio  Ingress Gateway is now using an NLB as shown in the screenshot below:</p> <p></p>","location":"guides/triggermesh-privatelink/#configuring-the-istio-ingress-gateway"},{"title":"Setting up the PrivateLink endpoint service","text":"<p>Before we set up the PrivateLink, let\u2019s make sure that the VPC to which our EKS  cluster is attached has the DNS hostnames feature enabled. This is needed in order  to be able to access our TriggerMesh services using the URL configured for the services.</p> <p></p> <p>To set up the service endpoint, we need to login to the AWS console and create an endpoint service. Let\u2019s specify the Name as  ksvc-endpoint-service, Load balancer type as Network and select the NLB  that is associated with our Istio Ingress Gateway.</p> <p>In the Additional settings section we need to enable the private DNS name  configuration and specify the domain name associated with our TriggerMesh services.  For example, if the domain of our Knative serving component is <code>k.acme.com</code>,  then specify the wildcard domain <code>*.k.acme.com</code> as the Private DNS name as  shown in the screenshot below:</p> <p></p> <p>Before we can start accessing the TriggerMesh endpoints using the Private DNS name,  we need to verify ownership of the domain name. To do so we need to create a TXT  record in our domain host with the Domain verification name and  Domain verification value and trigger the verification as shown in screenshot  below:</p> <p></p> <p>After the verification has been completed, the Domain verification status changes  to Verified and we should now be able to reach our TriggerMesh services using the service  URL.</p>","location":"guides/triggermesh-privatelink/#setting-up-the-privatelink-endpoint-service"},{"title":"Connecting to the endpoint service","text":"<p>Now that we have the services exposed on a VPC endpoint service, we can now access  the TriggerMesh services from another VPC in the same AWS account as well as  from another AWS account. Let\u2019s try accessing the TriggerMesh services from another  AWS account.</p> <p>To allow access to the service endpoint we need to first add the Amazon Resource  Name (ARN) of the AWS root account under the Allow Principals tab. This is the  ARN of the account from where we will be accessing the services, let's call this  the consumer.</p> <p></p> <p>Login to the VPC dashboard of the AWS account of the consumer and create an endpoint  connection. It\u2019s important to note that you need to be in the same region as the endpoint service in order to establish a PrivateLink connection.</p> <p>Let\u2019s name the endpoint connection ksvc-endpoint, for the Service category choose  Other endpoint services, enter the Service name of our service endpoint and click  on Verify service.</p> <p></p> <p>Select the VPC and Subnets on which you want to make the endpoint connection  available and finally specify the security groups to associate with the endpoint.  We need to ensure that our security group allows HTTP/HTTPS connection requests  as shown in the screenshot below:</p> <p></p> <p>Upon creating the endpoint, we need to go back to the VPC service endpoint and  accept the connection request.</p> <p></p> <p>Once the connection request has been accepted it takes a few minutes for the  endpoint connection to become Available in the consumer account. Lastly, in order  to access the TriggerMesh services using their URLs, we need to Enable private DNS  names which is available under the Modify private DNS name action menu item of  the endpoint connection as shown below:</p> <p></p>","location":"guides/triggermesh-privatelink/#connecting-to-the-endpoint-service"},{"title":"Accessing TriggerMesh services","text":"<p>To access the TriggerMesh services via the PrivateLink, we can create an EC2 instance,  in the consumers AWS account, on the same VPC in which the endpoint was created  and use cURL to reach the TriggerMesh service endpoints.</p> <p>For demonstration, I have deployed the TriggerMesh WebhookSource in the EKS cluster and the URL for the service is http://webhook.k.acme.com. This endpoint  can now simply be reached from the EC2 instance as shown below:</p> <pre><code>$ curl -d '{\"foo\": \"bar\"}' -H \"Content-Type: application/json\" http://webhook.k.acme.com\n</code></pre>","location":"guides/triggermesh-privatelink/#accessing-triggermesh-services"},{"title":"Writing a Webhook to Slack Bridge","text":"<p>This Bridge connects an HTTP endpoint to Slack. Every time the webhook is called a message will be produced, which we will validate and transform into an Slack message.</p> <p>We will be calling the exposed HTTP endpoint using <code>curl</code>, in a real world scenario the caller would be an application configuring a webhook callback.</p>","location":"guides/webhook-to-slack/"},{"title":"Events","text":"<p>Webhook Source produce arbitrary events based on configuration and received requests.</p> <ul> <li><code>type</code> attribute is set to the one configured by user.</li> <li><code>source</code> attribute is set to the one configured by user.</li> <li><code>datacontenttype</code> is set to the <code>Content-Type</code> received at the incoming request.</li> <li><code>data</code> is set to the body of the received request.</li> </ul> <p>Slack Target expect one of these 3 event types along with their related payload:</p> <ul> <li><code>com.slack.webapi.chat.postMessage</code> for consuming chat.postMessage</li> <li><code>com.slack.webapi.chat.scheduleMessage</code> for consuming chat.scheduleMessage</li> <li><code>com.slack.webapi.chat.update</code> for consuming chat.update</li> </ul> <p>This fictional scenario will send the following data to the Webhook Source using <code>curl</code>. <pre><code>{\"message\": \"Hello Slack!\"}\n</code></pre></p> <p>The Webhook Source is expected to produce this event.</p> <pre><code>type: webhook.slack.postmessage\ndata: {\"message\": \"Hello Slack!\"}\nothers: ...\n</code></pre> <p>We will be using TriggerMesh's Function to perform a transformation which will consume the event above and produce this one.</p> <pre><code>type: com.slack.webapi.chat.postMessage\ndata: {\"channel\":\"ABCDE12345\", \"text\": \"Hello Slack!\"}\nothers: ...\n</code></pre> <p>This event will finally be consumed by the Slack Target that will in turn call the Slack API to post the message.</p>","location":"guides/webhook-to-slack/#events"},{"title":"Webhook Source","text":"<p>For simplicity we are setting up a non authenticated Webhook and using the default Kubernetes namespace.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: WebhookSource\nmetadata:\n  name: post-message\nspec:\n  eventType: webhook.slack.postmessage\n  eventSource: webhook.post-message\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>The <code>eventType</code> and <code>eventSource</code> CloudEvents attributes are being set for further event filtering. There is a reference to a Broker sink object where events will be sent, we will get to that one later.</p>","location":"guides/webhook-to-slack/#webhook-source"},{"title":"Slack Target","text":"<p>Slack Target requires:</p> <ul> <li>Creating a new Slack App: add the <code>chat:write</code> permission under <code>Bot Token Scopes</code>, then install the application at your workspace.</li> <li>A Slack API token: from the Install App menu retrieve the OAuth Access token that begins with <code>xoxb-</code>.</li> </ul> <p>Create a secret using the Slack API token</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: slack-tm\ntype: Opaque\nstringData:\n  token: xoxb-12345-abcde\n</code></pre> <p>Create the Slack Target referencing the API token.</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SlackTarget\nmetadata:\n  name: slack-tm\nspec:\n  token:\n    secretKeyRef:\n      name: slack-tm\n      key: token\n</code></pre>","location":"guides/webhook-to-slack/#slack-target"},{"title":"Transformation Component","text":"<p>To bridge the gap between the event produced by the Webhook Source and the one expected at the Slack Target we need to perform a transformation, which we can do using a declarative or coded approach. We will use the later here.</p> <p>Replace the channel ID in this transformation with the one you want to use. The channel ID can be retrieved from the URL either at the browser or selecting the <code>copy link</code> option at the Slack app. Please make sure that the bot user is added to the Slack channel.</p> <pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: webhook-to-slack\nspec:\n  runtime: python\n  public: false\n  entrypoint: transformToSlack\n  ceOverrides:\n    extensions:\n      type: com.slack.webapi.chat.postMessage\n  code: |\n    from random import randrange\n\n    def transformToSlack(event, context):\n      return {\n        \"channel\":\"REPLACE-CHANNEL-ID\",\n        \"text\": event['message']\n      }\n</code></pre>","location":"guides/webhook-to-slack/#transformation-component"},{"title":"Routing Components","text":"<p>In order to connect all components we will setup these elements:</p> <ul> <li>A central Broker that receives messages from the Source</li> <li>A Trigger that consumes Webhook events filtered by the <code>webhook.slack.postmessage</code> type and sends them to the transformation Function.</li> <li>A Trigger that consumes transformed events filtered by the <code>com.slack.webapi.chat.postMessage</code> type and sends them to the Slack target.</li> </ul> <p>The Broker name is set to <code>default</code> to match the one used at the Webhook Source earlier.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: default\n</code></pre> <p>Both Triggers are setup on the Broker and subscribe their corresponding destination filtering by types.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: webhook-to-transform\nspec:\n  broker: default\n  filter:\n    attributes:\n      type: webhook.slack.postmessage\n  subscriber:\n    ref:\n      apiVersion: extensions.triggermesh.io/v1alpha1\n      kind: Function\n      name: webhook-to-slack\n\n---\n\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: slack-post-messages\nspec:\n  broker: default\n  filter:\n    attributes:\n      type: com.slack.webapi.chat.postMessage\n  subscriber:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: SlackTarget\n      name: slack-tm\n</code></pre>","location":"guides/webhook-to-slack/#routing-components"},{"title":"Done","text":"<p>Retrieve the URL where the Webhook is listening for incoming requests.</p> <pre><code>$ kubectl get webhooksources.sources.triggermesh.io post-message\nNAME           READY   REASON   URL                                                                  SINK                                                                            AGE\npost-message   True             https://webhooksource-post-message.woodford.dev.triggermesh.io   http://broker-ingress.knative-eventing.svc.cluster.local/woodford/default   61s\n</code></pre> <p>Use <code>curl</code> or any HTTP capable client to post messages at Slack.</p> <pre><code>curl -d '{\"message\":\"test my bridge\"}' https://webhooksource-post-message.woodford.dev.triggermesh.io\n</code></pre> <p>This Bridge can be extended in many different ways:</p> <ul> <li>Validation and error handling at the transformation Function.</li> <li>The Channel could be provided as a parameter from the WebhookSource, defaulting to a channel provided by the Function.</li> <li>AWS Comprehend could be used for sentiment analysis.</li> <li>Messages could be enriched if they contain word <code>avocado</code> with \ud83e\udd51</li> <li>Add a Twilio Source that will also feed incoming messages to the Broker.</li> <li>Add a Datadog Target that will convert a subset of filtered messages into alerts.</li> </ul> <p>If you have any questions on how to build this Bridge or how to modify it to suit your needs, join our Community Slack and contact us.</p>","location":"guides/webhook-to-slack/#done"},{"title":"Install TriggerMesh","text":"<p>The are two main TriggerMesh installables: <code>tmctl</code>, and TriggerMesh on Kubernetes.</p>","location":"installation/"},{"title":"Install <code>tmctl</code>","text":"<p>If you are new to TriggerMesh or if you are not familiar with Kubernetes we recommend that you start your journey with <code>tmctl</code>, the TriggerMesh CLI that that makes it easy to work with events on a laptop and only requires Docker. It lets you author event flows with objects like Sources, Brokers, and Targets, and handles running all the necessary components. <code>tmctl</code> can be installed using Homebrew or other methods.</p> <p>To install and get started with <code>tmctl</code>, we recommend starting with the quickstart that will take you through installation and creating your first event flows in a few minutes.</p>","location":"installation/#install-tmctl"},{"title":"TriggerMesh on Kubernetes","text":"<p>TriggerMesh can run natively on Kubernetes and we provide the custom resource definitions (CRDs) and controllers for you to install on any Kubernetes cluster. Once installed, you can configure TriggerMesh objects like Sources, Brokers, and Targets using K8s manifests and they'll just work.</p> <p>You can install TriggerMesh on Kubernetes with our Helm charts or with our YAML Kubernetes manifests.</p> <p>If you're curious about the relationship between TriggerMesh and Knative, please head here.</p>","location":"installation/#triggermesh-on-kubernetes"},{"title":"Install TriggerMesh on Kubernetes with Helm","text":"<p>This guide takes you through installing TriggerMesh on a Kubernetes cluster using our provided Helm charts. The Charts will install the required TriggerMesh custom resource definitions (CRDs) and controllers onto your cluster.</p>","location":"installation/kubernetes-helm/"},{"title":"Prerequisites","text":"<ul> <li>Kubernetes <code>v1.22+</code></li> <li>Knative Serving <code>v1.0.0+</code></li> <li>Helm <code>3.0+</code></li> </ul>","location":"installation/kubernetes-helm/#prerequisites"},{"title":"Installing Knative Serving","text":"<p>TriggerMesh relies on Knative Serving to run some of its components as Knative Services. We plan to relax this dependency in the near future.</p> <p>Please refer to the official Knative Serving installation instructions. Knative Eventing is not a prerequisite for TriggerMesh to run, but we do provide compatibility for Knative Eventing users.</p>","location":"installation/kubernetes-helm/#installing-knative-serving"},{"title":"Installing the Chart","text":"<p>Add the TriggerMesh chart repository to Helm:</p> <pre><code>helm repo add triggermesh https://storage.googleapis.com/triggermesh-charts\n</code></pre> <p>To install the chart with the release name <code>triggermesh</code>:</p> <pre><code>helm install -n triggermesh triggermesh triggermesh/triggermesh --create-namespace\n</code></pre> <p>The command deploys the TriggerMesh open-source components and uses the default configuration that can be adapted depending on your needs.</p>  <p>Doesn't work?</p> <p>Please let us know by filing a GitHub issue.</p>","location":"installation/kubernetes-helm/#installing-the-chart"},{"title":"Uninstalling the Chart","text":"<p>To uninstall the <code>triggermesh</code> deployment:</p> <pre><code>helm uninstall triggermesh -n triggermesh\n</code></pre> <p>The Kubernetes resources associated with chart will be removed and the Helm release will be deleted.</p>","location":"installation/kubernetes-helm/#uninstalling-the-chart"},{"title":"Configuration","text":"Parameter Description Default     <code>nameOverride</code> Override the name for controller resources <code>\"\"</code>   <code>fullnameOverride</code> Override the fullname for controller resources <code>\"\"</code>   <code>image.registry</code> Image registry name <code>gcr.io/triggermesh</code>   <code>image.tag</code> Image tag <code>.Chart.AppVersion</code>   <code>image.pullPolicy</code> Image pull policy <code>IfNotPresent</code>   <code>imagePullSecrets</code> Specify image pull secrets <code>[]</code>   <code>replicaCount</code> Number of replicas <code>1</code>   <code>rbac.create</code> Create RBAC resources <code>true</code>   <code>serviceAccount.create</code> Create service account for the controller <code>true</code>   <code>serviceAccount.annotations</code> Annotations to add to controller service account <code>{}</code>   <code>serviceAccount.name</code> Override the name for the service account <code>nil</code>   <code>podAnnotations</code> Annotations to add to the controller pod <code>{}</code>   <code>podSecurityContext</code> Security context for controller pods <code>{}</code>   <code>securityContext</code> Security context for controller containers <code>{}</code>   <code>resources</code> Resource requests/limits for the controller <code>{}</code>   <code>nodeSelector</code> Controller node selector <code>{}</code>   <code>tolerations</code> Tolerations for use with node taints <code>[]</code>   <code>affinity</code> Assign custom affinity rules to the controller pods <code>{}</code>   <code>webhook.podAnnotations</code> Annotations to add to the webhook pod <code>{sidecar.istio.io/inject: 'false'}</code>   <code>webhook.podSecurityContext</code> Security context for webhook pods <code>{}</code>   <code>webhook.securityContext</code> Security context for webhook containers <code>{}</code>   <code>webhook.resources</code> Resource requests/limits for the webhook <code>{}</code>   <code>webhook.nodeSelector</code> Webhook node selector <code>{}</code>   <code>webhook.tolerations</code> Tolerations for use with node taints <code>[]</code>   <code>webhook.affinity</code> Assign custom affinity rules to the webhook pods <code>{}</code>","location":"installation/kubernetes-helm/#configuration"},{"title":"Install TriggerMesh Components on Kubernetes with YAML","text":"<p>This guide takes you through installing TriggerMesh on a Kubernetes cluster by using our provided YAML manifests. The manifests will install the required TriggerMesh custom resource definitions (CRDs) and controllers onto your cluster.</p>","location":"installation/kubernetes-yaml/"},{"title":"Pre-requisites","text":"<ul> <li>A Kubernetes cluster version <code>v1.22+</code></li> <li>Knative Serving <code>v1.0.0+</code></li> </ul>","location":"installation/kubernetes-yaml/#pre-requisites"},{"title":"Installing Knative Serving","text":"<p>TriggerMesh relies on Knative Serving to run some of its components as Knative Services. We plan to relax this dependency in the near future.</p> <p>Please refer to the official Knative Serving installation instructions. Knative Eventing is not a prerequisite for TriggerMesh to run, but we do provide compatibility for Knative Eventing users.</p>","location":"installation/kubernetes-yaml/#installing-knative-serving"},{"title":"Install the CRDs","text":"<p>All TriggerMesh APIs are implemented as Kubernetes CRDs, which we need to create before deploying the controller. The following <code>kubectl apply</code> command will create all of the CRDs.</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh-core/releases/latest/download/triggermesh-core-crds.yaml\nkubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh-crds.yaml\n</code></pre>","location":"installation/kubernetes-yaml/#install-the-crds"},{"title":"Install the controllers","text":"<p>By default, the controllers are deployed in the <code>triggermesh</code> namespace. Deploy the controllers with the following <code>kubectl apply</code> command:</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh-core/releases/latest/download/triggermesh-core.yaml\nkubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh.yaml\n</code></pre>","location":"installation/kubernetes-yaml/#install-the-controllers"},{"title":"Verifying the installation","text":"<p>Upon successful creation of the CRDs and successful deployment of the controller you should see three pods running in the <code>triggermesh</code> namespace</p> <pre><code>$ kubectl get pods -n triggermesh\nNAME                                                   READY   STATUS    RESTARTS   AGE\ntriggermesh-controller-5cd97f4c8f-z6r2r                1/1     Running   0          57m\ntriggermesh-webhook-79cd8d6f5d-gf2lj                   1/1     Running   0          57m\ntriggermesh-core-controller-64c588d74c-jpr42           1/1     Running   0          57m\n</code></pre> <p>All event sources and targets will be available to you as new API objects. For example, you can list all AWS related sources and targets with:</p> <pre><code>$ kubectl get crds |grep triggermesh |grep aws\nawscloudwatchlogssources.sources.triggermesh.io         2021-10-06T09:01:27Z\nawscloudwatchsources.sources.triggermesh.io             2021-10-06T09:01:27Z\nawscodecommitsources.sources.triggermesh.io             2021-10-06T09:01:27Z\nawscognitoidentitysources.sources.triggermesh.io        2021-10-06T09:01:27Z\nawscognitouserpoolsources.sources.triggermesh.io        2021-10-06T09:01:27Z\nawscomprehendtargets.targets.triggermesh.io             2021-10-06T09:01:28Z\nawsdynamodbsources.sources.triggermesh.io               2021-10-06T09:01:28Z\nawsdynamodbtargets.targets.triggermesh.io               2021-10-06T09:01:28Z\nawseventbridgetargets.targets.triggermesh.io            2021-10-06T09:01:28Z\nawskinesissources.sources.triggermesh.io                2021-10-06T09:01:28Z\nawskinesistargets.targets.triggermesh.io                2021-10-06T09:01:29Z\nawslambdatargets.targets.triggermesh.io                 2021-10-06T09:01:29Z\nawsperformanceinsightssources.sources.triggermesh.io    2021-10-06T09:01:29Z\nawss3sources.sources.triggermesh.io                     2021-10-06T09:01:29Z\nawss3targets.targets.triggermesh.io                     2021-10-06T09:01:29Z\nawssnssources.sources.triggermesh.io                    2021-10-06T09:01:30Z\nawssnstargets.targets.triggermesh.io                    2021-10-06T09:01:30Z\nawssqssources.sources.triggermesh.io                    2021-10-06T09:01:30Z\nawssqstargets.targets.triggermesh.io                    2021-10-06T09:01:30Z\n</code></pre>","location":"installation/kubernetes-yaml/#verifying-the-installation"},{"title":"Installing <code>tmctl</code>","text":"<p>Please refer to the quickstart guide to install <code>tmctl</code>, the TriggerMesh command line interface.</p>","location":"installation/tmctl/"},{"title":"TriggerMesh and Knative","text":"<p>TriggerMesh depends on Knative Serving to run on Kubernetes, but Knative Eventing is optional. You can either use the provided, self-contained TriggerMesh eventing components which are the Broker and their Triggers, or you can choose to use Knative Eventing Brokers and Triggers. By default, TriggerMesh installations will use the new TriggerMesh Broker and Trigger, whether locally with <code>tmctl</code> or on Kubernetes.</p>  <p></p>","location":"installation/triggermesh-knative/"},{"title":"Why does TriggerMesh need Knative Serving on Kubernetes?","text":"<p>TriggerMesh sources and targets use Knative Serving to run as addressable services and to scale.</p>","location":"installation/triggermesh-knative/#why-does-triggermesh-need-knative-serving-on-kubernetes"},{"title":"How to use TriggerMesh with Knative Eventing?","text":"<p>If you want to, you can use the Brokers and Triggers from Knative Eventing instead of those provided by TriggerMesh.</p> <p>To do this, you'll want to avoid installing the TriggerMesh Brokers and Triggers on Kubernetes, and instead install Knative Eventing.</p> <p>First you'll need to have Knative Eventing and Serving installed on your cluster.</p>","location":"installation/triggermesh-knative/#how-to-use-triggermesh-with-knative-eventing"},{"title":"With YAML","text":"","location":"installation/triggermesh-knative/#with-yaml"},{"title":"Install the CRDs","text":"<p>All TriggerMesh APIs are implemented as Kubernetes CRDs, which we need to create before deploying the controller. The following <code>kubectl apply</code> command will create all of the CRDs. We're intentionally omitting <code>triggermesh-core</code> here.</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh-crds.yaml\n</code></pre>","location":"installation/triggermesh-knative/#install-the-crds"},{"title":"Install the controllers","text":"<p>By default, the controllers are deployed in the <code>triggermesh</code> namespace. Deploy the controllers with the following <code>kubectl apply</code> command. We're intentionally omitting <code>triggermesh-core</code> here.</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh.yaml\n</code></pre>","location":"installation/triggermesh-knative/#install-the-controllers"},{"title":"With HELM","text":"<p>Add the TriggerMesh chart repository to Helm:</p> <pre><code>helm repo add triggermesh https://storage.googleapis.com/triggermesh-charts\n</code></pre> <p>To install the chart with the release name <code>triggermesh</code>:</p> <pre><code>helm install -n triggermesh triggermesh triggermesh/triggermesh --set triggermesh-core.enabled=false --create-namespace\n</code></pre> <p>This command specifically omits <code>triggermesh-core</code>, so that is doesn't install the TriggerMesh Brokers and Triggers.</p>","location":"installation/triggermesh-knative/#with-helm"},{"title":"Using <code>tmctl</code> with Knative","text":"<p>When using <code>tmctl</code>, you can run <code>tmctl dump --knative</code> which will export a Kubernetes manifest that uses the Knative Eventing Brokers and Triggers instead of those provided by TriggerMesh.</p>","location":"installation/triggermesh-knative/#using-tmctl-with-knative"},{"title":"Observability","text":"<p>The TriggerMesh platform provides operational and usage insight into its various components via two types of instrumentations:</p> <ul> <li>Structured logging</li> <li>Telemetry metrics</li> </ul> <p>This observability data can be consumed and visualized using industry standard monitoring solutions.</p>","location":"observability/"},{"title":"Broker observability","text":"<p>A Broker will be configured with custom logger settings and exposing metrics for Prometheus.</p>","location":"observability/brokerobservability/"},{"title":"Instructions","text":"<p>The solution will include:</p> <ul> <li>RedisBroker, that will accept and deliver events.</li> <li>ConfigMap that contains observability settings.</li> <li>Trigger, which subscribes to events and push them to a configured target.</li> <li>Target that consumes events.</li> </ul>","location":"observability/brokerobservability/#instructions"},{"title":"Broker and Prometheus","text":"<p>Create a ConfigMap that enables prometheus metrics at port 9090.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/config-observability.yaml\n</code></pre> <p>Create a RedisBroker named <code>metrics-demo</code>.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/broker.yaml\n</code></pre> <p>Wait until the RedisBroker is ready. It will inform in its status of the URL where events can be ingested.</p> <pre><code>kubectl get redisbroker metrics-demo\n\nNAME   URL                                                        AGE   READY   REASON\ndemo   http://metrics-demo-rb-broker.default.svc.cluster.local   10s   True\n</code></pre> <p>Prometheus can be easily installed following one of this methods:</p> <ul> <li>Helm Charts.</li> <li>Prometheus Operator</li> <li>Kube Prometheus manifests and scripts</li> </ul> <p>All TriggerMesh Broker Pods expose the metrics port and are labeled like this.</p> <pre><code>  labels:\n    app.kubernetes.io/component: broker-deployment\n    app.kubernetes.io/managed-by: triggermesh-core\n    app.kubernetes.io/part-of: triggermesh\n...\n    ports:\n    - containerPort: 9090\n      name: metrics\n</code></pre> <p>Configure the Prometheus scrape to use the additional Pod monitors.</p> <pre><code>  additionalPodMonitors:\n\n  - name: triggermesh-components\n    jobLabel: app.kubernetes.io/name\n    namespaceSelector:\n      any: true\n    selector:\n      matchLabels:\n        app.kubernetes.io/part-of: triggermesh\n    podMetricsEndpoints:\n    - port: metrics\n</code></pre> <p>Refer to the Prometheus deployment method to access Grafana. When using the Helm chart, port-forwarding the grafana service and using the credentials from the <code>monitoring/kube-prometheus-stack-grafana</code> secret will.</p> <pre><code>kubectl -n monitoring port-forward svc/kube-prometheus-stack-grafana 3000:80\n</code></pre> <pre><code>kubectl -n monitoring get secret kube-prometheus-stack-grafana -o jsonpath='{.data.admin-user}' | base64 -d\n\nkubectl -n monitoring get secret kube-prometheus-stack-grafana -o jsonpath='{.data.admin-password}' | base64 -d\n</code></pre>","location":"observability/brokerobservability/#broker-and-prometheus"},{"title":"Ingest Metrics","text":"<p>To be able to use the broker we will create a Pod that allow us to send events inside the Kubernetes cluster.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre> <p>It is possible now to send events to the broker address by issuing curl commands. The response for ingested events must be an <code>HTTP 200</code> which means that the broker has received it and will try to deliver them to configured triggers.</p> <pre><code>kubectl exec -ti curl -- curl -v http://metrics-demo-rb-broker.default.svc.cluster.local/ \\\n    -X POST \\\n    -H \"Ce-Id: 1234-abcd\" \\\n    -H \"Ce-Specversion: 1.0\" \\\n    -H \"Ce-Type: demo.metrics1\" \\\n    -H \"Ce-Source: curl\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test1\":\"ingress\"}'\n</code></pre> <p>Use different <code>Ce-Type</code> values and send a number of event requests to be ingested by the broker, then open Grafana's metrics explorer and show <code>broker_ingest_event_count</code> metrics.</p> <p></p> <p>Incoming requests expose metrics:</p> <ul> <li><code>broker_ingest_event_count</code> for a global count of incoming requests.</li> <li><code>broker_ingest_event_latency_bucket</code> for the incoming requests latencies bucket.</li> </ul>","location":"observability/brokerobservability/#ingest-metrics"},{"title":"Trigger Metrics","text":"<p>We will create a target service and a Trigger pointing to it in order to gather Trigger metrics.</p> <pre><code># Event display service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml\n\n# Trigger using event display service\nkubectl apply -f https://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/trigger.yaml\n</code></pre> <p>The Trigger configures a filter that will deliver any event whose type is prefixed <code>demo.</code></p> <pre><code>spec:\n  broker:\n    kind: RedisBroker\n    group: eventing.triggermesh.io\n    name: metrics-demo\n  filters:\n  - any:\n    - prefix:\n        type: demo.\n</code></pre> <p>Just as before, use the <code>curl</code> pod to produce events with different <code>Ce-Type</code> values that start with <code>demo.</code>. Then use Grafana's  metrics explorer and show <code>broker_ingest_event_count</code> metrics.</p> <p></p> <p>Incoming requests expose metrics:</p> <ul> <li><code>broker_trigger_event_count</code> for a global count of outgoing events.</li> <li><code>broker_trigger_event_latency_bucket</code> for the outgoing events latencies bucket.</li> </ul>","location":"observability/brokerobservability/#trigger-metrics"},{"title":"Clean Up","text":"<p>To clean up the getting started guide, delete each of the created assets:</p> <pre><code># Removal of display-target not in this list, since it was deleted previously.\nkubectl delete -f \\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/trigger.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/display-target.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/broker.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/observability/config-observability.yaml,\\\nhttps://raw.githubusercontent.com/triggermesh/triggermesh-core/main/docs/assets/manifests/common/curl.yaml\n</code></pre>","location":"observability/brokerobservability/#clean-up"},{"title":"Structured Logging","text":"<p>TriggerMesh components communicate their internal events through a flexible logging system. Output format, structure, and granularity are adjustable through a configuration file. Information produced by the TriggerMesh logging system can be collected and stored by a centralized log management platform, such as the ELK stack or AWS CloudWatch, and used for further processing.</p>","location":"observability/observability-logging/"},{"title":"Logging configuration","text":"","location":"observability/observability-logging/#logging-configuration"},{"title":"Log levels","text":"<p>Log level configuration allows you to adjust the amount and detail of the logs produced by the TriggerMesh components. Logging configuration parameters are set through the configmap in the system namespace and applied on TriggerMesh components across all cluster namespaces.</p> <p>Since TriggerMesh core components are heavily based on the Knative libraries, logging also complies with the upstream configuration approach described here.</p>","location":"observability/observability-logging/#log-levels"},{"title":"Level definitions","text":"<p>Log levels supported by TriggerMesh components are:</p> <ul> <li><code>debug</code> - fine-grained debugging</li> <li><code>info</code> - normal logging</li> <li><code>warn</code> - unexpected but non-critical errors</li> <li><code>error</code> - critical errors; unexpected during normal operation</li> <li><code>dpanic</code> - in debug mode, trigger a panic (crash)</li> <li><code>panic</code> - trigger a panic (crash)</li> <li><code>fatal</code> - immediately exit with exit status 1 (failure)</li> </ul> <p>Each logging level in this hierarchy includes all levels below, i.e. setting the <code>error</code> level will silence the output tagged as debug, info, and warn, but will keep error, panic, and fatal. Most information is produced at the <code>debug</code> level - it can come in handy during integration development and tests. In the <code>error</code> logging level nothing but errors that require the operator's attention is emitted. By default, all components are set to the <code>info</code> level that provides general initialization information and some additional outputs that may be useful for the operator.</p>","location":"observability/observability-logging/#level-definitions"},{"title":"Configuring log levels","text":"<p>TriggerMesh components log levels are currently set from the <code>config-logging</code> configmap in <code>triggermesh</code> namespace. To update the component\u2019s logging level, the configuration must be either edited in place by executing this command:</p> <pre><code>kubectl -n triggermesh edit configmap config-logging\n</code></pre> <p>Or it can be changed in the project\u2019s source and applied with:</p> <pre><code>kubectl apply -f config-logging.yaml\n</code></pre> <p>Components logging configuration is propagated through the containers environment and picked up at the initialization step, hence switching between levels may require resource re-creation.</p> <p>The sample configuration fragment below sets the individual log levels for some of the TriggerMesh resources:</p> <pre><code># Logging level overrides for the TriggerMesh control plane.\nloglevel.triggermesh-controller: error\nloglevel.triggermesh-webhook: error\n\n# Logging level overrides for TriggerMesh components.\n# The name of the logger is the Kubernetes kind of the component.\nloglevel.awss3target: debug\nloglevel.ibmmqsource: debug\nloglevel.transformation: debug\n</code></pre> <p>After we apply this configuration, TriggerMesh controller and webhook will switch to the <code>error</code> level, while all newly created AWS S3 targets, IBM MQ sources, and Transformations will have a <code>debug</code> logging level.</p>","location":"observability/observability-logging/#configuring-log-levels"},{"title":"Telemetry Metrics","text":"<p>Metrics allow operators to understand the internal state of a system by observing its outputs.</p> <p>In TriggerMesh, telemetry is achieved by exposing a variety of time-based numeric measurements \u2014 also referred to as time-series \u2014 that can be collected and analyzed by third-party monitoring solutions.</p> <p>This guide provides an overview of the nature and format of the telemetry metrics exposed by the TriggerMesh platform, as well as detailed examples of approaches for collecting and analyzing them.</p>","location":"observability/observability-metrics/"},{"title":"Exposed Telemetry Data","text":"","location":"observability/observability-metrics/#exposed-telemetry-data"},{"title":"Metrics Categories","text":"<p>Here is an overview of the types of metrics that are exposed by TriggerMesh components. The list is deliberately broad and generic, as some categories of metrics may only be exposed by certain types of components.</p> <ul> <li>Processing of events<ul> <li>Successes and errors</li> <li>Latency distribution</li> </ul> </li> <li>Delivery of events<ul> <li>Successes and errors</li> <li>Latency distribution</li> </ul> </li> <li>Software runtime<ul> <li>Heap memory usage</li> <li>Garbage collection</li> </ul> </li> </ul> <p>Later in this document, we will explore how metrics in these different categories can be collected, analyzed and visualized.</p>","location":"observability/observability-metrics/#metrics-categories"},{"title":"Data Model","text":"<p>Metrics are exposed by TriggerMesh in a line-oriented text-based format popularized by the Prometheus open source monitoring toolkit.</p> <p>A Prometheus metric is typically represented as a single line of UTF-8 characters, optionally prepended with a <code>HELP</code> and a <code>TYPE</code> comment lines, starting with the name of the metric and ending with its value:</p> <pre><code># HELP event_processing_success_count The number of events successfully processed\n# TYPE event_processing_success_count counter\nevent_processing_success_count{event_source=\"my.cloud.storage\", event_type=\"object.created\"} 129389\n</code></pre> <p>The <code>HELP</code> comment provides a description of what the metric represents, whereas the <code>TYPE</code> comment carries information about the type of the metric (one of the four core metric types offered by Prometheus).</p> <p>As illustrated in the example above, the metric name may be directly followed by a list of comma-separated key-value pairs between curly brackets called labels. Labels allow differentiating the characteristics of what is being measured. Each unique combination of labels identifies a particular dimension of a metric. Labels, and metric dimensions by extension, vary from metric to metric.</p>","location":"observability/observability-metrics/#data-model"},{"title":"Enabling Metrics","text":"<p>By default TriggerMesh does not enable any metrics backend. Observability of TriggerMesh can be configured  via the <code>config-observability</code> ConfigMap object.</p> <p>For example, the following ConfigMap object enables the Prometheus metrics exporter in all TriggerMesh components:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: config-observability\n  namespace: triggermesh\ndata:\n  metrics.backend-destination: prometheus\n</code></pre> <p>For a description of the configuration settings which are currently supported, please refer to the  <code>observability.yaml</code> manifest files inside the Knative Eventing source repository.</p>","location":"observability/observability-metrics/#enabling-metrics"},{"title":"Access to Metrics","text":"<p>Every TriggerMesh component exposes a set of telemetry metrics on the local HTTP endpoint <code>:9092/metrics</code>. Available measurements can be retrieved via a simple <code>GET</code> request. The returned values are an instant view of each measurement at the time of the request.</p> <p>This model is particularly suitable for a pull-based retrieval of metrics (\"scrape\") on a fixed interval by monitoring software, and for storage in a time-series database. Prometheus itself is a popular choice for this job, as it includes both a server for scraping telemetry metrics, and a time-series database optimized for the Prometheus data model. </p> <p></p> <p>Most of the available metrics fall into the categories described previously in this document, whenever applicable based on the type of component. Some components may expose additional, application-specific metrics. The data model presented in the previous section makes these metrics easily discoverable by consumers.</p>","location":"observability/observability-metrics/#access-to-metrics"},{"title":"Collection and Analysis with Prometheus and Grafana","text":"<p>This section provides examples of configurations for collecting metrics from TriggerMesh components using the Prometheus monitoring toolkit, and visualizing them using the observability platform Grafana.</p> <p>The rest of this document assumes that Prometheus and Grafana are both available in the Kubernetes cluster where TriggerMesh is deployed.</p>  <p>Tip</p> <p>If you don't already have Prometheus and Grafana set up in your TriggerMesh cluster, we recommend installing a pre-configured Prometheus-Grafana stack using the Helm application manager for Kubernetes by executing the commands below:</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm install -n monitoring prometheus-stack prometheus-community/kube-prometheus-stack\n</code></pre> <p>Detailed installation instructions are available in the <code>kube-prometheus-stack</code> chart's documentation.</p>","location":"observability/observability-metrics/#collection-and-analysis-with-prometheus-and-grafana"},{"title":"Scraping Metrics via Prometheus","text":"<p>The Prometheus Operator \u2014 which is included in the aforementioned kube-prometheus Stack and manages most Prometheus installations on Kubernetes \u2014 allows configuring Prometheus' scrape targets using familiar Kubernetes API objects.</p> <p>The manifest below contains a PodMonitor that instructs Prometheus to automatically discover and scrape TriggerMesh components:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: triggermesh-components\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:  # (1)\n      app.kubernetes.io/part-of: triggermesh\n  namespaceSelector:  # (2)\n    any: true\n  podMetricsEndpoints:  # (3)\n  - port: metrics\n  - port: user-port\n    relabelings:\n    - action: replace\n      targetLabel: __address__\n      sourceLabels:\n      - __meta_kubernetes_pod_ip\n      replacement: $1:9092\n  jobLabel: app.kubernetes.io/name  # (4)\n</code></pre> <ol> <li>Selects all targets (Pods) that are labeled as being managed by TriggerMesh.</li> <li>Looks up targets (Pods) matching the above selector in all Kubernetes namespace.</li> <li>For targets that matched the above selectors, either scrape the port named <code>metrics</code> if it exists, or fall back to     the TCP port <code>9092</code>.</li> <li>Sets the value of the <code>job</code> label in collected metrics to the name of the component.</li> </ol> <p>After applying this configuration to the Kubernetes cluster using the <code>kubectl apply -f</code> command, a list of targets matching the name of the PodMonitor should be reported by Prometheus with the state <code>UP</code>.</p>  <p>Tip</p> <p>If you installed Prometheus via the <code>kube-prometheus-stack</code> Helm chart \u2014 as suggested in the introduction to this section \u2014 you should be able to forward the local port <code>9090</code> to the Prometheus instance running in the Kubernetes cluster:</p> <pre><code>kubectl -n monitoring port-forward svc/kube-prometheus-stack-prometheus 9090\n</code></pre> <p>Then, open your web browser at http://localhost:9090/targets.</p>  <p></p>","location":"observability/observability-metrics/#scraping-metrics-via-prometheus"},{"title":"Visualizing Metrics in a Grafana Dashboard","text":"<p>By combining the visualization power of Grafana with the query language of Prometheus, we are able to analyze trends in collected metrics using different types of graphs and charts.</p> <p>In the following example, we will create a dashboard like the one below where we analyze the latency distribution of a given measure \u2014 such as the processed or delivered events \u2014 over a selected period of time.</p> <p></p>  <p>Tip</p> <p>If you installed Grafana via the <code>kube-prometheus-stack</code> Helm chart \u2014 as suggested in the introduction to this section \u2014 you should be able to forward the local port <code>3000</code> to the Grafana instance running in the Kubernetes cluster:</p> <pre><code>kubectl -n monitoring port-forward svc/kube-prometheus-stack-grafana 3000:80\n</code></pre> <p>Then, open your web browser at http://localhost:3000.</p>","location":"observability/observability-metrics/#visualizing-metrics-in-a-grafana-dashboard"},{"title":"Number of Events Grouped by Latency Bucket","text":"<p>In this panel, we will use a bar gauge to display the distribution of the time spent by a component processing events over a selected period of time, organized in latency buckets.</p> <p>The chart will be based on a Prometheus metric of type histogram with a pre-configured bucket distribution in milliseconds, defined by TriggerMesh as follows:</p> <pre><code># HELP event_processing_latencies Time spent in the CloudEvents handler processing events\n# TYPE event_processing_latencies histogram\n</code></pre> <p>In a histogram metric, cumulative counters for each bucket are exposed as sub-metrics of the main histogram metric, with _bucket appended to the name, and a <code>le</code> (\"less than or equal\") label indicating the upper bound of the bucket, such as in the example below:</p> <pre><code>event_processing_latencies_bucket{le=\"1\"} 0\nevent_processing_latencies_bucket{le=\"2\"} 0\nevent_processing_latencies_bucket{le=\"5\"} 1541\nevent_processing_latencies_bucket{le=\"10\"} 6161\nevent_processing_latencies_bucket{le=\"20\"} 6776\nevent_processing_latencies_bucket{le=\"50\"} 6865\nevent_processing_latencies_bucket{le=\"100\"} 6868\n</code></pre> <p>We can start by charting the evolution of the raw counters corresponding to each latency bucket over time in a standard time series graph, before switching to bar gauges, in order to understand the metric's trend:</p> <pre><code>sum(\n  event_processing_latencies_bucket\n) by (le)\n</code></pre>  <p>Warning</p> <p>Always select the Heatmap format while working with Prometheus metrics of type <code>histogram</code>. This enables Grafana's intrinsic knowledge about Prometheus histograms, which results in buckets being sorted per <code>le</code> value and distinctive counts being shown for each bucket as one would expect.</p>  <p></p> <p>We can observe that counter values are cumulative. Some buckets have a steeper evolution than others, which already hints at a trend about the distribution of the component's processing latency.</p> <p>When switching from a time series chart to a bar gauge chart, we will want the summary value to correspond to the aggregation of all events processed in a given latency bucket. We could be tempted to simply summarize totals as the last value per bucket in the selected time period, but </p> <ol> <li>This would show the overall total of events processed by the component prior to the end of the time period, not the    total of events processed during the selected time period.</li> <li>This might result in skewed calculations if the counters were reset during that time period, as illustrated at the    very end of the range in the previous graph. Such situation isn't unusual and could occur for different reasons, such    as roll outs of new versions, horizontal scaling, Pod relocations, etc.</li> </ol> <p>We will instead calculate the increase in the time series in the selected time range using a query function which adjusts for breaks in monotonicity, such as counter resets:</p> <pre><code>sum(\n  increase(event_processing_latencies_bucket[$__range])\n) by (le)\n</code></pre> <p></p> <p>Selecting <code>Bar Gauge</code> in the list of visualizations instead of <code>Time Series</code> now shows a histogram which summary values accurately represent the number of events processed in each latency bucket for the selected time period:</p> <p></p> <p>The visualization options can be adjusted to one's preferences in order to obtain the desired result:</p> <p></p>","location":"observability/observability-metrics/#number-of-events-grouped-by-latency-bucket"},{"title":"Rate of Processed Events by Latency Bucket","text":"<p>In this panel, we will use a time series graph to display the rate of events processed by a component over time, and distributed in latency buckets.</p> <p>The chart will be based on the same Prometheus metric as in the previous example.</p> <p>This time around, we will stick with the default <code>Time Series</code> visualization, but replace the <code>increase()</code> function used previously with the <code>irate()</code> function:</p> <pre><code>sum(\n  irate(event_processing_latencies_bucket[$__rate_interval])\n) by (le)\n</code></pre> <p>The interval used to calculate the rate of change of the metric can be either</p> <ol> <li>Selected manually using an explicit time duration such as \"[3m]\".</li> <li>Delegated to Grafana using Grafana's <code>$__rate_interval</code> variable, which calculates an optimal value    based on the number of data points in the graph.</li> </ol> <p>The result of this calculation is a series of metrics (\"instant vectors\"), each representing the number of events per second processed by the component over time in a given latency bucket:</p> <p></p>","location":"observability/observability-metrics/#rate-of-processed-events-by-latency-bucket"},{"title":"90th Percentile of the Processing Latency Over Time","text":"<p>In this panel, we will use a time series graph to display the 90th percentile of processing durations of events handled by a component over time. This measure indicates the longest time it took to process an event, for 90% of all the events processed during each time interval on the graph.</p> <p>The chart will be based on the same Prometheus metric as in the previous example.</p> <p>We can reuse the query from the previous example, and pass it to the <code>histogram_quantile()</code> function with the desired quantile:</p> <pre><code>histogram_quantile(0.90,\n  sum(\n    irate(event_processing_latencies_bucket[$__rate_interval])\n  )\n) by (le)\n</code></pre> <p>The result of this calculation is a single metric (\"instant vector\"). An interesting exercise could be to compare this graph with the rate of processed events measured in the previous example, and observe whether or not spikes in the 90th latency percentile can be correlated with higher processing rates:</p> <p></p>","location":"observability/observability-metrics/#90th-percentile-of-the-processing-latency-over-time"},{"title":"Additional Notes and Takeaways","text":"<p>It can be noted that, in the previous examples, we generated three valuable types of visualizations from a single metric, by simply changing Prometheus queries to perform different types of calculations/aggregations.</p> <p>Thanks to the power of time series and the multi-dimensional aspect of Prometheus metrics, we could explore other types of visualizations based on this same metric, for example by filtering or grouping metrics by labels.</p> <p>For instance, the following query could be used to graph the event processing rate over time broken down by event type:</p> <pre><code>sum(\n  irate(event_processing_latencies_count[$__rate_interval])\n) by (event_type)\n</code></pre> <p>This other query could be used to graph the event processing rate over time for a specific event type:</p> <pre><code>sum(\n  irate(event_processing_latencies_count{event_type=\"object.created\"}[$__rate_interval])\n)\n</code></pre> <p>The same idea can be applied when it comes to visualizing metrics pertaining to a specific instance of a given component, or for example to all instances of that component within a specific Kubernetes namespace. There is a large amount of possibilities to be explored, the only limit is the choice of labels available for each metric. </p> <p></p>","location":"observability/observability-metrics/#additional-notes-and-takeaways"},{"title":"TriggerMesh APIs","text":"<p>TriggerMesh is composed of a set of APIs representing:</p> <ul> <li>Event sources</li> <li>Event targets</li> <li>Event Routing components</li> <li>Declarative event Transformation</li> <li>Event processing using Function</li> <li>Core TriggerMesh eventing</li> </ul>","location":"reference/"},{"title":"Repository structure","text":"<p>All APIs are available in the TriggerMesh GitHub repository <code>triggermesh/triggermesh</code> under the <code>pkg/apis</code> directory</p>  <p>Info</p> <p>This documentation is automatically generated using this code which is a slightly modified version of what the Knative project uses.</p>","location":"reference/#repository-structure"},{"title":"Core","text":"<p>Package:</p> <ul> <li> eventing.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/eventing/"},{"title":"eventing.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 is the v1alpha1 version of the API.</p> </p> <p>Resource Types:</p> <ul><li> MemoryBroker </li><li> RedisBroker </li><li> Trigger </li></ul>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1"},{"title":"MemoryBroker","text":"<p> <p>MemoryBroker is a Memory based broker implementation that collects a pool of events that are consumable using Triggers. Brokers provide a well-known endpoint for event delivery that senders can use with minimal knowledge of the event routing strategy. Subscribers use Triggers to request delivery of events from a broker\u2019s pool to a specific URL or Addressable endpoint.</p> </p>    Field Description      <code>apiVersion</code> string  <code> eventing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>MemoryBroker</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   MemoryBrokerSpec     <p>Spec defines the desired state of the broker.</p>      <code>memory</code>   Memory         <code>broker</code>   Broker            <code>status</code>   MemoryBrokerStatus     (Optional) <p>Status represents the current state of the broker. This data may be out of date.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.MemoryBroker"},{"title":"RedisBroker","text":"<p> <p>RedisBroker is a Redis based broker implementation that collects a pool of events that are consumable using Triggers. Brokers provide a well-known endpoint for event delivery that senders can use with minimal knowledge of the event routing strategy. Subscribers use Triggers to request delivery of events from a broker\u2019s pool to a specific URL or Addressable endpoint.</p> </p>    Field Description      <code>apiVersion</code> string  <code> eventing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>RedisBroker</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   RedisBrokerSpec     <p>Spec defines the desired state of the broker.</p>      <code>redis</code>   Redis         <code>broker</code>   Broker            <code>status</code>   RedisBrokerStatus     (Optional) <p>Status represents the current state of the broker. This data may be out of date.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.RedisBroker"},{"title":"Trigger","text":"<p> <p>Trigger represents a request to have events delivered to a target from a Broker\u2019s event pool.</p> </p>    Field Description      <code>apiVersion</code> string  <code> eventing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Trigger</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TriggerSpec     <p>Spec defines the desired state of the Trigger.</p>      <code>broker</code>   knative.dev/pkg/apis/duck/v1.KReference     <p>Broker is the broker that this trigger receives events from.</p>     <code>filters</code>  []github.com/triggermesh/brokers/pkg/config/broker.Filter    (Optional) <p>Filters is an experimental field that conforms to the CNCF CloudEvents Subscriptions API. It\u2019s an array of filter expressions that evaluate to true or false. If any filter expression in the array evaluates to false, the event MUST NOT be sent to the target. If all the filter expressions in the array evaluate to true, the event MUST be attempted to be delivered. Absence of a filter or empty array implies a value of true. In the event of users specifying both Filter and Filters, then the latter will override the former. This will allow users to try out the effect of the new Filters field without compromising the existing attribute-based Filter and try it out on existing Trigger objects.</p>     <code>target</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Target is the addressable that receives events from the Broker that pass the Filter. It is required.</p>     <code>delivery</code>  knative.dev/eventing/pkg/apis/duck/v1.DeliverySpec    (Optional) <p>Delivery contains the delivery spec for this specific trigger.</p>        <code>status</code>   TriggerStatus     (Optional) <p>Status represents the current state of the Trigger. This data may be out of date.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.Trigger"},{"title":"Broker","text":"<p> (Appears on: MemoryBrokerSpec,  RedisBrokerSpec) </p> <p> </p>    Field Description      <code>port</code>  int        <code>observability</code>   Observability","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.Broker"},{"title":"Memory","text":"<p> (Appears on: MemoryBrokerSpec) </p> <p> </p>    Field Description      <code>streamMaxLen</code>  int    <p>Maximum number of items the stream can host.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.Memory"},{"title":"MemoryBrokerSpec","text":"<p> (Appears on: MemoryBroker) </p> <p> </p>    Field Description      <code>memory</code>   Memory         <code>broker</code>   Broker","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.MemoryBrokerSpec"},{"title":"MemoryBrokerStatus","text":"<p> (Appears on: MemoryBroker) </p> <p> <p>MemoryBrokerStatus represents the current state of a Memory broker.</p> </p>    Field Description      <code>Status</code>   knative.dev/pkg/apis/duck/v1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p> <p>inherits duck/v1 Status, which currently provides: * ObservedGeneration - the \u2018Generation\u2019 of the Broker that was last processed by the controller. * Conditions - the latest available observations of a resource\u2019s current state.</p>     <code>address</code>   knative.dev/pkg/apis/duck/v1.Addressable     (Optional) <p>Broker is Addressable. It exposes the endpoint as an URI to get events delivered into the Broker mesh.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.MemoryBrokerStatus"},{"title":"Observability","text":"<p> (Appears on: Broker) </p> <p> </p>    Field Description      <code>valueFromConfigMap</code>  string","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.Observability"},{"title":"ReconcilableBroker","text":"<p> </p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.ReconcilableBroker"},{"title":"ReconcilableBrokerStatus","text":"<p> </p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.ReconcilableBrokerStatus"},{"title":"Redis","text":"<p> (Appears on: RedisBrokerSpec) </p> <p> </p>    Field Description      <code>connection</code>   RedisConnection     <p>Redis connection data.</p>     <code>stream</code>  string    <p>Stream name used by the broker.</p>     <code>streamMaxLen</code>  int    <p>Maximum number of items the stream can host.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.Redis"},{"title":"RedisBrokerSpec","text":"<p> (Appears on: RedisBroker) </p> <p> </p>    Field Description      <code>redis</code>   Redis         <code>broker</code>   Broker","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.RedisBrokerSpec"},{"title":"RedisBrokerStatus","text":"<p> (Appears on: RedisBroker) </p> <p> <p>RedisBrokerStatus represents the current state of a Redis broker.</p> </p>    Field Description      <code>Status</code>   knative.dev/pkg/apis/duck/v1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p> <p>inherits duck/v1 Status, which currently provides: * ObservedGeneration - the \u2018Generation\u2019 of the Broker that was last processed by the controller. * Conditions - the latest available observations of a resource\u2019s current state.</p>     <code>address</code>   knative.dev/pkg/apis/duck/v1.Addressable     (Optional) <p>Broker is Addressable. It exposes the endpoint as an URI to get events delivered into the Broker mesh.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.RedisBrokerStatus"},{"title":"RedisConnection","text":"<p> (Appears on: Redis) </p> <p> </p>    Field Description      <code>url</code>  string    <p>Redis URL.</p>     <code>username</code>   SecretValueFromSource     <p>Redis username.</p>     <code>password</code>   SecretValueFromSource     <p>Redis password.</p>     <code>tlsEnabled</code>  bool    <p>Use TLS enctrypted connection.</p>     <code>tlsSkipVerify</code>  bool    <p>Skip TLS certificate verification.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.RedisConnection"},{"title":"SecretValueFromSource","text":"<p> (Appears on: RedisConnection) </p> <p> <p>SecretValueFromSource represents the source of a secret value</p> </p>    Field Description      <code>secretKeyRef</code>   Kubernetes core/v1.SecretKeySelector     <p>The Secret key to select from.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.SecretValueFromSource"},{"title":"TriggerSpec","text":"<p> (Appears on: Trigger) </p> <p> <p>TriggerSpec defines the desired state of Trigger</p> </p>    Field Description      <code>broker</code>   knative.dev/pkg/apis/duck/v1.KReference     <p>Broker is the broker that this trigger receives events from.</p>     <code>filters</code>  []github.com/triggermesh/brokers/pkg/config/broker.Filter    (Optional) <p>Filters is an experimental field that conforms to the CNCF CloudEvents Subscriptions API. It\u2019s an array of filter expressions that evaluate to true or false. If any filter expression in the array evaluates to false, the event MUST NOT be sent to the target. If all the filter expressions in the array evaluate to true, the event MUST be attempted to be delivered. Absence of a filter or empty array implies a value of true. In the event of users specifying both Filter and Filters, then the latter will override the former. This will allow users to try out the effect of the new Filters field without compromising the existing attribute-based Filter and try it out on existing Trigger objects.</p>     <code>target</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Target is the addressable that receives events from the Broker that pass the Filter. It is required.</p>     <code>delivery</code>  knative.dev/eventing/pkg/apis/duck/v1.DeliverySpec    (Optional) <p>Delivery contains the delivery spec for this specific trigger.</p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.TriggerSpec"},{"title":"TriggerStatus","text":"<p> (Appears on: Trigger) </p> <p> <p>TriggerStatus represents the current state of a Trigger.</p> </p>    Field Description      <code>Status</code>   knative.dev/pkg/apis/duck/v1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p> <p>inherits duck/v1 Status, which currently provides: * ObservedGeneration - the \u2018Generation\u2019 of the Trigger that was last processed by the controller. * Conditions - the latest available observations of a resource\u2019s current state.</p>     <code>targetUri</code>   knative.dev/pkg/apis.URL     (Optional) <p>TargetURI is the resolved URI of the receiver for this Trigger.</p>     <code>DeliveryStatus</code>  knative.dev/eventing/pkg/apis/duck/v1.DeliveryStatus    <p> (Members of <code>DeliveryStatus</code> are embedded into this type.) </p> <p>DeliveryStatus contains a resolved URL to the dead letter sink address, and any other resolved delivery options.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>39ee26c</code>. </p>","location":"reference/eventing/#eventing.triggermesh.io/v1alpha1.TriggerStatus"},{"title":"Functions","text":"<p>Package:</p> <ul> <li> extensions.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/extensions/"},{"title":"extensions.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the extensions/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> Function </li></ul>","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1"},{"title":"Function","text":"<p> <p>Function is an addressable object that executes function code.</p> </p>    Field Description      <code>apiVersion</code> string  <code> extensions.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Function</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   FunctionSpec          <code>runtime</code>  string        <code>entrypoint</code>  string        <code>code</code>  string        <code>responseIsEvent</code>  bool        <code>eventStore</code>   EventStoreConnection         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying, as well as setting the CloudEvents \u2018type\u2019 and \u2018source\u2019 attributes using CloudEventOverrides (hack).</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   FunctionStatus","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1.Function"},{"title":"EventStoreConnection","text":"<p> (Appears on: FunctionSpec) </p> <p> <p>EventStoreConnection contains the data to connect to an EventStore instance</p> </p>    Field Description      <code>uri</code>  string    <p>URI is the gRPC location to the EventStore</p>","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1.EventStoreConnection"},{"title":"FunctionConfigMapIdentity","text":"<p> (Appears on: FunctionStatus) </p> <p> <p>FunctionConfigMapIdentity represents the identity of the ConfigMap containing the code of a Function.</p> </p>    Field Description      <code>name</code>  string        <code>resourceVersion</code>  string","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1.FunctionConfigMapIdentity"},{"title":"FunctionSpec","text":"<p> (Appears on: Function) </p> <p> <p>FunctionSpec holds the desired state of the Function Specification</p> </p>    Field Description      <code>runtime</code>  string        <code>entrypoint</code>  string        <code>code</code>  string        <code>responseIsEvent</code>  bool        <code>eventStore</code>   EventStoreConnection         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying, as well as setting the CloudEvents \u2018type\u2019 and \u2018source\u2019 attributes using CloudEventOverrides (hack).</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1.FunctionSpec"},{"title":"FunctionStatus","text":"<p> (Appears on: Function) </p> <p> <p>FunctionStatus defines the observed state of the Function.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>configMap</code>   FunctionConfigMapIdentity          <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>85a776ff</code>. </p>","location":"reference/extensions/#extensions.triggermesh.io/v1alpha1.FunctionStatus"},{"title":"Transformation","text":"<p>Package:</p> <ul> <li> flow.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/flow/"},{"title":"flow.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the flow/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> DataWeaveTransformation </li><li> JQTransformation </li><li> Synchronizer </li><li> Transformation </li><li> XMLToJSONTransformation </li><li> XSLTTransformation </li></ul>","location":"reference/flow/#flow.triggermesh.io/v1alpha1"},{"title":"DataWeaveTransformation","text":"<p> <p>DataWeaveTransformation is the Schema for an DataWeave transformation target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>DataWeaveTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   DataWeaveTransformationSpec          <code>dwSpell</code>   ValueFromField     (Optional) <p>DataWeave spell that will be used by default for transformation.</p>     <code>allowPerEventDwSpell</code>  bool    (Optional) <p>Whether the default DwSpell can be overriden at each event</p>     <code>inputContentType</code>  string    (Optional) <p>Content type for the incoming transformation.</p>     <code>outputContentType</code>  string    (Optional) <p>Content type for transformation Output.</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.DataWeaveTransformation"},{"title":"JQTransformation","text":"<p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>JQTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   JQTransformationSpec          <code>query</code>  string    <p>The query that gets passed to the JQ library</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.JQTransformation"},{"title":"Synchronizer","text":"<p> <p>Synchronizer is the Schema for the Synchronizer target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Synchronizer</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SynchronizerSpec          <code>correlationKey</code>   Correlation         <code>response</code>   Response         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Synchronizer"},{"title":"Transformation","text":"<p> <p>Transformation allows to declaratively perform data transformations on CloudEvents.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Transformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TransformationSpec          <code>context</code>   []Transform     <p>Context contains Transformations that must be applied on CE Context</p>     <code>data</code>   []Transform     <p>Data contains Transformations that must be applied on CE Data</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Transformation"},{"title":"XMLToJSONTransformation","text":"<p> <p>XMLToJSONTransformation is the schema for the event transformer.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>XMLToJSONTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   XMLToJSONTransformationSpec          <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.XMLToJSONTransformation"},{"title":"XSLTTransformation","text":"<p> <p>XSLTTransformation is the Schema for an XSLT transformation target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>XSLTTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   XSLTTransformationSpec          <code>xslt</code>   ValueFromField     (Optional) <p>XSLT document that will be used by default for transformation. Can be omited if the XSLT is informed at each event.</p>     <code>allowPerEventXSLT</code>  bool    (Optional) <p>Whether the default XSLT can be overriden at each event</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/flow/#flow.triggermesh.io/v1alpha1.XSLTTransformation"},{"title":"Correlation","text":"<p> (Appears on: SynchronizerSpec) </p> <p> <p>Correlation holds the request-response matching parameters.</p> </p>    Field Description      <code>attribute</code>  string        <code>length</code>  int","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Correlation"},{"title":"DataWeaveTransformationSpec","text":"<p> (Appears on: DataWeaveTransformation) </p> <p> <p>DataWeaveTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>dwSpell</code>   ValueFromField     (Optional) <p>DataWeave spell that will be used by default for transformation.</p>     <code>allowPerEventDwSpell</code>  bool    (Optional) <p>Whether the default DwSpell can be overriden at each event</p>     <code>inputContentType</code>  string    (Optional) <p>Content type for the incoming transformation.</p>     <code>outputContentType</code>  string    (Optional) <p>Content type for transformation Output.</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.DataWeaveTransformationSpec"},{"title":"EventOptions","text":"<p> (Appears on: JQTransformationSpec,  XMLToJSONTransformationSpec) </p> <p> <p>EventOptions modifies CloudEvents management at Targets.</p> </p>    Field Description      <code>payloadPolicy</code>  github.com/triggermesh/triggermesh/pkg/targets/adapter/cloudevents.PayloadPolicy    (Optional) <p>PayloadPolicy indicates if replies from the target should include a payload if available. Possible values are:</p> <ul> <li>always: will return a with the reply payload if avaliable.</li> <li>errors: will only reply with payload in case of an error.</li> <li>never: will not reply with payload.</li> </ul>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.EventOptions"},{"title":"JQTransformationSpec","text":"<p> (Appears on: JQTransformation) </p> <p> <p>JQTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>query</code>  string    <p>The query that gets passed to the JQ library</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.JQTransformationSpec"},{"title":"Path","text":"<p> (Appears on: Transform) </p> <p> <p>Path is a key-value pair that represents JSON object path</p> </p>    Field Description      <code>key</code>  string        <code>value</code>  string","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Path"},{"title":"Response","text":"<p> (Appears on: SynchronizerSpec) </p> <p> <p>Response defines the response handling configuration.</p> </p>    Field Description      <code>timeout</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Response"},{"title":"SynchronizerSpec","text":"<p> (Appears on: Synchronizer) </p> <p> <p>SynchronizerSpec defines the desired state of the component.</p> </p>    Field Description      <code>correlationKey</code>   Correlation         <code>response</code>   Response         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.SynchronizerSpec"},{"title":"Transform","text":"<p> (Appears on: TransformationSpec) </p> <p> <p>Transform describes transformation schemes for different CE types.</p> </p>    Field Description      <code>operation</code>  string        <code>paths</code>   []Path","location":"reference/flow/#flow.triggermesh.io/v1alpha1.Transform"},{"title":"TransformationSpec","text":"<p> (Appears on: Transformation) </p> <p> <p>TransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>context</code>   []Transform     <p>Context contains Transformations that must be applied on CE Context</p>     <code>data</code>   []Transform     <p>Data contains Transformations that must be applied on CE Data</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.TransformationSpec"},{"title":"ValueFromField","text":"<p> (Appears on: DataWeaveTransformationSpec,  XSLTTransformationSpec) </p> <p> <p>ValueFromField is a struct field that can have its value either defined explicitly or sourced from another entity.</p> </p>    Field Description      <code>value</code>  string    (Optional) <p>Field value.</p>     <code>valueFromSecret</code>   Kubernetes core/v1.SecretKeySelector     (Optional) <p>Field value from a Kubernetes Secret.</p>     <code>valueFromConfigMap</code>   Kubernetes core/v1.ConfigMapKeySelector     (Optional) <p>Field value from a Kubernetes ConfigMap.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.ValueFromField"},{"title":"XMLToJSONTransformationSpec","text":"<p> (Appears on: XMLToJSONTransformation) </p> <p> <p>XMLToJSONTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.XMLToJSONTransformationSpec"},{"title":"XSLTTransformationSpec","text":"<p> (Appears on: XSLTTransformation) </p> <p> <p>XSLTTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>xslt</code>   ValueFromField     (Optional) <p>XSLT document that will be used by default for transformation. Can be omited if the XSLT is informed at each event.</p>     <code>allowPerEventXSLT</code>  bool    (Optional) <p>Whether the default XSLT can be overriden at each event</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>85a776ff</code>. </p>","location":"reference/flow/#flow.triggermesh.io/v1alpha1.XSLTTransformationSpec"},{"title":"Routing","text":"<p>Package:</p> <ul> <li> routing.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/routing/"},{"title":"routing.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the routing/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> Filter </li><li> Splitter </li></ul>","location":"reference/routing/#routing.triggermesh.io/v1alpha1"},{"title":"Filter","text":"<p> <p>Filter is an addressable object that filters incoming events according to provided Common Language Expression</p> </p>    Field Description      <code>apiVersion</code> string  <code> routing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Filter</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   FilterSpec          <code>expression</code>  string        <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Sink is a reference to an object that will resolve to a domain name to use as the sink.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/routing/#routing.triggermesh.io/v1alpha1.Filter"},{"title":"Splitter","text":"<p> <p>Splitter is an addressable object that splits incoming events according to provided specification.</p> </p>    Field Description      <code>apiVersion</code> string  <code> routing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Splitter</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SplitterSpec          <code>path</code>  string        <code>ceContext</code>   CloudEventContext         <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/routing/#routing.triggermesh.io/v1alpha1.Splitter"},{"title":"CloudEventContext","text":"<p> (Appears on: SplitterSpec) </p> <p> <p>CloudEventContext declares context attributes that will be propagated to resulting events.</p> </p>    Field Description      <code>type</code>  string        <code>source</code>  string        <code>extensions</code>  map[string]string","location":"reference/routing/#routing.triggermesh.io/v1alpha1.CloudEventContext"},{"title":"FilterSpec","text":"<p> (Appears on: Filter) </p> <p> <p>FilterSpec defines the desired state of the component.</p> </p>    Field Description      <code>expression</code>  string        <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Sink is a reference to an object that will resolve to a domain name to use as the sink.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/routing/#routing.triggermesh.io/v1alpha1.FilterSpec"},{"title":"SplitterSpec","text":"<p> (Appears on: Splitter) </p> <p> <p>SplitterSpec defines the desired state of the component.</p> </p>    Field Description      <code>path</code>  string        <code>ceContext</code>   CloudEventContext         <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>85a776ff</code>. </p>","location":"reference/routing/#routing.triggermesh.io/v1alpha1.SplitterSpec"},{"title":"Sources","text":"<p>Package:</p> <ul> <li> sources.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/sources/"},{"title":"sources.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the sources/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> AWSCloudWatchLogsSource </li><li> AWSCloudWatchSource </li><li> AWSCodeCommitSource </li><li> AWSCognitoIdentitySource </li><li> AWSCognitoUserPoolSource </li><li> AWSDynamoDBSource </li><li> AWSEventBridgeSource </li><li> AWSKinesisSource </li><li> AWSPerformanceInsightsSource </li><li> AWSS3Source </li><li> AWSSNSSource </li><li> AWSSQSSource </li><li> AzureActivityLogsSource </li><li> AzureBlobStorageSource </li><li> AzureEventGridSource </li><li> AzureEventHubsSource </li><li> AzureIOTHubSource </li><li> AzureQueueStorageSource </li><li> AzureServiceBusQueueSource </li><li> AzureServiceBusTopicSource </li><li> CloudEventsSource </li><li> GoogleCloudAuditLogsSource </li><li> GoogleCloudBillingSource </li><li> GoogleCloudPubSubSource </li><li> GoogleCloudSourceRepositoriesSource </li><li> GoogleCloudStorageSource </li><li> HTTPPollerSource </li><li> IBMMQSource </li><li> KafkaSource </li><li> OCIMetricsSource </li><li> SalesforceSource </li><li> SlackSource </li><li> TwilioSource </li><li> WebhookSource </li><li> ZendeskSource </li></ul>","location":"reference/sources/#sources.triggermesh.io/v1alpha1"},{"title":"AWSCloudWatchLogsSource","text":"<p> <p>AWSCloudWatchLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCloudWatchLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCloudWatchLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the Log Group to source data from. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncloudwatchlogs.html#amazoncloudwatchlogs-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often logs should be pulled from Amazon CloudWatch Logs. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch Logs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchLogsSource"},{"title":"AWSCloudWatchSource","text":"<p> <p>AWSCloudWatchSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCloudWatchSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCloudWatchSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>region</code>  string    <p>Code of the AWS region to source metrics from. Available region codes are documented at https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints.</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often metrics should be pulled from Amazon CloudWatch. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>metricQueries</code>   []AWSCloudWatchMetricQuery     (Optional) <p>List of queries that determine what metrics will be sourced from Amazon CloudWatch.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchSource"},{"title":"AWSCodeCommitSource","text":"<p> <p>AWSCodeCommitSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCodeCommitSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCodeCommitSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Repository ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awscodecommit.html#awscodecommit-resources-for-iam-policies</p>     <code>branch</code>  string    <p>Name of the Git branch this source observes.</p>     <code>eventTypes</code>  []string    <p>List of event types that should be processed by the source. Valid values: [push, pull_request]</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CodeCommit API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCodeCommitSource"},{"title":"AWSCognitoIdentitySource","text":"<p> <p>AWSCognitoIdentitySource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCognitoIdentitySource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCognitoIdentitySourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Identity Pool ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazoncognitoidentity.html#amazoncognitoidentity-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoIdentitySource"},{"title":"AWSCognitoUserPoolSource","text":"<p> <p>AWSCognitoUserPoolSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCognitoUserPoolSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCognitoUserPoolSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>User Pool ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncognitouserpools.html#amazoncognitouserpools-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoUserPoolSource"},{"title":"AWSDynamoDBSource","text":"<p> <p>AWSDynamoDBSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSDynamoDBSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSDynamoDBSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon DynamoDB API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSDynamoDBSource"},{"title":"AWSEventBridgeSource","text":"<p> <p>AWSEventBridgeSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSEventBridgeSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSEventBridgeSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>EventBridge event bus ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html#amazoneventbridge-resources-for-iam-policies</p>     <code>eventPattern</code>  string    (Optional) <p>Event pattern used to select events that this source should subscribe to. If not specified, the event rule is created with a catch-all pattern. https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html</p>     <code>destination</code>   AWSEventBridgeSourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon EventBridge event bus, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the EventBridge event rule.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSEventBridgeSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSource"},{"title":"AWSKinesisSource","text":"<p> <p>AWSKinesisSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSKinesisSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSKinesisSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Stream ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Kinesis API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSKinesisSource"},{"title":"AWSPerformanceInsightsSource","text":"<p> <p>AWSPerformanceInsightsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSPerformanceInsightsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSPerformanceInsightsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the RDS instance to receive metrics for. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonrds.html#amazonrds-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often metrics should be pulled from Amazon Performance Insights. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>metrics</code>  []string    <p>List of queries that determine what metrics will be sourced from Amazon Performance Insights.</p> <p>Each item represents the \u2018metric\u2019 attribute of a MetricQuery. https://docs.aws.amazon.com/performance-insights/latest/APIReference/API_MetricQuery.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon RDS and Performance Insights APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSPerformanceInsightsSource"},{"title":"AWSS3Source","text":"<p> <p>AWSS3Source is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSS3Source</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSS3SourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Bucket ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html#amazons3-resources-for-iam-policies</p> <p>Although not technically supported by S3, the ARN provided via this attribute may include a region and an account ID. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless an existing queue is provided via the QueueARN attribute.</p>     <code>eventTypes</code>  []string    <p>List of event types that the source should subscribe to. Accepted values: https://docs.aws.amazon.com/AmazonS3/latest/API/API_QueueConfiguration.html https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html</p>     <code>destination</code>   AWSS3SourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon S3 bucket, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the bucket.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSS3SourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSS3Source"},{"title":"AWSSNSSource","text":"<p> <p>AWSSNSSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSNSSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSNSSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Topic ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>subscriptionAttributes</code>  map[string]*string    (Optional) <p>Attributes to set on the Subscription that is used for receiving messages from the topic. For a list of supported subscription attributes, please refer to the following resources: * https://docs.aws.amazon.com/sns/latest/api/API_SetSubscriptionAttributes.html * https://docs.aws.amazon.com/sns/latest/dg/sns-how-it-works.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SNS API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSSNSSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSource"},{"title":"AWSSQSSource","text":"<p> <p>AWSSQSSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSQSSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSQSSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>receiveOptions</code>   AWSSQSSourceReceiveOptions     (Optional) <p>Options that control the behavior of message receivers.</p>     <code>messageProcessor</code>  string    (Optional) <p>Name of the message processor to use for converting SQS messages to CloudEvents. Supported values are \u201cdefault\u201d and \u201cs3\u201d.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SQS API.</p>     <code>endpoint</code>   AWSEndpoint     (Optional) <p>Customizations of the AWS REST API endpoint.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSource"},{"title":"AzureActivityLogsSource","text":"<p> <p>AzureActivityLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureActivityLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureActivityLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>subscriptionID</code>  string    <p>The ID of the Azure subscription which activity logs to subscribe to.</p>     <code>destination</code>   AzureActivityLogsSourceDestination     <p>The intermediate destination of activity logs, before they are retrieved by this event source.</p>     <code>categories</code>  []string    (Optional) <p>Categories of Activity Logs to collect.</p> <p>All available categories are selected when this attribute is empty. https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-schema#categories</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Monitor REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureActivityLogsSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSource"},{"title":"AzureBlobStorageSource","text":"<p> <p>AzureBlobStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureBlobStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureBlobStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>storageAccountID</code>   AzureResourceID     <p>Resource ID of the Storage Account to receive events for.</p> <p>Format: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}</p> <p>Besides the Storage Account name itself, the resource ID contains the subscription ID and resource group name which all together uniquely identify the Storage Account within Azure.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://docs.microsoft.com/en-us/azure/event-grid/event-schema-blob-storage</p> <p>When this attribute is not set, the source automatically subscribes to the following event types: - Microsoft.Storage.BlobCreated - Microsoft.Storage.BlobDeleted</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureBlobStorageSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSource"},{"title":"AzureEventGridSource","text":"<p> <p>AzureEventGridSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventGridSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventGridSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>scope</code>   AzureResourceID     <p>The resource ID the event subscription applies to.</p> <p>Can be - an Azure subscription: /subscriptions/{subscriptionId} - a resource group: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName} - a top-level resource from a resource provider (including Event Grid topic): /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>If not specified, Azure automatically selects all available event types for the provided Scope.</p> <p>For a list of all available event types, please refer to the list of Azure services that support system topics at https://docs.microsoft.com/en-us/azure/event-grid/system-topics</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureEventGridSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSource"},{"title":"AzureEventHubsSource","text":"<p> <p>AzureEventHubsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventHubsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventHubsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventHubsSource"},{"title":"AzureIOTHubSource","text":"<p> <p>AzureIOTHubSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureIOTHubSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureIOTHubSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   AzureAuth     <p>AzureAuth contains multiple authentication methods for Azure services.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureIOTHubSource"},{"title":"AzureQueueStorageSource","text":"<p> <p>AzureQueueStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureQueueStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureQueueStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>accountName</code>  string        <code>queueName</code>  string        <code>accountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureQueueStorageSource"},{"title":"AzureServiceBusQueueSource","text":"<p> <p>AzureServiceBusQueueSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureServiceBusQueueSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureServiceBusQueueSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>queueID</code>   AzureResourceID     <p>The resource ID the Service Bus Queue to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/queues/{queueName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with Azure Service Bus. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusQueueSource"},{"title":"AzureServiceBusTopicSource","text":"<p> <p>AzureServiceBusTopicSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureServiceBusTopicSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureServiceBusTopicSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topicID</code>   AzureResourceID     <p>The resource ID the Service Bus Topic to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/topics/{topicName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>webSocketsEnable</code>  bool    (Optional) <p>WebSocketsEnable</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureServiceBusTopicSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSource"},{"title":"CloudEventsSource","text":"<p> <p>CloudEventsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>CloudEventsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   CloudEventsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>credentials</code>   HTTPCredentials     (Optional) <p>Credentials to connect to this source.</p>     <code>path</code>  string    (Optional) <p>Path under which requests are accepted.</p>     <code>rateLimiter</code>   RateLimiter     (Optional) <p>RateLimiter for incoming events per adapter instance. A single CloudEventsSource object can create multiple adapter instances, the rate limiting configuration being applied to each of them individually.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.CloudEventsSource"},{"title":"GoogleCloudAuditLogsSource","text":"<p> <p>GoogleCloudAuditLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudAuditLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudAuditLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>serviceName</code>  string    <p>The GCP service this instance should source audit logs from. Required. example: compute.googleapis.com</p>     <code>methodName</code>  string    <p>The name of the service method or operation. For API calls, this should be the name of the API method. Required. beta.compute.instances.insert</p>     <code>resourceName</code>  string    <p>The resource or collection that is the target of the operation. The name is a scheme-less URI, not including the API service name. example: \u201cprojects/PROJECT_ID/zones/us-central1-a/instances\u201d</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Audit Logs event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudAuditLogsSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSource"},{"title":"GoogleCloudBillingSource","text":"<p> <p>GoogleCloudBillingSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudBillingSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudBillingSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>billingAccountId</code>  string    <p>The identifier for the Cloud Billing account owning the budget.</p>     <code>budgetId</code>  string    <p>The identifier for the Cloud Billing budget. You can locate the budget\u2019s ID in your budget under Manage notifications. The ID is displayed after you select Connect a Pub/Sub topic to this budget.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Billing budget event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudBillingSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSource"},{"title":"GoogleCloudPubSubSource","text":"<p> <p>GoogleCloudPubSubSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudPubSubSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudPubSubSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>subscriptionID</code>  string    (Optional) <p>ID of the subscription to use to pull messages from the topic.</p> <p>If supplied, this subscription must 1) exist and 2) belong to the provided topic. Otherwise, a pull subscription to that topic is created on behalf of the user.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudPubSubSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSource"},{"title":"GoogleCloudSourceRepositoriesSource","text":"<p> <p>GoogleCloudSourceRepositoriesSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudSourceRepositoriesSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudSourceRepositoriesSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>repository</code>   GCloudResourceName     <p>Name of the Cloud repo to receive notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the repo events.</p>     <code>publishServiceAccount</code>  string    (Optional) <p>Email address of the service account used for publishing notifications to Pub/Sub. This service account needs to be in the same project as the repo, and to have the \u2018pubsub.topics.publish\u2019 IAM permission associated with it. It can (but doesn\u2019t have to) be the same service account as the \u2018ServiceAccountKey\u2019 attribute.</p> <p>If unspecified, it defaults to the Compute Engine default service account.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudSourceRepositoriesSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSource"},{"title":"GoogleCloudStorageSource","text":"<p> <p>GoogleCloudStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bucket</code>  string    <p>Name of the Cloud Storage bucket to receive change notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the bucket.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://cloud.google.com/storage/docs/pubsub-notifications#events</p> <p>All types are selected when this attribute is not set.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudStorageSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSource"},{"title":"HTTPPollerSource","text":"<p> <p>HTTPPollerSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HTTPPollerSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HTTPPollerSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>HTTP/S URL of the endpoint to poll data from.</p>     <code>method</code>  string    <p>HTTP request method to use in requests to the specified \u2018endpoint\u2019. https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods</p>     <code>skipVerify</code>  bool    (Optional) <p>Controls whether the HTTP client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>caCertificate</code>  string    (Optional) <p>CA certificate in X.509 format the HTTP client should use to verify the identity of remote servers when communicating over TLS.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name to set in HTTP requests that require HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password to set in HTTP requests that require HTTP Basic authentication.</p>     <code>headers</code>  map[string]string    (Optional) <p>HTTP headers to include in HTTP requests.</p>     <code>interval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often the HTTP/S endpoint should be polled. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.HTTPPollerSource"},{"title":"IBMMQSource","text":"<p> <p>IBMMQSource is the Schema the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>IBMMQSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   IBMMQSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>delivery</code>   Delivery         <code>credentials</code>   Credentials         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.IBMMQSource"},{"title":"KafkaSource","text":"<p> <p>KafkaSource is the Schema for the KafkaSource.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>KafkaSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   KafkaSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>topic</code>  string    <p>Topic holds the name of the Kafka Topic.</p>     <code>groupID</code>  string    <p>GroupID holds the name of the Kafka Group ID.</p>     <code>auth</code>   KafkaSourceAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.KafkaSource"},{"title":"OCIMetricsSource","text":"<p> <p>OCIMetricsSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>OCIMetricsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   OCIMetricsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>oracleApiPrivateKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key</p>     <code>oracleApiPrivateKeyPassphrase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key passphrase</p>     <code>oracleApiPrivateKeyFingerprint</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API cert fingerprint</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region</p>     <code>metricsPollingFrequency</code>  string    (Optional) <p>OCI Metrics Polling Frequency</p>     <code>metrics</code>   []OCIMetrics     <p>Array of metrics</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.OCIMetricsSource"},{"title":"SalesforceSource","text":"<p> <p>SalesforceSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SalesforceSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SalesforceSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   SalesforceAuth     <p>Authentication method to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce.</p>     <code>subscription</code>   SalesforceSubscription     <p>Subscription to a Salesforce channel</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SalesforceSource"},{"title":"SlackSource","text":"<p> <p>SlackSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SlackSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SlackSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>signingSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>SigningSecret can be set to the value of Slack request signing secret to authenticate callbacks. See: https://api.slack.com/authentication/verifying-requests-from-slack</p>     <code>appID</code>  string    (Optional) <p>AppID identifies the Slack application generating this event. It helps identifying the App sourcing events when multiple Slack applications shared an endpoint. See: https://api.slack.com/events-api</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SlackSource"},{"title":"TwilioSource","text":"<p> <p>TwilioSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TwilioSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TwilioSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.TwilioSource"},{"title":"WebhookSource","text":"<p> <p>WebhookSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>WebhookSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   WebhookSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>eventExtensionAttributes</code>   WebhookEventExtensionAttributes     (Optional) <p>Options to transform HTTP request data into CloudEvent extensions. https://github.com/cloudevents/spec/blob/main/cloudevents/spec.md#extension-context-attributes</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>corsAllowOrigin</code>  string    (Optional) <p>Specifies the CORS Origin to use in pre-flight headers.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/sources/#sources.triggermesh.io/v1alpha1.WebhookSource"},{"title":"ZendeskSource","text":"<p> <p>ZendeskSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ZendeskSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ZendeskSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token identifies the API token used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>email</code>  string    <p>Email identifies the email used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>webhookPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>WebhookPassword used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>webhookUsername</code>  string    <p>WebhookUsername used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>subdomain</code>  string    <p>Subdomain identifies Zendesk subdomain</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   ZendeskSourceStatus","location":"reference/sources/#sources.triggermesh.io/v1alpha1.ZendeskSource"},{"title":"AWSAuth","text":"<p> (Appears on: AWSCloudWatchLogsSourceSpec,  AWSCloudWatchSourceSpec,  AWSCodeCommitSourceSpec,  AWSCognitoIdentitySourceSpec,  AWSCognitoUserPoolSourceSpec,  AWSDynamoDBSourceSpec,  AWSEventBridgeSourceSpec,  AWSKinesisSourceSpec,  AWSPerformanceInsightsSourceSpec,  AWSS3SourceSpec,  AWSSNSSourceSpec,  AWSSQSSourceSpec) </p> <p> <p>AWSAuth contains multiple authentication methods for AWS services.</p> </p>    Field Description      <code>credentials</code>   AWSSecurityCredentials     (Optional) <p>Security credentials allow AWS to authenticate and authorize requests based on a signature composed of an access key ID and a corresponding secret access key. See https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html</p>     <code>iamRole</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     (Optional) <p>(Amazon EKS only) The ARN of an IAM role which can be impersonated to obtain AWS permissions. See https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSAuth"},{"title":"AWSCloudWatchLogsSourceSpec","text":"<p> (Appears on: AWSCloudWatchLogsSource) </p> <p> <p>AWSCloudWatchLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the Log Group to source data from. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncloudwatchlogs.html#amazoncloudwatchlogs-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often logs should be pulled from Amazon CloudWatch Logs. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch Logs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchLogsSourceSpec"},{"title":"AWSCloudWatchMetric","text":"<p> (Appears on: AWSCloudWatchMetricStat) </p> <p> <p>AWSCloudWatchMetric is a metric definition.</p> </p>    Field Description      <code>dimensions</code>   []AWSCloudWatchMetricDimension         <code>metricName</code>  string        <code>namespace</code>  string","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetric"},{"title":"AWSCloudWatchMetricDimension","text":"<p> (Appears on: AWSCloudWatchMetric) </p> <p> <p>AWSCloudWatchMetricDimension represents the dimensions of a metric.</p> </p>    Field Description      <code>name</code>  string        <code>value</code>  string","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricDimension"},{"title":"AWSCloudWatchMetricQuery","text":"<p> (Appears on: AWSCloudWatchSourceSpec) </p> <p> <p>AWSCloudWatchMetricQuery represents a CloudWatch MetricDataQuery. https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDataQuery.html</p> </p>    Field Description      <code>name</code>  string    <p>Unique short name that identifies the query.</p>     <code>expression</code>  string    (Optional) <p>Math expression to be performed on the metric data.</p>     <code>metric</code>   AWSCloudWatchMetricStat     (Optional) <p>Representation of a metric with statistics, period, and units, but no math expression.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricQuery"},{"title":"AWSCloudWatchMetricStat","text":"<p> (Appears on: AWSCloudWatchMetricQuery) </p> <p> <p>AWSCloudWatchMetricStat is a representation of a metric with statistics, period, and units, but no math expression.</p> </p>    Field Description      <code>metric</code>   AWSCloudWatchMetric         <code>period</code>  int64    <p>Definition of the metric</p>     <code>stat</code>  string    <p>metric resolution in seconds</p>     <code>unit</code>  string    <p>statistic type to use</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricStat"},{"title":"AWSCloudWatchSourceSpec","text":"<p> (Appears on: AWSCloudWatchSource) </p> <p> <p>AWSCloudWatchSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>region</code>  string    <p>Code of the AWS region to source metrics from. Available region codes are documented at https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints.</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often metrics should be pulled from Amazon CloudWatch. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>metricQueries</code>   []AWSCloudWatchMetricQuery     (Optional) <p>List of queries that determine what metrics will be sourced from Amazon CloudWatch.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchSourceSpec"},{"title":"AWSCodeCommitSourceSpec","text":"<p> (Appears on: AWSCodeCommitSource) </p> <p> <p>AWSCodeCommitSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Repository ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awscodecommit.html#awscodecommit-resources-for-iam-policies</p>     <code>branch</code>  string    <p>Name of the Git branch this source observes.</p>     <code>eventTypes</code>  []string    <p>List of event types that should be processed by the source. Valid values: [push, pull_request]</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CodeCommit API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCodeCommitSourceSpec"},{"title":"AWSCognitoIdentitySourceSpec","text":"<p> (Appears on: AWSCognitoIdentitySource) </p> <p> <p>AWSCognitoIdentitySourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Identity Pool ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazoncognitoidentity.html#amazoncognitoidentity-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoIdentitySourceSpec"},{"title":"AWSCognitoUserPoolSourceSpec","text":"<p> (Appears on: AWSCognitoUserPoolSource) </p> <p> <p>AWSCognitoUserPoolSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>User Pool ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncognitouserpools.html#amazoncognitouserpools-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoUserPoolSourceSpec"},{"title":"AWSDynamoDBSourceSpec","text":"<p> (Appears on: AWSDynamoDBSource) </p> <p> <p>AWSDynamoDBSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon DynamoDB API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSDynamoDBSourceSpec"},{"title":"AWSEndpoint","text":"<p> (Appears on: AWSSQSSourceSpec) </p> <p> <p>AWSEndpoint contains parameters which are used to override the destination of REST API calls to AWS services. It allows, for example, to target API-compatible alternatives to the public AWS cloud (Localstack, Minio, ElasticMQ, \u2026).</p> </p>    Field Description      <code>url</code>   knative.dev/pkg/apis.URL     <p>URL of the endpoint.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEndpoint"},{"title":"AWSEventBridgeSourceDestination","text":"<p> (Appears on: AWSEventBridgeSourceSpec) </p> <p> <p>AWSEventBridgeSourceDestination contains possible intermediate destinations for the event bus\u2019 events.</p> </p>    Field Description      <code>sqs</code>   AWSEventBridgeSourceDestinationSQS     (Optional) <p>Amazon SQS destination.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceDestination"},{"title":"AWSEventBridgeSourceDestinationSQS","text":"<p> (Appears on: AWSEventBridgeSourceDestination) </p> <p> <p>AWSEventBridgeSourceDestinationSQS contains properties of an Amazon SQS queue to use as destination for the event bus\u2019 events.</p> </p>    Field Description      <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>SQS Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceDestinationSQS"},{"title":"AWSEventBridgeSourceSpec","text":"<p> (Appears on: AWSEventBridgeSource) </p> <p> <p>AWSEventBridgeSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>EventBridge event bus ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html#amazoneventbridge-resources-for-iam-policies</p>     <code>eventPattern</code>  string    (Optional) <p>Event pattern used to select events that this source should subscribe to. If not specified, the event rule is created with a catch-all pattern. https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html</p>     <code>destination</code>   AWSEventBridgeSourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon EventBridge event bus, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the EventBridge event rule.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceSpec"},{"title":"AWSEventBridgeSourceStatus","text":"<p> (Appears on: AWSEventBridgeSource) </p> <p> <p>AWSEventBridgeSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>ruleARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN         <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceStatus"},{"title":"AWSKinesisSourceSpec","text":"<p> (Appears on: AWSKinesisSource) </p> <p> <p>AWSKinesisSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Stream ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Kinesis API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSKinesisSourceSpec"},{"title":"AWSPerformanceInsightsSourceSpec","text":"<p> (Appears on: AWSPerformanceInsightsSource) </p> <p> <p>AWSPerformanceInsightsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the RDS instance to receive metrics for. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonrds.html#amazonrds-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often metrics should be pulled from Amazon Performance Insights. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>metrics</code>  []string    <p>List of queries that determine what metrics will be sourced from Amazon Performance Insights.</p> <p>Each item represents the \u2018metric\u2019 attribute of a MetricQuery. https://docs.aws.amazon.com/performance-insights/latest/APIReference/API_MetricQuery.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon RDS and Performance Insights APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSPerformanceInsightsSourceSpec"},{"title":"AWSS3SourceDestination","text":"<p> (Appears on: AWSS3SourceSpec) </p> <p> <p>AWSS3SourceDestination contains possible intermediate destinations for bucket notifications.</p> </p>    Field Description      <code>sqs</code>   AWSS3SourceDestinationSQS     (Optional) <p>Amazon SQS destination.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceDestination"},{"title":"AWSS3SourceDestinationSQS","text":"<p> (Appears on: AWSS3SourceDestination) </p> <p> <p>AWSS3SourceDestinationSQS contains properties of an Amazon SQS queue to use as destination for bucket notifications.</p> </p>    Field Description      <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>SQS Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceDestinationSQS"},{"title":"AWSS3SourceSpec","text":"<p> (Appears on: AWSS3Source) </p> <p> <p>AWSS3SourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Bucket ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html#amazons3-resources-for-iam-policies</p> <p>Although not technically supported by S3, the ARN provided via this attribute may include a region and an account ID. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless an existing queue is provided via the QueueARN attribute.</p>     <code>eventTypes</code>  []string    <p>List of event types that the source should subscribe to. Accepted values: https://docs.aws.amazon.com/AmazonS3/latest/API/API_QueueConfiguration.html https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html</p>     <code>destination</code>   AWSS3SourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon S3 bucket, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the bucket.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceSpec"},{"title":"AWSS3SourceStatus","text":"<p> (Appears on: AWSS3Source) </p> <p> <p>AWSS3SourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceStatus"},{"title":"AWSSNSSourceSpec","text":"<p> (Appears on: AWSSNSSource) </p> <p> <p>AWSSNSSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Topic ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>subscriptionAttributes</code>  map[string]*string    (Optional) <p>Attributes to set on the Subscription that is used for receiving messages from the topic. For a list of supported subscription attributes, please refer to the following resources: * https://docs.aws.amazon.com/sns/latest/api/API_SetSubscriptionAttributes.html * https://docs.aws.amazon.com/sns/latest/dg/sns-how-it-works.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SNS API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSourceSpec"},{"title":"AWSSNSSourceStatus","text":"<p> (Appears on: AWSSNSSource) </p> <p> <p>AWSSNSSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscriptionARN</code>  string","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSourceStatus"},{"title":"AWSSQSSourceReceiveOptions","text":"<p> (Appears on: AWSSQSSourceSpec) </p> <p> <p>AWSSQSSourceReceiveOptions defines options that control the behavior of Amazon SQS message receivers.</p> </p>    Field Description      <code>visibilityTimeout</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Period of time during which Amazon SQS prevents other consumers from receiving and processing a message that has been received via ReceiveMessage. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>If not defined, the overall visibility timeout for the queue is used.</p> <p>For more details, please refer to the Amazon SQS Developer Guide at https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSourceReceiveOptions"},{"title":"AWSSQSSourceSpec","text":"<p> (Appears on: AWSSQSSource) </p> <p> <p>AWSSQSSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>receiveOptions</code>   AWSSQSSourceReceiveOptions     (Optional) <p>Options that control the behavior of message receivers.</p>     <code>messageProcessor</code>  string    (Optional) <p>Name of the message processor to use for converting SQS messages to CloudEvents. Supported values are \u201cdefault\u201d and \u201cs3\u201d.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SQS API.</p>     <code>endpoint</code>   AWSEndpoint     (Optional) <p>Customizations of the AWS REST API endpoint.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSourceSpec"},{"title":"AWSSecurityCredentials","text":"<p> (Appears on: AWSAuth) </p> <p> <p>AWSSecurityCredentials represents a set of AWS security credentials.</p> </p>    Field Description      <code>accessKeyID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>secretAccessKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AWSSecurityCredentials"},{"title":"AzureActivityLogsSourceDestination","text":"<p> (Appears on: AzureActivityLogsSourceSpec) </p> <p> <p>AzureActivityLogsSourceDestination contains possible intermediate destinations for activity logs.</p> </p>    Field Description      <code>eventHubs</code>   AzureActivityLogsSourceDestinationEventHubs","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceDestination"},{"title":"AzureActivityLogsSourceDestinationEventHubs","text":"<p> (Appears on: AzureActivityLogsSourceDestination) </p> <p> <p>AzureActivityLogsSourceDestinationEventHubs contains properties of an Event Hubs namespace to use as intermediate destination for events.</p> </p>    Field Description      <code>namespaceID</code>   AzureResourceID     <p>Resource ID of the Event Hubs namespace.</p> <p>The expected format is /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}</p>     <code>hubName</code>  string    (Optional) <p>Name of the Event Hubs instance within the selected namespace. If omitted, Azure automatically creates an Event Hub with the name \u2018insights-activity-logs\u2019 inside the selected namespace.</p>     <code>sasPolicy</code>  string    (Optional) <p>Name of a SAS policy with Manage permissions inside the Event Hubs namespace referenced in the EventHubID field.</p> <p>Defaults to \u201cRootManageSharedAccessKey\u201d.</p> <p>References: * https://docs.microsoft.com/en-us/rest/api/eventhub/2017-04-01/authorization%20rules%20-%20namespaces/getauthorizationrule * https://docs.microsoft.com/en-us/azure/event-hubs/authorize-access-shared-access-signature</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceDestinationEventHubs"},{"title":"AzureActivityLogsSourceSpec","text":"<p> (Appears on: AzureActivityLogsSource) </p> <p> <p>AzureActivityLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>subscriptionID</code>  string    <p>The ID of the Azure subscription which activity logs to subscribe to.</p>     <code>destination</code>   AzureActivityLogsSourceDestination     <p>The intermediate destination of activity logs, before they are retrieved by this event source.</p>     <code>categories</code>  []string    (Optional) <p>Categories of Activity Logs to collect.</p> <p>All available categories are selected when this attribute is empty. https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-schema#categories</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Monitor REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceSpec"},{"title":"AzureActivityLogsSourceStatus","text":"<p> (Appears on: AzureActivityLogsSource) </p> <p> <p>AzureActivityLogsSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceStatus"},{"title":"AzureAuth","text":"<p> (Appears on: AzureActivityLogsSourceSpec,  AzureBlobStorageSourceSpec,  AzureEventGridSourceSpec,  AzureEventHubsSourceSpec,  AzureIOTHubSourceSpec,  AzureServiceBusQueueSourceSpec,  AzureServiceBusTopicSourceSpec) </p> <p> <p>AzureAuth contains multiple authentication methods for Azure services.</p> </p>    Field Description      <code>servicePrincipal</code>   AzureServicePrincipal     <p>Service principals provide a way to create a non-interactive account associated with your identity to which you grant only the privileges your app needs to run. See https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals</p>     <code>sasToken</code>   AzureSASToken     <p>A shared access signature (SAS) provides secure delegated access to resources in a storage account. See https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureAuth"},{"title":"AzureBlobStorageSourceSpec","text":"<p> (Appears on: AzureBlobStorageSource) </p> <p> <p>AzureBlobStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>storageAccountID</code>   AzureResourceID     <p>Resource ID of the Storage Account to receive events for.</p> <p>Format: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}</p> <p>Besides the Storage Account name itself, the resource ID contains the subscription ID and resource group name which all together uniquely identify the Storage Account within Azure.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://docs.microsoft.com/en-us/azure/event-grid/event-schema-blob-storage</p> <p>When this attribute is not set, the source automatically subscribes to the following event types: - Microsoft.Storage.BlobCreated - Microsoft.Storage.BlobDeleted</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSourceSpec"},{"title":"AzureBlobStorageSourceStatus","text":"<p> (Appears on: AzureBlobStorageSource) </p> <p> <p>AzureBlobStorageSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance that is currently receiving events from the Azure Event Grid subscription.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSourceStatus"},{"title":"AzureEventGridSourceDestinationEventHubs","text":"<p> (Appears on: AzureEventGridSourceEndpoint) </p> <p> <p>AzureEventGridSourceDestinationEventHubs contains properties of an Event Hubs namespace to use as intermediate destination for events.</p> </p>    Field Description      <code>namespaceID</code>   AzureResourceID     <p>Resource ID of the Event Hubs namespace.</p> <p>The expected format is /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}</p>     <code>hubName</code>  string    (Optional) <p>Name of the Event Hubs instance within the selected namespace. If omitted, an Event Hubs instance is created on behalf of the user.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceDestinationEventHubs"},{"title":"AzureEventGridSourceEndpoint","text":"<p> (Appears on: AzureBlobStorageSourceSpec,  AzureEventGridSourceSpec) </p> <p> <p>AzureEventGridSourceEndpoint contains possible intermediate destinations for events.</p> </p>    Field Description      <code>eventHubs</code>   AzureEventGridSourceDestinationEventHubs","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceEndpoint"},{"title":"AzureEventGridSourceSpec","text":"<p> (Appears on: AzureEventGridSource) </p> <p> <p>AzureEventGridSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>scope</code>   AzureResourceID     <p>The resource ID the event subscription applies to.</p> <p>Can be - an Azure subscription: /subscriptions/{subscriptionId} - a resource group: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName} - a top-level resource from a resource provider (including Event Grid topic): /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>If not specified, Azure automatically selects all available event types for the provided Scope.</p> <p>For a list of all available event types, please refer to the list of Azure services that support system topics at https://docs.microsoft.com/en-us/azure/event-grid/system-topics</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceSpec"},{"title":"AzureEventGridSourceStatus","text":"<p> (Appears on: AzureEventGridSource) </p> <p> <p>AzureEventGridSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>eventSubscriptionID</code>   AzureResourceID     <p>Resource ID of the Event Grid subscription that is currently registered for the user-provided scope.</p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance that is currently receiving events from the Azure Event Grid subscription.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceStatus"},{"title":"AzureEventHubsSourceSpec","text":"<p> (Appears on: AzureEventHubsSource) </p> <p> <p>AzureEventHubsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureEventHubsSourceSpec"},{"title":"AzureIOTHubSourceSpec","text":"<p> (Appears on: AzureIOTHubSource) </p> <p> <p>AzureIOTHubSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   AzureAuth     <p>AzureAuth contains multiple authentication methods for Azure services.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureIOTHubSourceSpec"},{"title":"AzureQueueStorageSourceSpec","text":"<p> (Appears on: AzureQueueStorageSource) </p> <p> <p>AzureQueueStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>accountName</code>  string        <code>queueName</code>  string        <code>accountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureQueueStorageSourceSpec"},{"title":"AzureResourceID","text":"<p> (Appears on: AzureActivityLogsSourceDestinationEventHubs,  AzureBlobStorageSourceSpec,  AzureBlobStorageSourceStatus,  AzureEventGridSourceDestinationEventHubs,  AzureEventGridSourceSpec,  AzureEventGridSourceStatus,  AzureEventHubsSourceSpec,  AzureServiceBusQueueSourceSpec,  AzureServiceBusTopicSourceSpec,  AzureServiceBusTopicSourceStatus) </p> <p> <p>AzureResourceID represents a resource ID for an Azure resource.</p> </p>    Field Description      <code>SubscriptionID</code>  string        <code>ResourceGroup</code>  string        <code>ResourceProvider</code>  string        <code>Namespace</code>  string        <code>ResourceType</code>  string        <code>ResourceName</code>  string        <code>SubResourceType</code>  string        <code>SubResourceName</code>  string","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureResourceID"},{"title":"AzureSASToken","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureSASToken represents an Azure SAS token.</p> </p>    Field Description      <code>keyName</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keyValue</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>connectionString</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureSASToken"},{"title":"AzureServiceBusQueueSourceSpec","text":"<p> (Appears on: AzureServiceBusQueueSource) </p> <p> <p>AzureServiceBusQueueSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>queueID</code>   AzureResourceID     <p>The resource ID the Service Bus Queue to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/queues/{queueName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with Azure Service Bus. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusQueueSourceSpec"},{"title":"AzureServiceBusTopicSourceSpec","text":"<p> (Appears on: AzureServiceBusTopicSource) </p> <p> <p>AzureServiceBusTopicSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topicID</code>   AzureResourceID     <p>The resource ID the Service Bus Topic to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/topics/{topicName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication. If it not present, it will try to use Azure AKS Managed Identity</p>     <code>webSocketsEnable</code>  bool    (Optional) <p>WebSocketsEnable</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSourceSpec"},{"title":"AzureServiceBusTopicSourceStatus","text":"<p> (Appears on: AzureServiceBusTopicSource) </p> <p> <p>AzureServiceBusTopicSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscriptionID</code>   AzureResourceID     <p>Resource ID of the Service Bus Subscription that is currently used by the event source for consuming events from the configured Service Bus Topic.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSourceStatus"},{"title":"AzureServicePrincipal","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureServicePrincipal represents an AAD Service Principal.</p> </p>    Field Description      <code>tenantID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.AzureServicePrincipal"},{"title":"CloudEventsSourceSpec","text":"<p> (Appears on: CloudEventsSource) </p> <p> <p>CloudEventsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>credentials</code>   HTTPCredentials     (Optional) <p>Credentials to connect to this source.</p>     <code>path</code>  string    (Optional) <p>Path under which requests are accepted.</p>     <code>rateLimiter</code>   RateLimiter     (Optional) <p>RateLimiter for incoming events per adapter instance. A single CloudEventsSource object can create multiple adapter instances, the rate limiting configuration being applied to each of them individually.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.CloudEventsSourceSpec"},{"title":"Credentials","text":"<p> (Appears on: IBMMQSourceSpec) </p> <p> <p>Credentials holds the auth details.</p> </p>    Field Description      <code>username</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>tls</code>   TLSSpec","location":"reference/sources/#sources.triggermesh.io/v1alpha1.Credentials"},{"title":"Delivery","text":"<p> (Appears on: IBMMQSourceSpec) </p> <p> <p>Delivery defines the source\u2019s message delivery behavior.</p> </p>    Field Description      <code>deadLetterQueue</code>  string        <code>retry</code>  int        <code>deadLetterQueueManager</code>  string    <p>currently not used</p>     <code>backoffDelay</code>  int","location":"reference/sources/#sources.triggermesh.io/v1alpha1.Delivery"},{"title":"GCloudResourceName","text":"<p> (Appears on: GoogleCloudAuditLogsSourceStatus,  GoogleCloudBillingSourceStatus,  GoogleCloudPubSubSourceSpec,  GoogleCloudPubSubSourceStatus,  GoogleCloudSourcePubSubSpec,  GoogleCloudSourceRepositoriesSourceSpec,  GoogleCloudSourceRepositoriesSourceStatus,  GoogleCloudStorageSourceStatus) </p> <p> <p>GCloudResourceName represents a fully qualified resource name, as described at</p> <pre><code>https://cloud.google.com/apis/design/resource_names\n</code></pre> <p>Examples of such resource names include: - projects/{project_name}/topics/{topic_name} - projects/{project_name}/repos/{repo_name} - projects/{project_name}/subscriptions/{subscription_name}</p> </p>    Field Description      <code>Project</code>  string        <code>Collection</code>  string        <code>Resource</code>  string","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GCloudResourceName"},{"title":"GoogleCloudAuditLogsSourceSpec","text":"<p> (Appears on: GoogleCloudAuditLogsSource) </p> <p> <p>GoogleCloudAuditLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>serviceName</code>  string    <p>The GCP service this instance should source audit logs from. Required. example: compute.googleapis.com</p>     <code>methodName</code>  string    <p>The name of the service method or operation. For API calls, this should be the name of the API method. Required. beta.compute.instances.insert</p>     <code>resourceName</code>  string    <p>The resource or collection that is the target of the operation. The name is a scheme-less URI, not including the API service name. example: \u201cprojects/PROJECT_ID/zones/us-central1-a/instances\u201d</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Audit Logs event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSourceSpec"},{"title":"GoogleCloudAuditLogsSourceStatus","text":"<p> (Appears on: GoogleCloudAuditLogsSource) </p> <p> <p>GoogleCloudAuditLogsSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>auditLogsSink</code>  string    <p>ID of the AuditLogSink used to publish audit log messages.</p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSourceStatus"},{"title":"GoogleCloudBillingSourceSpec","text":"<p> (Appears on: GoogleCloudBillingSource) </p> <p> <p>GoogleCloudBillingSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>billingAccountId</code>  string    <p>The identifier for the Cloud Billing account owning the budget.</p>     <code>budgetId</code>  string    <p>The identifier for the Cloud Billing budget. You can locate the budget\u2019s ID in your budget under Manage notifications. The ID is displayed after you select Connect a Pub/Sub topic to this budget.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Billing budget event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSourceSpec"},{"title":"GoogleCloudBillingSourceStatus","text":"<p> (Appears on: GoogleCloudBillingSource) </p> <p> <p>GoogleCloudBillingSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSourceStatus"},{"title":"GoogleCloudPubSubSourceSpec","text":"<p> (Appears on: GoogleCloudPubSubSource) </p> <p> <p>GoogleCloudPubSubSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>subscriptionID</code>  string    (Optional) <p>ID of the subscription to use to pull messages from the topic.</p> <p>If supplied, this subscription must 1) exist and 2) belong to the provided topic. Otherwise, a pull subscription to that topic is created on behalf of the user.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSourceSpec"},{"title":"GoogleCloudPubSubSourceStatus","text":"<p> (Appears on: GoogleCloudPubSubSource) </p> <p> <p>GoogleCloudPubSubSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscription</code>   GCloudResourceName","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSourceStatus"},{"title":"GoogleCloudSourcePubSubSpec","text":"<p> (Appears on: GoogleCloudAuditLogsSourceSpec,  GoogleCloudBillingSourceSpec,  GoogleCloudSourceRepositoriesSourceSpec,  GoogleCloudStorageSourceSpec) </p> <p> <p>GoogleCloudSourcePubSubSpec defines the attributes related to the configuration of Pub/Sub resources.</p> </p>    Field Description      <code>topic</code>   GCloudResourceName     (Optional) <p>Full resource name of the Pub/Sub topic where messages/notifications originating from the configured Google Cloud resource are sent to, before being retrieved by this event source. If not supplied, a topic is created on behalf of the user, in the GCP project referenced by the Project attribute.</p> <p>The expected format is described at https://cloud.google.com/pubsub/docs/admin#resource_names: \u201cprojects/{project_name}/topics/{topic_name}\u201d</p>     <code>project</code>  string    (Optional) <p>Name of the GCP project where Pub/Sub resources associated with the configured Google Cloud resource are to be created.</p> <p>Mutually exclusive with Topic which, if supplied, already contains the project name.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourcePubSubSpec"},{"title":"GoogleCloudSourceRepositoriesSourceSpec","text":"<p> (Appears on: GoogleCloudSourceRepositoriesSource) </p> <p> <p>GoogleCloudSourceRepositoriesSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>repository</code>   GCloudResourceName     <p>Name of the Cloud repo to receive notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the repo events.</p>     <code>publishServiceAccount</code>  string    (Optional) <p>Email address of the service account used for publishing notifications to Pub/Sub. This service account needs to be in the same project as the repo, and to have the \u2018pubsub.topics.publish\u2019 IAM permission associated with it. It can (but doesn\u2019t have to) be the same service account as the \u2018ServiceAccountKey\u2019 attribute.</p> <p>If unspecified, it defaults to the Compute Engine default service account.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSourceSpec"},{"title":"GoogleCloudSourceRepositoriesSourceStatus","text":"<p> (Appears on: GoogleCloudSourceRepositoriesSource) </p> <p> <p>GoogleCloudSourceRepositoriesSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSourceStatus"},{"title":"GoogleCloudStorageSourceSpec","text":"<p> (Appears on: GoogleCloudStorageSource) </p> <p> <p>GoogleCloudStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bucket</code>  string    <p>Name of the Cloud Storage bucket to receive change notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the bucket.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://cloud.google.com/storage/docs/pubsub-notifications#events</p> <p>All types are selected when this attribute is not set.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSourceSpec"},{"title":"GoogleCloudStorageSourceStatus","text":"<p> (Appears on: GoogleCloudStorageSource) </p> <p> <p>GoogleCloudStorageSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>notificationID</code>  string    <p>ID of the managed Cloud Storage bucket notification configuration.</p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSourceStatus"},{"title":"HTTPBasicAuth","text":"<p> (Appears on: HTTPCredentials) </p> <p> <p>HTTPBasicAuth credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.HTTPBasicAuth"},{"title":"HTTPCredentials","text":"<p> (Appears on: CloudEventsSourceSpec) </p> <p> <p>HTTPCredentials to be used when receiving requests.</p> </p>    Field Description      <code>basicAuths</code>   []HTTPBasicAuth","location":"reference/sources/#sources.triggermesh.io/v1alpha1.HTTPCredentials"},{"title":"HTTPPollerSourceSpec","text":"<p> (Appears on: HTTPPollerSource) </p> <p> <p>HTTPPollerSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>HTTP/S URL of the endpoint to poll data from.</p>     <code>method</code>  string    <p>HTTP request method to use in requests to the specified \u2018endpoint\u2019. https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods</p>     <code>skipVerify</code>  bool    (Optional) <p>Controls whether the HTTP client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>caCertificate</code>  string    (Optional) <p>CA certificate in X.509 format the HTTP client should use to verify the identity of remote servers when communicating over TLS.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name to set in HTTP requests that require HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password to set in HTTP requests that require HTTP Basic authentication.</p>     <code>headers</code>  map[string]string    (Optional) <p>HTTP headers to include in HTTP requests.</p>     <code>interval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often the HTTP/S endpoint should be polled. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.HTTPPollerSourceSpec"},{"title":"IBMMQSourceSpec","text":"<p> (Appears on: IBMMQSource) </p> <p> <p>IBMMQSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>delivery</code>   Delivery         <code>credentials</code>   Credentials         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.IBMMQSourceSpec"},{"title":"KafkaSourceAuth","text":"<p> (Appears on: KafkaSourceSpec) </p> <p> <p>KafkaSourceAuth contains Authentication method used to interact with Kafka.</p> </p>    Field Description      <code>kerberos</code>   KafkaSourceKerberos         <code>tls</code>   KafkaSourceTLSAuth         <code>saslEnable</code>  bool    <p>SASL Enable</p>     <code>tlsEnable</code>  bool    (Optional) <p>TLS Enable</p>     <code>securityMechanism</code>  string    (Optional) <p>SecurityMechanisms holds the assignment of the specific SASL mechanisms.</p>     <code>username</code>  string    (Optional) <p>Username Kafka account User</p>     <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password Kafka account Password</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceAuth"},{"title":"KafkaSourceKerberos","text":"<p> (Appears on: KafkaSourceAuth) </p> <p> <p>KafkaSourceKerberos contains kerberos credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>realm</code>  string        <code>serviceName</code>  string        <code>configPath</code>  string        <code>keytabPath</code>  string        <code>config</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keytab</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceKerberos"},{"title":"KafkaSourceSpec","text":"<p> (Appears on: KafkaSource) </p> <p> <p>KafkaSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>topic</code>  string    <p>Topic holds the name of the Kafka Topic.</p>     <code>groupID</code>  string    <p>GroupID holds the name of the Kafka Group ID.</p>     <code>auth</code>   KafkaSourceAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceSpec"},{"title":"KafkaSourceTLSAuth","text":"<p> (Appears on: KafkaSourceAuth) </p> <p> <p>KafkaSourceTLSAuth contains kerberos credentials.</p> </p>    Field Description      <code>ca</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientCert</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>skipVerify</code>  bool","location":"reference/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceTLSAuth"},{"title":"Keystore","text":"<p> (Appears on: TLSSpec) </p> <p> <p>Keystore represents Key Database components.</p> </p>    Field Description      <code>keyDatabase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>passwordStash</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.Keystore"},{"title":"OCIMetrics","text":"<p> (Appears on: OCIMetricsSourceSpec) </p> <p> <p>OCIMetrics represents OCI metrics structure.</p> </p>    Field Description      <code>name</code>  string    <p>Human description for the metrics entry</p>     <code>metricsNamespace</code>  string    <p>Namespace for the query metric to use</p>     <code>metricsQuery</code>  string    <p>OCI Metrics Query See https://docs.cloud.oracle.com/en-us/iaas/api/#/en/monitoring/20180401/MetricData</p>     <code>oracleCompartment</code>  string    <p>Oracle Compartment OCID</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.OCIMetrics"},{"title":"OCIMetricsSourceSpec","text":"<p> (Appears on: OCIMetricsSource) </p> <p> <p>OCIMetricsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>oracleApiPrivateKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key</p>     <code>oracleApiPrivateKeyPassphrase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key passphrase</p>     <code>oracleApiPrivateKeyFingerprint</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API cert fingerprint</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region</p>     <code>metricsPollingFrequency</code>  string    (Optional) <p>OCI Metrics Polling Frequency</p>     <code>metrics</code>   []OCIMetrics     <p>Array of metrics</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.OCIMetricsSourceSpec"},{"title":"RateLimiter","text":"<p> (Appears on: CloudEventsSourceSpec) </p> <p> <p>RateLimiter parameters.</p> </p>    Field Description      <code>requestsPerSecond</code>  int    <p>RequestsPerSecond is used to limit the number of requests that a single instance of the CloudEventsSource adapter can accept.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.RateLimiter"},{"title":"SalesforceAuth","text":"<p> (Appears on: SalesforceSourceSpec) </p> <p> <p>SalesforceAuth contains Salesforce credentials.</p> </p>    Field Description      <code>clientID</code>  string        <code>server</code>  string        <code>user</code>  string        <code>certKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SalesforceAuth"},{"title":"SalesforceSourceSpec","text":"<p> (Appears on: SalesforceSource) </p> <p> <p>SalesforceSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   SalesforceAuth     <p>Authentication method to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce.</p>     <code>subscription</code>   SalesforceSubscription     <p>Subscription to a Salesforce channel</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SalesforceSourceSpec"},{"title":"SalesforceSubscription","text":"<p> (Appears on: SalesforceSourceSpec) </p> <p> <p>SalesforceSubscription to connect to.</p> </p>    Field Description      <code>channel</code>  string        <code>replayID</code>  int","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SalesforceSubscription"},{"title":"SlackSourceSpec","text":"<p> (Appears on: SlackSource) </p> <p> <p>SlackSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>signingSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>SigningSecret can be set to the value of Slack request signing secret to authenticate callbacks. See: https://api.slack.com/authentication/verifying-requests-from-slack</p>     <code>appID</code>  string    (Optional) <p>AppID identifies the Slack application generating this event. It helps identifying the App sourcing events when multiple Slack applications shared an endpoint. See: https://api.slack.com/events-api</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.SlackSourceSpec"},{"title":"TLSSpec","text":"<p> (Appears on: Credentials) </p> <p> <p>TLSSpec holds the IBM MQ TLS authentication parameters.</p> </p>    Field Description      <code>cipher</code>  string        <code>clientAuthRequired</code>  bool        <code>certLabel</code>  string        <code>keyRepository</code>   Keystore","location":"reference/sources/#sources.triggermesh.io/v1alpha1.TLSSpec"},{"title":"TwilioSourceSpec","text":"<p> (Appears on: TwilioSource) </p> <p> <p>TwilioSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.TwilioSourceSpec"},{"title":"WebhookEventExtensionAttributes","text":"<p> (Appears on: WebhookSourceSpec) </p> <p> <p>WebhookEventExtensionAttributes sets the policy for converting HTTP data into.</p> </p>    Field Description      <code>from</code>  []string    (Optional) <p>From informs HTTP elements that will be converted into CloudEvents attributes</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.WebhookEventExtensionAttributes"},{"title":"WebhookSourceSpec","text":"<p> (Appears on: WebhookSource) </p> <p> <p>WebhookSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>eventExtensionAttributes</code>   WebhookEventExtensionAttributes     (Optional) <p>Options to transform HTTP request data into CloudEvent extensions. https://github.com/cloudevents/spec/blob/main/cloudevents/spec.md#extension-context-attributes</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>corsAllowOrigin</code>  string    (Optional) <p>Specifies the CORS Origin to use in pre-flight headers.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.WebhookSourceSpec"},{"title":"ZendeskSourceSpec","text":"<p> (Appears on: ZendeskSource) </p> <p> <p>ZendeskSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token identifies the API token used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>email</code>  string    <p>Email identifies the email used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>webhookPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>WebhookPassword used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>webhookUsername</code>  string    <p>WebhookUsername used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>subdomain</code>  string    <p>Subdomain identifies Zendesk subdomain</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.ZendeskSourceSpec"},{"title":"ZendeskSourceStatus","text":"<p> (Appears on: ZendeskSource) </p> <p> <p>ZendeskSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>85a776ff</code>. </p>","location":"reference/sources/#sources.triggermesh.io/v1alpha1.ZendeskSourceStatus"},{"title":"Targets","text":"<p>Package:</p> <ul> <li> targets.triggermesh.io/v1alpha1 </li> </ul>","location":"reference/targets/"},{"title":"targets.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the targets/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> AWSComprehendTarget </li><li> AWSDynamoDBTarget </li><li> AWSEventBridgeTarget </li><li> AWSKinesisTarget </li><li> AWSLambdaTarget </li><li> AWSS3Target </li><li> AWSSNSTarget </li><li> AWSSQSTarget </li><li> AlibabaOSSTarget </li><li> AzureEventHubsTarget </li><li> AzureSentinelTarget </li><li> CloudEventsTarget </li><li> ConfluentTarget </li><li> DatadogTarget </li><li> ElasticsearchTarget </li><li> GoogleCloudFirestoreTarget </li><li> GoogleCloudPubSubTarget </li><li> GoogleCloudStorageTarget </li><li> GoogleCloudWorkflowsTarget </li><li> GoogleSheetTarget </li><li> HTTPTarget </li><li> HasuraTarget </li><li> IBMMQTarget </li><li> JiraTarget </li><li> KafkaTarget </li><li> LogzMetricsTarget </li><li> LogzTarget </li><li> OracleTarget </li><li> SalesforceTarget </li><li> SendGridTarget </li><li> SlackTarget </li><li> SplunkTarget </li><li> TektonTarget </li><li> TwilioTarget </li><li> ZendeskTarget </li></ul>","location":"reference/targets/#targets.triggermesh.io/v1alpha1"},{"title":"AWSComprehendTarget","text":"<p> <p>AWSComprehendTarget is the Schema for an AWS Comprehend Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSComprehendTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSComprehendTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key.</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key.</p>     <code>region</code>  string    <p>Region to use for calling into Comprehend API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>language</code>  string    <p>Language code to use to interact with Comprehend. The supported list can be found at: https://docs.aws.amazon.com/comprehend/latest/dg/supported-languages.html</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSComprehendTarget"},{"title":"AWSDynamoDBTarget","text":"<p> <p>AWSDynamoDBTarget is the Schema for an AWS DynamoDB Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSDynamoDBTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSDynamoDBTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSDynamoDBTarget"},{"title":"AWSEventBridgeTarget","text":"<p> <p>AWSEventBridgeTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSEventBridgeTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSEventBridgeTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the EventBridge Event Bus. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to EventBridge. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTarget"},{"title":"AWSKinesisTarget","text":"<p> <p>AWSKinesisTarget is the Schema for an AWS Kinesis Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSKinesisTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSKinesisTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Kinesis stream. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>partition</code>  string    <p>Kinesis Partition to publish the events to</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in records created in Kinesis. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSKinesisTarget"},{"title":"AWSLambdaTarget","text":"<p> <p>AWSLambdaTarget is the Schema for an AWS Lambda Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSLambdaTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSLambdaTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Lambda function. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awslambda.html#awslambda-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in Lambda function calls. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSLambdaTarget"},{"title":"AWSS3Target","text":"<p> <p>AWSS3Target is the Schema for an AWS s3 Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSS3Target</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSS3TargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the S3 bucket. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html#amazons3-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in S3. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSS3Target"},{"title":"AWSSNSTarget","text":"<p> <p>AWSSNSTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSNSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSNSTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SNS topic. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to SNS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSSNSTarget"},{"title":"AWSSQSTarget","text":"<p> <p>AWSSQSTarget is the Schema for an AWS SQS Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSQSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSQSTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SQS queue. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>messageGroupId</code>  string    (Optional) <p>Message Group ID is required for FIFO based queues, and is used to uniquely identify the event producer https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-understanding-logic.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to SQS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSSQSTarget"},{"title":"AlibabaOSSTarget","text":"<p> <p>AlibabaOSSTarget is the Schema for an Alibaba Object Storage Service Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AlibabaOSSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AlibabaOSSTargetSpec          <code>accessKeyID</code>   SecretValueFromSource     <p>Alibaba SDK access key id as registered. For more information on how to create an access key pair, please refer to https://www.alibabacloud.com/help/doc-detail/53045.htm?spm=a2c63.p38356.879954.9.23bc7d91ARN6Hy#task968.</p>     <code>accessKeySecret</code>   SecretValueFromSource     <p>Alibaba SDK access key secret as registered.</p>     <code>endpoint</code>  string    <p>The domain name used to access the OSS. For more information, please refer to the region and endpoint guide at https://www.alibabacloud.com/help/doc-detail/31837.htm?spm=a2c63.p38356.879954.8.23bc7d91ARN6Hy#concept-zt4-cvy-5db</p>     <code>bucket</code>  string    <p>The unique container to store objects in OSS.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AlibabaOSSTarget"},{"title":"AzureEventHubsTarget","text":"<p> <p>AzureEventHubsTarget is the Schema for an Alibaba Object Storage Service Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventHubsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventHubsTargetSpec          <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventHubID</code>   EventHubResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool        <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureEventHubsTarget"},{"title":"AzureSentinelTarget","text":"<p> <p>AzureSentinelTarget is the Schema for an Azure Sentinel Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureSentinelTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureSentinelTargetSpec          <code>subscriptionID</code>  string    <p>SubscriptionID refers to the Azure Subscription ID that the Azure Sentinel instance is associated with.</p>     <code>resourceGroup</code>  string    <p>ResourceGroup refers to the resource group where the Azure Sentinel instance is deployed.</p>     <code>workspace</code>  string    <p>Workspace refers to the workspace name in Azure Sentinel.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureSentinelTarget"},{"title":"CloudEventsTarget","text":"<p> <p>CloudEventsTarget is a gateway that produces received CloudEvents to a destination.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>CloudEventsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   CloudEventsTargetSpec          <code>credentials</code>   CloudEventsCredentials     (Optional) <p>Credentials to connect to the remote endpoint.</p>     <code>path</code>  string    (Optional) <p>Path at the remote endpoint under which requests are accepted.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint that accept CloudEvents.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>AdapterOverrides sets runtime parameters to the adapter instance.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.CloudEventsTarget"},{"title":"ConfluentTarget","text":"<p> <p>ConfluentTarget is the Schema for an ConfluentTarget.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ConfluentTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ConfluentTargetSpec          <code>username</code>  string    <p>SASLUsername Confluent account User</p>     <code>password</code>   SecretValueFromSource     <p>SASLPassword Confluent account Password</p>     <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>securityProtocol</code>  string    <p>SecurityProtocol allows the user to set the security protocol</p>     <code>saslMechanism</code>  string    <p>SASLMechanisms all the assignment of specific SASL mechanisms.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ConfluentTarget"},{"title":"DatadogTarget","text":"<p> <p>DatadogTarget is the Schema for an HTTP Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>DatadogTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   DatadogTargetSpec          <code>apiKey</code>   SecretValueFromSource     <p>DatadogApiKey represents how Datadog credentials should be provided in the secret</p>     <code>metricPrefix</code>  string    (Optional) <p>MetricPrefix is prepended to the name of the associated metrics.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.DatadogTarget"},{"title":"ElasticsearchTarget","text":"<p> <p>ElasticsearchTarget is the Schema for an Elasticsearch Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ElasticsearchTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ElasticsearchTargetSpec          <code>connection</code>   Connection     (Optional) <p>Connection information to elasticsearch.</p>     <code>indexName</code>  string    <p>IndexName to write to.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Elasticsearch. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ElasticsearchTarget"},{"title":"GoogleCloudFirestoreTarget","text":"<p> <p>GoogleCloudFirestoreTarget is the Schema for the GoogleCloudFirestore Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudFirestoreTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudFirestoreTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Firestore credentials should be provided in the secret</p>     <code>defaultCollection</code>  string    <p>DefaultCollection sets a default Firestore collection to select from</p>     <code>projectID</code>  string    <p>ProjectID specifies the Google project ID</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Firestore. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudFirestoreTarget"},{"title":"GoogleCloudPubSubTarget","text":"<p> <p>GoogleCloudPubSubTarget is the Schema the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudPubSubTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudPubSubTargetSpec          <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>credentialsJson</code>   SecretValueFromSource     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>DiscardCloudEventContext is the policy for how to handle the payload of the CloudEvent.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTarget"},{"title":"GoogleCloudStorageTarget","text":"<p> <p>GoogleCloudStorageTarget is the Schema for an Google Storage Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudStorageTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudStorageTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Storage credentials should be provided in the secret</p>     <code>bucketName</code>  string    <p>BucketName specifies the Google Storage Bucket</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in Google Cloud Storage. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudStorageTarget"},{"title":"GoogleCloudWorkflowsTarget","text":"<p> <p>GoogleCloudWorkflowsTarget is the Schema for an Google Cloud Workflows Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudWorkflowsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudWorkflowsTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>GoogleCloudWorkflowsApiKey represents how GoogleCloudWorkflows credentials should be provided in the secret</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudWorkflowsTarget"},{"title":"GoogleSheetTarget","text":"<p> <p>GoogleSheetTarget is the Schema for an GoogleSheet Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleSheetTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleSheetTargetSpec          <code>googleServiceAccount</code>   SecretValueFromSource     <p>GoogleSheet credential JSON for auth</p>     <code>id</code>  string    <p>ID of Google a spreadsheet</p>     <code>defaultPrefix</code>  string    <p>DefaultPrefix is a pre-defined prefix for the individual sheets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleSheetTarget"},{"title":"HTTPTarget","text":"<p> <p>HTTPTarget is the Schema for an HTTP Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HTTPTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HTTPTargetSpec          <code>response</code>   HTTPEventResponse     <p>Response data to be used at replies.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint to connect to.</p>     <code>method</code>  string    <p>Method to use at requests.</p>     <code>headers</code>  map[string]string    (Optional) <p>Headers to be included at HTTP requests</p>     <code>skipVerify</code>  bool    (Optional) <p>SkipVerify disables server certificate validation.</p>     <code>caCertificate</code>  string    (Optional) <p>CACertificate uses the CA certificate to verify the remote server certificate.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>BasicAuthUsername used for basic authentication.</p>     <code>basicAuthPassword</code>   SecretValueFromSource     (Optional) <p>BasicAuthPassword used for basic authentication.</p>     <code>oauthClientID</code>  string    (Optional) <p>OAuthClientID used for OAuth2 authentication.</p>     <code>oauthClientSecret</code>   SecretValueFromSource     (Optional) <p>OAuthClientSecret used for OAuth2 authentication.</p>     <code>oauthTokenURL</code>  string    (Optional) <p>OAuthTokenURL used for OAuth2 authentication.</p>     <code>oauthScopes</code>  []string    (Optional) <p>OAuthScopes used for OAuth2 authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HTTPTarget"},{"title":"HasuraTarget","text":"<p> <p>HasuraTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HasuraTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HasuraTargetSpec          <code>endpoint</code>  string    <p>The GraphQL server endpoint.</p>     <code>jwt</code>   SecretValueFromSource     (Optional) <p>A user token for interfacing with Hasura.</p>     <code>admin</code>   SecretValueFromSource     (Optional) <p>An alternate token for interfacing with Hasura using admin privileges.</p>     <code>defaultRole</code>  string    (Optional) <p>A default role that the queries should use when running the query.</p>     <code>queries</code>  map[string]string    (Optional) <p>A predefined list of queries that an event can specify in the io.triggermesh.graphql.query event type.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HasuraTarget"},{"title":"IBMMQTarget","text":"<p> <p>IBMMQTarget is the Schema the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>IBMMQTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   IBMMQTargetSpec          <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>replyTo</code>   MQReplyOptions         <code>credentials</code>   Credentials         <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to MQ. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.IBMMQTarget"},{"title":"JiraTarget","text":"<p> <p>JiraTarget is the Schema for the Jira Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>JiraTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   JiraTargetSpec          <code>auth</code>   JiraAuth     <p>Authentication to interact with the Salesforce API.</p>     <code>url</code>  string    <p>URL for Jira service.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.JiraTarget"},{"title":"KafkaTarget","text":"<p> <p>KafkaTarget is the Schema for an KafkaTarget.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>KafkaTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   KafkaTargetSpec          <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int16    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int32    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>auth</code>   KafkaTargetAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.KafkaTarget"},{"title":"LogzMetricsTarget","text":"<p> <p>LogzMetricsTarget receives CloudEvents typed <code>io.triggermesh.opentelemetry.metrics.push</code> that fullfil the schema at https://docs.triggermesh.io/schemas/opentelemetry.metrics.push.json to push new observations.</p> <p>The target works using an OpenTelemetry to Cortex adapter, and is able to manage OpenTelemetry Synchronous Kinds. In case of an error a CloudEvent response conformant with https://docs.triggermesh.io/schemas/triggermesh.error.json and with an the attribute extension <code>category: error</code> can be produced.</p> <p>Due to the buffering nature of this target, not returning an error does not guarantee that the metrics have been pushed to Logz</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>LogzMetricsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   LogzMetricsTargetSpec          <code>connection</code>   LogzMetricsConnection     <p>Connection information for LogzMetrics.</p>     <code>instruments</code>   []Instrument     <p>Instruments configured for pushing metrics. It is mandatory that all metrics pushed by using this target are pre-registered using this list.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsTarget"},{"title":"LogzTarget","text":"<p> <p>LogzTarget is the Schema for the Logz Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>LogzTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   LogzTargetSpec          <code>shippingToken</code>   SecretValueFromSource     <p>ShippingToken defines the API token.</p>     <code>logsListenerURL</code>  string    <p>LogsListenerURL Defines the Log listener URL</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.LogzTarget"},{"title":"OracleTarget","text":"<p> <p>OracleTarget is the Schema for an Oracle Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>OracleTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   OracleTargetSpec          <code>oracleApiPrivateKey</code>   SecretValueFromSource     <p>Oracle User API private key.</p>     <code>oracleApiPrivateKeyPassphrase</code>   SecretValueFromSource     <p>Oracle User API private key passphrase.</p>     <code>oracleApiPrivateKeyFingerprint</code>   SecretValueFromSource     <p>Oracle User API cert fingerprint.</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID.</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key.</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region.</p>     <code>function</code>   OracleFunctionSpecSpec         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.OracleTarget"},{"title":"SalesforceTarget","text":"<p> <p>SalesforceTarget receives CloudEvents typed <code>io.triggermesh.salesforce.apicall</code> that fullfil the schema at https://docs.triggermesh.io/schemas/salesforce.apicall.json and consumes the Salesforce API.</p> <p>Upon a successful call a response is returned typed <code>io.triggermesh.salesforce.apicall.response</code> containing the returned payload as the CloudEvent data and a <code>category: success</code> extension. In case of an error the payload will be conformant with https://docs.triggermesh.io/schemas/triggermesh.error.json and the CloudEvent extension will be set to <code>category: error</code>.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SalesforceTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SalesforceTargetSpec          <code>auth</code>   SalesforceAuth     <p>Authentication information to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce. If not set the latest version will be used.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SalesforceTarget"},{"title":"SendGridTarget","text":"<p> <p>SendGridTarget is the Schema for an Sendgrid Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SendGridTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SendGridTargetSpec          <code>apiKey</code>   SecretValueFromSource     <p>APIKey for account</p>     <code>defaultFromEmail</code>  string    (Optional) <p>DefaultFromEmail is a default email account to assign to the outgoing email\u2019s.</p>     <code>defaultToEmail</code>  string    (Optional) <p>DefaultToEmail is a default recipient email account to assign to the outgoing email\u2019s.</p>     <code>defaultToName</code>  string    (Optional) <p>DefaultToName is a default recipient name to assign to the outgoing email\u2019s.</p>     <code>defaultFromName</code>  string    (Optional) <p>DefaultFromName is a default sender name to assign to the outgoing email\u2019s.</p>     <code>defaultMessage</code>  string    (Optional) <p>DefaultMessage is a default message to assign to the outgoing email\u2019s.</p>     <code>defaultSubject</code>  string    (Optional) <p>DefaultSubject is a default subject to assign to the outgoing email\u2019s.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SendGridTarget"},{"title":"SlackTarget","text":"<p> <p>SlackTarget defines the schema for the Slack target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SlackTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SlackTargetSpec          <code>token</code>   SecretValueFromSource     <p>Token for Slack App</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SlackTarget"},{"title":"SplunkTarget","text":"<p> <p>SplunkTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SplunkTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SplunkTargetSpec          <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>URL of the HTTP Event Collector (HEC). Only the scheme, hostname, and port (optionally) are evaluated, the URL path is trimmed if present. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#Enable_HTTP_Event_Collector</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token for authenticating requests against the HEC. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#About_Event_Collector_tokens</p>     <code>index</code>  string    (Optional) <p>Name of the index to send events to. When undefined, events are sent to the default index defined in the HEC token\u2019s configuration.</p>     <code>skipTLSVerify</code>  bool    (Optional) <p>Controls whether the Splunk client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SplunkTarget"},{"title":"TektonTarget","text":"<p> <p>TektonTarget defines the schema for the Tekton target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TektonTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TektonTargetSpec          <code>reapPolicy</code>   TektonTargetReapPolicy     (Optional) <p>ReapPolicy dictates the reaping policy to be applied for the target</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TektonTarget"},{"title":"TwilioTarget","text":"<p> <p>TwilioTarget is the Schema for an Twilio Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TwilioTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TwilioTargetSpec          <code>sid</code>   SecretValueFromSource     <p>Twilio account SID</p>     <code>token</code>   SecretValueFromSource     <p>Twilio account Token</p>     <code>defaultPhoneFrom</code>  string    (Optional) <p>DefaultPhoneFrom is the purchased Twilio phone we are using</p>     <code>defaultPhoneTo</code>  string    (Optional) <p>DefaultPhoneTo is the destination phone</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TwilioTarget"},{"title":"ZendeskTarget","text":"<p> <p>ZendeskTarget is the Schema for an Zendesk Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ZendeskTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ZendeskTargetSpec          <code>token</code>   SecretValueFromSource     <p>Token contains the Zendesk account Token.</p>     <code>subdomain</code>  string    <p>Subdomain the Zendesk subdomain.</p>     <code>email</code>  string    <p>Email the registered Zendesk email account.</p>     <code>subject</code>  string    (Optional) <p>Subject a static subject assignemnt for every ticket.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ZendeskTarget"},{"title":"AWSComprehendTargetSpec","text":"<p> (Appears on: AWSComprehendTarget) </p> <p> <p>AWSComprehendTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key.</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key.</p>     <code>region</code>  string    <p>Region to use for calling into Comprehend API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>language</code>  string    <p>Language code to use to interact with Comprehend. The supported list can be found at: https://docs.aws.amazon.com/comprehend/latest/dg/supported-languages.html</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSComprehendTargetSpec"},{"title":"AWSDynamoDBTargetSpec","text":"<p> (Appears on: AWSDynamoDBTarget) </p> <p> <p>AWSDynamoDBTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSDynamoDBTargetSpec"},{"title":"AWSEventBridgeTargetSpec","text":"<p> (Appears on: AWSEventBridgeTarget) </p> <p> <p>AWSEventBridgeTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the EventBridge Event Bus. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to EventBridge. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTargetSpec"},{"title":"AWSKinesisTargetSpec","text":"<p> (Appears on: AWSKinesisTarget) </p> <p> <p>AWSKinesisTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Kinesis stream. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>partition</code>  string    <p>Kinesis Partition to publish the events to</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in records created in Kinesis. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSKinesisTargetSpec"},{"title":"AWSLambdaTargetSpec","text":"<p> (Appears on: AWSLambdaTarget) </p> <p> <p>AWSLambdaTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Lambda function. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awslambda.html#awslambda-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in Lambda function calls. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSLambdaTargetSpec"},{"title":"AWSS3TargetSpec","text":"<p> (Appears on: AWSS3Target) </p> <p> <p>AWSS3TargetSpec holds the desired state of the even target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the S3 bucket. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html#amazons3-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in S3. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSS3TargetSpec"},{"title":"AWSSNSTargetSpec","text":"<p> (Appears on: AWSSNSTarget) </p> <p> <p>AWSSNSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SNS topic. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to SNS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSSNSTargetSpec"},{"title":"AWSSQSTargetSpec","text":"<p> (Appears on: AWSSQSTarget) </p> <p> <p>AWSSQSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SQS queue. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>messageGroupId</code>  string    (Optional) <p>Message Group ID is required for FIFO based queues, and is used to uniquely identify the event producer https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-understanding-logic.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to SQS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AWSSQSTargetSpec"},{"title":"AlibabaOSSTargetSpec","text":"<p> (Appears on: AlibabaOSSTarget) </p> <p> <p>AlibabaOSSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>accessKeyID</code>   SecretValueFromSource     <p>Alibaba SDK access key id as registered. For more information on how to create an access key pair, please refer to https://www.alibabacloud.com/help/doc-detail/53045.htm?spm=a2c63.p38356.879954.9.23bc7d91ARN6Hy#task968.</p>     <code>accessKeySecret</code>   SecretValueFromSource     <p>Alibaba SDK access key secret as registered.</p>     <code>endpoint</code>  string    <p>The domain name used to access the OSS. For more information, please refer to the region and endpoint guide at https://www.alibabacloud.com/help/doc-detail/31837.htm?spm=a2c63.p38356.879954.8.23bc7d91ARN6Hy#concept-zt4-cvy-5db</p>     <code>bucket</code>  string    <p>The unique container to store objects in OSS.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AlibabaOSSTargetSpec"},{"title":"AzureAuth","text":"<p> (Appears on: AzureEventHubsTargetSpec,  AzureSentinelTargetSpec) </p> <p> <p>AzureAuth contains multiple authentication methods for Azure services.</p> </p>    Field Description      <code>servicePrincipal</code>   AzureServicePrincipal     <p>Service principals provide a way to create a non-interactive account associated with your identity to which you grant only the privileges your app needs to run. See https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals</p>     <code>sasToken</code>   AzureSASToken     <p>A shared access signature (SAS) provides secure delegated access to resources in a storage account. See https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureAuth"},{"title":"AzureEventHubsTargetSpec","text":"<p> (Appears on: AzureEventHubsTarget) </p> <p> <p>AzureEventHubsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventHubID</code>   EventHubResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool        <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureEventHubsTargetSpec"},{"title":"AzureSASToken","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureSASToken represents an Azure SAS token.</p> </p>    Field Description      <code>keyName</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keyValue</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>connectionString</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureSASToken"},{"title":"AzureSentinelTargetSpec","text":"<p> (Appears on: AzureSentinelTarget) </p> <p> <p>AzureSentinelTargetSpec holds the desired state of the event target.</p> </p>    Field Description      <code>subscriptionID</code>  string    <p>SubscriptionID refers to the Azure Subscription ID that the Azure Sentinel instance is associated with.</p>     <code>resourceGroup</code>  string    <p>ResourceGroup refers to the resource group where the Azure Sentinel instance is deployed.</p>     <code>workspace</code>  string    <p>Workspace refers to the workspace name in Azure Sentinel.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureSentinelTargetSpec"},{"title":"AzureServicePrincipal","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureServicePrincipal represents an AAD Service Principal.</p> </p>    Field Description      <code>tenantID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/targets/#targets.triggermesh.io/v1alpha1.AzureServicePrincipal"},{"title":"CloudEventsCredentials","text":"<p> (Appears on: CloudEventsTargetSpec) </p> <p> <p>CloudEventsCredentials to be used when sending requests.</p> </p>    Field Description      <code>basicAuth</code>   HTTPBasicAuth","location":"reference/targets/#targets.triggermesh.io/v1alpha1.CloudEventsCredentials"},{"title":"CloudEventsTargetSpec","text":"<p> (Appears on: CloudEventsTarget) </p> <p> <p>CloudEventsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentials</code>   CloudEventsCredentials     (Optional) <p>Credentials to connect to the remote endpoint.</p>     <code>path</code>  string    (Optional) <p>Path at the remote endpoint under which requests are accepted.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint that accept CloudEvents.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>AdapterOverrides sets runtime parameters to the adapter instance.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.CloudEventsTargetSpec"},{"title":"ConfluentTargetSpec","text":"<p> (Appears on: ConfluentTarget) </p> <p> <p>ConfluentTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>username</code>  string    <p>SASLUsername Confluent account User</p>     <code>password</code>   SecretValueFromSource     <p>SASLPassword Confluent account Password</p>     <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>securityProtocol</code>  string    <p>SecurityProtocol allows the user to set the security protocol</p>     <code>saslMechanism</code>  string    <p>SASLMechanisms all the assignment of specific SASL mechanisms.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ConfluentTargetSpec"},{"title":"Connection","text":"<p> (Appears on: ElasticsearchTargetSpec) </p> <p> <p>Connection contains connection and configuration parameters</p> </p>    Field Description      <code>addresses</code>  []string    <p>Array of hostnames or IP addresses to connect the target to.</p>     <code>caCert</code>  string    <p>CA Certificate used to verify connection with the Elasticsearch instance.</p>     <code>skipVerify</code>  bool    <p>Skip verification of the SSL certificate during the connection.</p>     <code>username</code>  string    <p>Elasticsearch account username.</p>     <code>password</code>   SecretValueFromSource     <p>Elasticsearch account password.</p>     <code>apiKey</code>   SecretValueFromSource     <p>When informed supersedes username and password.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.Connection"},{"title":"Credentials","text":"<p> (Appears on: IBMMQTargetSpec) </p> <p> <p>Credentials holds the auth details.</p> </p>    Field Description      <code>username</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>tls</code>   TLSSpec","location":"reference/targets/#targets.triggermesh.io/v1alpha1.Credentials"},{"title":"DatadogTargetSpec","text":"<p> (Appears on: DatadogTarget) </p> <p> <p>DatadogTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>apiKey</code>   SecretValueFromSource     <p>DatadogApiKey represents how Datadog credentials should be provided in the secret</p>     <code>metricPrefix</code>  string    (Optional) <p>MetricPrefix is prepended to the name of the associated metrics.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.DatadogTargetSpec"},{"title":"ElasticsearchTargetSpec","text":"<p> (Appears on: ElasticsearchTarget) </p> <p> <p>ElasticsearchTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connection</code>   Connection     (Optional) <p>Connection information to elasticsearch.</p>     <code>indexName</code>  string    <p>IndexName to write to.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Elasticsearch. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ElasticsearchTargetSpec"},{"title":"EventHubResourceID","text":"<p> (Appears on: AzureEventHubsTargetSpec) </p> <p> <p>EventHubResourceID represents a resource ID for an Event Hubs instance or namespace.</p> </p>    Field Description      <code>SubscriptionID</code>  string        <code>ResourceGroup</code>  string        <code>Namespace</code>  string        <code>EventHub</code>  string","location":"reference/targets/#targets.triggermesh.io/v1alpha1.EventHubResourceID"},{"title":"EventOptions","text":"<p> (Appears on: AWSComprehendTargetSpec,  AlibabaOSSTargetSpec,  AzureEventHubsTargetSpec,  AzureSentinelTargetSpec,  DatadogTargetSpec,  ElasticsearchTargetSpec,  GoogleCloudFirestoreTargetSpec,  GoogleCloudPubSubTargetSpec,  GoogleCloudStorageTargetSpec,  GoogleCloudWorkflowsTargetSpec,  IBMMQTargetSpec,  LogzMetricsTargetSpec,  LogzTargetSpec,  SalesforceTargetSpec,  SendGridTargetSpec,  TwilioTargetSpec) </p> <p> <p>EventOptions modifies CloudEvents management at Targets.</p> </p>    Field Description      <code>payloadPolicy</code>  github.com/triggermesh/triggermesh/pkg/targets/adapter/cloudevents.PayloadPolicy    (Optional) <p>PayloadPolicy indicates if replies from the target should include a payload if available. Possible values are:</p> <ul> <li>always: will return a with the reply payload if avaliable.</li> <li>errors: will only reply with payload in case of an error.</li> <li>never: will not reply with payload.</li> </ul>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.EventOptions"},{"title":"GCloudResourceName","text":"<p> (Appears on: GoogleCloudPubSubTargetSpec) </p> <p> <p>GCloudResourceName represents a fully qualified resource name, as described at</p> <pre><code>https://cloud.google.com/apis/design/resource_names\n</code></pre> <p>Examples of such resource names include: - projects/{project_name}/topics/{topic_name} - projects/{project_name}/repos/{repo_name} - projects/{project_name}/subscriptions/{subscription_name}</p> </p>    Field Description      <code>Project</code>  string        <code>Collection</code>  string        <code>Resource</code>  string","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GCloudResourceName"},{"title":"GoogleCloudFirestoreTargetSpec","text":"<p> (Appears on: GoogleCloudFirestoreTarget) </p> <p> <p>GoogleCloudFirestoreTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Firestore credentials should be provided in the secret</p>     <code>defaultCollection</code>  string    <p>DefaultCollection sets a default Firestore collection to select from</p>     <code>projectID</code>  string    <p>ProjectID specifies the Google project ID</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Firestore. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudFirestoreTargetSpec"},{"title":"GoogleCloudPubSubTargetSpec","text":"<p> (Appears on: GoogleCloudPubSubTarget) </p> <p> <p>GoogleCloudPubSubTargetSpec holds the desired state of the event target.</p> </p>    Field Description      <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>credentialsJson</code>   SecretValueFromSource     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>DiscardCloudEventContext is the policy for how to handle the payload of the CloudEvent.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTargetSpec"},{"title":"GoogleCloudPubSubTargetStatus","text":"<p> <p>GoogleCloudPubSubTargetStatus communicates the observed state of the event target.</p> </p>    Field Description      <code>Status</code>   knative.dev/pkg/apis/duck/v1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>AddressStatus</code>   knative.dev/pkg/apis/duck/v1.AddressStatus     <p> (Members of <code>AddressStatus</code> are embedded into this type.) </p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTargetStatus"},{"title":"GoogleCloudStorageTargetSpec","text":"<p> (Appears on: GoogleCloudStorageTarget) </p> <p> <p>GoogleCloudStorageTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Storage credentials should be provided in the secret</p>     <code>bucketName</code>  string    <p>BucketName specifies the Google Storage Bucket</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in Google Cloud Storage. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudStorageTargetSpec"},{"title":"GoogleCloudWorkflowsTargetSpec","text":"<p> (Appears on: GoogleCloudWorkflowsTarget) </p> <p> <p>GoogleCloudWorkflowsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>GoogleCloudWorkflowsApiKey represents how GoogleCloudWorkflows credentials should be provided in the secret</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudWorkflowsTargetSpec"},{"title":"GoogleSheetTargetSpec","text":"<p> (Appears on: GoogleSheetTarget) </p> <p> <p>GoogleSheetTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>googleServiceAccount</code>   SecretValueFromSource     <p>GoogleSheet credential JSON for auth</p>     <code>id</code>  string    <p>ID of Google a spreadsheet</p>     <code>defaultPrefix</code>  string    <p>DefaultPrefix is a pre-defined prefix for the individual sheets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.GoogleSheetTargetSpec"},{"title":"HTTPBasicAuth","text":"<p> (Appears on: CloudEventsCredentials) </p> <p> <p>HTTPBasicAuth credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HTTPBasicAuth"},{"title":"HTTPEventResponse","text":"<p> (Appears on: HTTPTargetSpec) </p> <p> <p>HTTPEventResponse for reply events context.</p> </p>    Field Description      <code>eventType</code>  string    <p>EventType for the reply.</p>     <code>eventSource</code>  string    <p>EventSource for the reply.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HTTPEventResponse"},{"title":"HTTPTargetSpec","text":"<p> (Appears on: HTTPTarget) </p> <p> <p>HTTPTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>response</code>   HTTPEventResponse     <p>Response data to be used at replies.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint to connect to.</p>     <code>method</code>  string    <p>Method to use at requests.</p>     <code>headers</code>  map[string]string    (Optional) <p>Headers to be included at HTTP requests</p>     <code>skipVerify</code>  bool    (Optional) <p>SkipVerify disables server certificate validation.</p>     <code>caCertificate</code>  string    (Optional) <p>CACertificate uses the CA certificate to verify the remote server certificate.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>BasicAuthUsername used for basic authentication.</p>     <code>basicAuthPassword</code>   SecretValueFromSource     (Optional) <p>BasicAuthPassword used for basic authentication.</p>     <code>oauthClientID</code>  string    (Optional) <p>OAuthClientID used for OAuth2 authentication.</p>     <code>oauthClientSecret</code>   SecretValueFromSource     (Optional) <p>OAuthClientSecret used for OAuth2 authentication.</p>     <code>oauthTokenURL</code>  string    (Optional) <p>OAuthTokenURL used for OAuth2 authentication.</p>     <code>oauthScopes</code>  []string    (Optional) <p>OAuthScopes used for OAuth2 authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HTTPTargetSpec"},{"title":"HasuraTargetSpec","text":"<p> (Appears on: HasuraTarget) </p> <p> <p>HasuraTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>endpoint</code>  string    <p>The GraphQL server endpoint.</p>     <code>jwt</code>   SecretValueFromSource     (Optional) <p>A user token for interfacing with Hasura.</p>     <code>admin</code>   SecretValueFromSource     (Optional) <p>An alternate token for interfacing with Hasura using admin privileges.</p>     <code>defaultRole</code>  string    (Optional) <p>A default role that the queries should use when running the query.</p>     <code>queries</code>  map[string]string    (Optional) <p>A predefined list of queries that an event can specify in the io.triggermesh.graphql.query event type.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.HasuraTargetSpec"},{"title":"IBMMQTargetSpec","text":"<p> (Appears on: IBMMQTarget) </p> <p> <p>IBMMQTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>replyTo</code>   MQReplyOptions         <code>credentials</code>   Credentials         <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to MQ. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.IBMMQTargetSpec"},{"title":"Instrument","text":"<p> (Appears on: LogzMetricsTargetSpec) </p> <p> <p>Instrument push metrics for.</p> </p>    Field Description      <code>name</code>  string    <p>Name for the Instrument.</p>     <code>description</code>  string    (Optional) <p>Description for the Instrument</p>     <code>instrument</code>   InstrumentKind     <p>Instrument Kind as defined by OpenTelemetry. Supported values are:</p> <ul> <li>Histogram: for absolute values that can be aggregated.</li> <li>Counter: for delta values that increase monotonically.</li> <li>UpDownCounter: for delta values that can increase and decrease.</li> </ul>     <code>number</code>   NumberKind     <p>Number Kind as defined by OpenTelemetry, defines the measure data type accepted by the Instrument. Supported values are:</p> <ul> <li>Int64.</li> <li>Float64.</li> </ul>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.Instrument"},{"title":"InstrumentKind (<code>string</code> alias)","text":"<p> (Appears on: Instrument) </p> <p> <p>InstrumentKind as defined by OpenTelemetry.</p> </p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.InstrumentKind"},{"title":"JiraAuth","text":"<p> (Appears on: JiraTargetSpec) </p> <p> <p>JiraAuth contains Jira credentials.</p> </p>    Field Description      <code>user</code>  string    <p>Jira username to connect to the instance as.</p>     <code>token</code>   SecretValueFromSource     <p>Jira API token bound to the user.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.JiraAuth"},{"title":"JiraTargetSpec","text":"<p> (Appears on: JiraTarget) </p> <p> <p>JiraTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   JiraAuth     <p>Authentication to interact with the Salesforce API.</p>     <code>url</code>  string    <p>URL for Jira service.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.JiraTargetSpec"},{"title":"KafkaTargetAuth","text":"<p> (Appears on: KafkaTargetSpec) </p> <p> <p>KafkaTargetAuth contains Authentication method used to interact with Kafka.</p> </p>    Field Description      <code>kerberos</code>   KafkaTargetKerberos         <code>tls</code>   KafkaTargetTLSAuth         <code>saslEnable</code>  bool    <p>SASL Enable</p>     <code>tlsEnable</code>  bool    (Optional) <p>TLS Enable</p>     <code>securityMechanism</code>  string    (Optional) <p>SecurityMechanisms holds the assignment of the specific SASL mechanisms.</p>     <code>username</code>  string    (Optional) <p>Username Kafka account User</p>     <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password Kafka account Password</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetAuth"},{"title":"KafkaTargetKerberos","text":"<p> (Appears on: KafkaTargetAuth) </p> <p> <p>KafkaTargetKerberos contains kerberos credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>serviceName</code>  string        <code>configPath</code>  string        <code>keytabPath</code>  string        <code>config</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keytab</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>realm</code>  string","location":"reference/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetKerberos"},{"title":"KafkaTargetSpec","text":"<p> (Appears on: KafkaTarget) </p> <p> <p>KafkaTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int16    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int32    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>auth</code>   KafkaTargetAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetSpec"},{"title":"KafkaTargetTLSAuth","text":"<p> (Appears on: KafkaTargetAuth) </p> <p> <p>KafkaTargetTLSAuth contains kerberos credentials.</p> </p>    Field Description      <code>ca</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientCert</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>skipVerify</code>  bool","location":"reference/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetTLSAuth"},{"title":"Keystore","text":"<p> (Appears on: TLSSpec) </p> <p> <p>Keystore represents Key Database components.</p> </p>    Field Description      <code>keyDatabase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>passwordStash</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"reference/targets/#targets.triggermesh.io/v1alpha1.Keystore"},{"title":"LogzMetricsConnection","text":"<p> (Appears on: LogzMetricsTargetSpec) </p> <p> <p>LogzMetricsConnection contains the information to connect to a Logz tenant to push metrics.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token for connecting to Logz metrics listener.</p>     <code>listenerURL</code>  string    <p>ListenerURL for pushing metrics.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsConnection"},{"title":"LogzMetricsTargetSpec","text":"<p> (Appears on: LogzMetricsTarget) </p> <p> <p>LogzMetricsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connection</code>   LogzMetricsConnection     <p>Connection information for LogzMetrics.</p>     <code>instruments</code>   []Instrument     <p>Instruments configured for pushing metrics. It is mandatory that all metrics pushed by using this target are pre-registered using this list.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsTargetSpec"},{"title":"LogzTargetSpec","text":"<p> (Appears on: LogzTarget) </p> <p> <p>LogzTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>shippingToken</code>   SecretValueFromSource     <p>ShippingToken defines the API token.</p>     <code>logsListenerURL</code>  string    <p>LogsListenerURL Defines the Log listener URL</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.LogzTargetSpec"},{"title":"MQReplyOptions","text":"<p> (Appears on: IBMMQTargetSpec) </p> <p> </p>    Field Description      <code>queueManager</code>  string        <code>queueName</code>  string","location":"reference/targets/#targets.triggermesh.io/v1alpha1.MQReplyOptions"},{"title":"NumberKind (<code>string</code> alias)","text":"<p> (Appears on: Instrument) </p> <p> <p>NumberKind as defined by OpenTelemetry.</p> </p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.NumberKind"},{"title":"OracleFunctionSpecSpec","text":"<p> (Appears on: OracleTargetSpec) </p> <p> <p>OracleFunctionSpecSpec defines the desired state of the event target.</p> </p>    Field Description      <code>function</code>  string    <p> (Members of <code>function</code> are embedded into this type.) </p> <p>Oracle Cloud ID of the function to invoke.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.OracleFunctionSpecSpec"},{"title":"OracleTargetSpec","text":"<p> (Appears on: OracleTarget) </p> <p> <p>OracleTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>oracleApiPrivateKey</code>   SecretValueFromSource     <p>Oracle User API private key.</p>     <code>oracleApiPrivateKeyPassphrase</code>   SecretValueFromSource     <p>Oracle User API private key passphrase.</p>     <code>oracleApiPrivateKeyFingerprint</code>   SecretValueFromSource     <p>Oracle User API cert fingerprint.</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID.</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key.</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region.</p>     <code>function</code>   OracleFunctionSpecSpec         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.OracleTargetSpec"},{"title":"SalesforceAuth","text":"<p> (Appears on: SalesforceTargetSpec) </p> <p> <p>SalesforceAuth contains OAuth JWT information to interact with the Salesforce API. See: https://help.salesforce.com/s/articleView?id=sf.remoteaccess_oauth_jwt_flow.htm</p> </p>    Field Description      <code>clientID</code>  string    <p>ClientID for the Salesforce connected app.</p>     <code>server</code>  string    <p>Server points to the authorization URL.</p>     <code>user</code>  string    <p>User configuring the connected app.</p>     <code>certKey</code>   SecretValueFromSource     <p>CertKey is the private key used to sign requests from the target.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SalesforceAuth"},{"title":"SalesforceTargetSpec","text":"<p> (Appears on: SalesforceTarget) </p> <p> <p>SalesforceTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   SalesforceAuth     <p>Authentication information to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce. If not set the latest version will be used.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SalesforceTargetSpec"},{"title":"SecretValueFromSource","text":"<p> (Appears on: AWSComprehendTargetSpec,  AWSDynamoDBTargetSpec,  AWSEventBridgeTargetSpec,  AWSKinesisTargetSpec,  AWSLambdaTargetSpec,  AWSS3TargetSpec,  AWSSNSTargetSpec,  AWSSQSTargetSpec,  AlibabaOSSTargetSpec,  ConfluentTargetSpec,  Connection,  DatadogTargetSpec,  GoogleCloudFirestoreTargetSpec,  GoogleCloudPubSubTargetSpec,  GoogleCloudStorageTargetSpec,  GoogleCloudWorkflowsTargetSpec,  GoogleSheetTargetSpec,  HTTPTargetSpec,  HasuraTargetSpec,  JiraAuth,  LogzMetricsConnection,  LogzTargetSpec,  OracleTargetSpec,  SalesforceAuth,  SendGridTargetSpec,  SlackTargetSpec,  TwilioTargetSpec,  ZendeskTargetSpec) </p> <p> <p>SecretValueFromSource represents the source of a secret value</p> </p>    Field Description      <code>secretKeyRef</code>   Kubernetes core/v1.SecretKeySelector     <p>The Secret key to select from.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SecretValueFromSource"},{"title":"SendGridTargetSpec","text":"<p> (Appears on: SendGridTarget) </p> <p> <p>SendGridTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>apiKey</code>   SecretValueFromSource     <p>APIKey for account</p>     <code>defaultFromEmail</code>  string    (Optional) <p>DefaultFromEmail is a default email account to assign to the outgoing email\u2019s.</p>     <code>defaultToEmail</code>  string    (Optional) <p>DefaultToEmail is a default recipient email account to assign to the outgoing email\u2019s.</p>     <code>defaultToName</code>  string    (Optional) <p>DefaultToName is a default recipient name to assign to the outgoing email\u2019s.</p>     <code>defaultFromName</code>  string    (Optional) <p>DefaultFromName is a default sender name to assign to the outgoing email\u2019s.</p>     <code>defaultMessage</code>  string    (Optional) <p>DefaultMessage is a default message to assign to the outgoing email\u2019s.</p>     <code>defaultSubject</code>  string    (Optional) <p>DefaultSubject is a default subject to assign to the outgoing email\u2019s.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SendGridTargetSpec"},{"title":"SlackTargetSpec","text":"<p> (Appears on: SlackTarget) </p> <p> <p>SlackTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token for Slack App</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SlackTargetSpec"},{"title":"SplunkTargetSpec","text":"<p> (Appears on: SplunkTarget) </p> <p> <p>SplunkTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>URL of the HTTP Event Collector (HEC). Only the scheme, hostname, and port (optionally) are evaluated, the URL path is trimmed if present. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#Enable_HTTP_Event_Collector</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token for authenticating requests against the HEC. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#About_Event_Collector_tokens</p>     <code>index</code>  string    (Optional) <p>Name of the index to send events to. When undefined, events are sent to the default index defined in the HEC token\u2019s configuration.</p>     <code>skipTLSVerify</code>  bool    (Optional) <p>Controls whether the Splunk client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.SplunkTargetSpec"},{"title":"TLSSpec","text":"<p> (Appears on: Credentials) </p> <p> <p>TLSSpec defines the desired state of the event target.</p> </p>    Field Description      <code>cipher</code>  string        <code>clientAuthRequired</code>  bool        <code>certLabel</code>  string        <code>keyRepository</code>   Keystore","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TLSSpec"},{"title":"TektonTargetReapPolicy","text":"<p> (Appears on: TektonTargetSpec) </p> <p> <p>TektonTargetReapPolicy defines desired Repeating Policy.</p> </p>    Field Description      <code>success</code>  string    <p>ReapSuccessAge How long to wait before reaping runs that were successful</p>     <code>fail</code>  string    <p>ReapFailAge How long to wait before reaping runs that failed</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TektonTargetReapPolicy"},{"title":"TektonTargetSpec","text":"<p> (Appears on: TektonTarget) </p> <p> <p>TektonTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>reapPolicy</code>   TektonTargetReapPolicy     (Optional) <p>ReapPolicy dictates the reaping policy to be applied for the target</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TektonTargetSpec"},{"title":"TwilioTargetSpec","text":"<p> (Appears on: TwilioTarget) </p> <p> <p>TwilioTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>sid</code>   SecretValueFromSource     <p>Twilio account SID</p>     <code>token</code>   SecretValueFromSource     <p>Twilio account Token</p>     <code>defaultPhoneFrom</code>  string    (Optional) <p>DefaultPhoneFrom is the purchased Twilio phone we are using</p>     <code>defaultPhoneTo</code>  string    (Optional) <p>DefaultPhoneTo is the destination phone</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.TwilioTargetSpec"},{"title":"ZendeskTargetSpec","text":"<p> (Appears on: ZendeskTarget) </p> <p> <p>ZendeskTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token contains the Zendesk account Token.</p>     <code>subdomain</code>  string    <p>Subdomain the Zendesk subdomain.</p>     <code>email</code>  string    <p>Email the registered Zendesk email account.</p>     <code>subject</code>  string    (Optional) <p>Subject a static subject assignemnt for every ticket.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>85a776ff</code>. </p>","location":"reference/targets/#targets.triggermesh.io/v1alpha1.ZendeskTargetSpec"},{"title":"tmctl","text":"<p>A command line interface to build event-driven applications</p>","location":"reference/tmctl/tmctl/"},{"title":"Synopsis","text":"<p>tmctl is a CLI to help you create event brokers, sources, targets and transformations.</p> <p>Find more information at: https://docs.triggermesh.io</p>","location":"reference/tmctl/tmctl/#synopsis"},{"title":"Options","text":"<pre><code>      --broker string    Optional broker name.\n  -h, --help             help for tmctl\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl/#options"},{"title":"SEE ALSO","text":"<ul> <li>tmctl brokers  - Show list and switch between existing brokers</li> <li>tmctl config    - Read and write config values</li> <li>tmctl create    - Create TriggerMesh component</li> <li>tmctl delete    - Delete components by names</li> <li>tmctl describe    - Show broker status</li> <li>tmctl dump    - Generate Kubernetes manifest</li> <li>tmctl send-event    - Send CloudEvent to the target</li> <li>tmctl start  - Starts TriggerMesh components</li> <li>tmctl stop    - Stops TriggerMesh components, removes docker containers</li> <li>tmctl version  - CLI version information</li> <li>tmctl watch  - Watch events flowing through the broker</li> </ul>","location":"reference/tmctl/tmctl/#see-also"},{"title":"tmctl brokers","text":"","location":"reference/tmctl/tmctl_brokers/"},{"title":"tmctl brokers","text":"<p>Show list and switch between existing brokers</p> <pre><code>tmctl brokers [--set &lt;broker&gt;] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_brokers/#tmctl-brokers"},{"title":"Options","text":"<pre><code>  -h, --help         help for brokers\n      --set string   Change the current broker\n</code></pre>","location":"reference/tmctl/tmctl_brokers/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_brokers/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_brokers/#see-also"},{"title":"tmctl config","text":"","location":"reference/tmctl/tmctl_config/"},{"title":"tmctl config","text":"<p>Read and write config values</p> <pre><code>tmctl config [set|get] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_config/#tmctl-config"},{"title":"Options","text":"<pre><code>  -h, --help   help for config\n</code></pre>","location":"reference/tmctl/tmctl_config/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_config/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> <li>tmctl config get    - Show config value</li> <li>tmctl config set    - Write config value</li> </ul>","location":"reference/tmctl/tmctl_config/#see-also"},{"title":"tmctl config get","text":"","location":"reference/tmctl/tmctl_config_get/"},{"title":"tmctl config get","text":"<p>Show config value</p> <pre><code>tmctl config get [key] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_config_get/#tmctl-config-get"},{"title":"Options","text":"<pre><code>  -h, --help   help for get\n</code></pre>","location":"reference/tmctl/tmctl_config_get/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_config_get/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl config    - Read and write config values</li> </ul>","location":"reference/tmctl/tmctl_config_get/#see-also"},{"title":"tmctl config set","text":"","location":"reference/tmctl/tmctl_config_set/"},{"title":"tmctl config set","text":"<p>Write config value</p> <pre><code>tmctl config set &lt;key&gt; &lt;value&gt; [flags]\n</code></pre>","location":"reference/tmctl/tmctl_config_set/#tmctl-config-set"},{"title":"Options","text":"<pre><code>  -h, --help   help for set\n</code></pre>","location":"reference/tmctl/tmctl_config_set/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_config_set/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl config    - Read and write config values</li> </ul>","location":"reference/tmctl/tmctl_config_set/#see-also"},{"title":"tmctl create","text":"","location":"reference/tmctl/tmctl_create/"},{"title":"tmctl create","text":"<p>Create TriggerMesh component</p>","location":"reference/tmctl/tmctl_create/#tmctl-create"},{"title":"Options","text":"<pre><code>  -h, --help   help for create\n</code></pre>","location":"reference/tmctl/tmctl_create/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> <li>tmctl create broker  - Create TriggerMesh Broker. More information at https://docs.triggermesh.io/brokers/</li> <li>tmctl create source  - Create TriggerMesh source. More information at https://docs.triggermesh.io</li> <li>tmctl create target  - Create TriggerMesh target. More information at https://docs.triggermesh.io</li> <li>tmctl create transformation  - Create TriggerMesh transformation. More information at https://docs.triggermesh.io/transformation/jsontransformation/</li> <li>tmctl create trigger    - Create TriggerMesh trigger. More information at https://docs.triggermesh.io/brokers/triggers/</li> </ul>","location":"reference/tmctl/tmctl_create/#see-also"},{"title":"tmctl create broker","text":"","location":"reference/tmctl/tmctl_create_broker/"},{"title":"tmctl create broker","text":"<p>Create TriggerMesh Broker. More information at https://docs.triggermesh.io/brokers/</p> <pre><code>tmctl create broker &lt;name&gt; [flags]\n</code></pre>","location":"reference/tmctl/tmctl_create_broker/#tmctl-create-broker"},{"title":"Examples","text":"<pre><code>tmctl create broker foo\n</code></pre>","location":"reference/tmctl/tmctl_create_broker/#examples"},{"title":"Options","text":"<pre><code>  -h, --help   help for broker\n</code></pre>","location":"reference/tmctl/tmctl_create_broker/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create_broker/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl create    - Create TriggerMesh component</li> </ul>","location":"reference/tmctl/tmctl_create_broker/#see-also"},{"title":"tmctl create source","text":"","location":"reference/tmctl/tmctl_create_source/"},{"title":"tmctl create source","text":"<p>Create TriggerMesh source. More information at https://docs.triggermesh.io</p> <pre><code>tmctl create source [kind]/[--from-image &lt;image&gt;][--name &lt;name&gt;] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_create_source/#tmctl-create-source"},{"title":"Examples","text":"<pre><code>tmctl create source httppoller \\\n    --endpoint https://www.example.com \\\n    --eventType sample-event \\\n    --interval 30s  \\\n    --method GET\n</code></pre>","location":"reference/tmctl/tmctl_create_source/#examples"},{"title":"Options","text":"<pre><code>  -h, --help   help for source\n</code></pre>","location":"reference/tmctl/tmctl_create_source/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create_source/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl create    - Create TriggerMesh component</li> </ul>","location":"reference/tmctl/tmctl_create_source/#see-also"},{"title":"tmctl create target","text":"","location":"reference/tmctl/tmctl_create_target/"},{"title":"tmctl create target","text":"<p>Create TriggerMesh target. More information at https://docs.triggermesh.io</p> <pre><code>tmctl create target [kind]/[--from-image &lt;image&gt;][--name &lt;name&gt;][--source &lt;name&gt;...][--eventTypes &lt;type&gt;...] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_create_target/#tmctl-create-target"},{"title":"Examples","text":"<pre><code>tmctl create target http \\\n    --endpoint https://image-charts.com \\\n    --method GET \\\n    --response.eventType qr-data.response\n</code></pre>","location":"reference/tmctl/tmctl_create_target/#examples"},{"title":"Options","text":"<pre><code>  -h, --help   help for target\n</code></pre>","location":"reference/tmctl/tmctl_create_target/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create_target/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl create    - Create TriggerMesh component</li> </ul>","location":"reference/tmctl/tmctl_create_target/#see-also"},{"title":"tmctl create transformation","text":"","location":"reference/tmctl/tmctl_create_transformation/"},{"title":"tmctl create transformation","text":"<p>Create TriggerMesh transformation. More information at https://docs.triggermesh.io/transformation/jsontransformation/</p> <pre><code>tmctl create transformation [--target &lt;name&gt;][--source &lt;name&gt;...][--eventTypes &lt;type&gt;...][--from &lt;path&gt;] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_create_transformation/#tmctl-create-transformation"},{"title":"Examples","text":"<pre><code>tmctl create transformation &lt;&lt;EOF\n  data:\n  - operation: add\n    paths:\n    - key: new-field\n      value: hello from Transformation!\nEOF\n</code></pre>","location":"reference/tmctl/tmctl_create_transformation/#examples"},{"title":"Options","text":"<pre><code>      --eventTypes strings   Event types filter\n  -f, --from string          Transformation specification file\n  -h, --help                 help for transformation\n      --name string          Transformation name\n      --source strings       Sources component names\n      --target string        Target name\n</code></pre>","location":"reference/tmctl/tmctl_create_transformation/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create_transformation/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl create    - Create TriggerMesh component</li> </ul>","location":"reference/tmctl/tmctl_create_transformation/#see-also"},{"title":"tmctl create trigger","text":"","location":"reference/tmctl/tmctl_create_trigger/"},{"title":"tmctl create trigger","text":"<p>Create TriggerMesh trigger. More information at https://docs.triggermesh.io/brokers/triggers/</p> <pre><code>tmctl create trigger --target &lt;name&gt; [--source &lt;name&gt;...][--eventTypes &lt;type&gt;...] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_create_trigger/#tmctl-create-trigger"},{"title":"Examples","text":"<pre><code>tmctl create trigger --target sockeye --source foo-httppollersource\n</code></pre>","location":"reference/tmctl/tmctl_create_trigger/#examples"},{"title":"Options","text":"<pre><code>      --eventTypes strings   Event types filter\n  -h, --help                 help for trigger\n      --name string          Trigger name\n      --source strings       Event sources filter\n      --target string        Target name\n</code></pre>","location":"reference/tmctl/tmctl_create_trigger/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_create_trigger/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl create    - Create TriggerMesh component</li> </ul>","location":"reference/tmctl/tmctl_create_trigger/#see-also"},{"title":"tmctl delete","text":"","location":"reference/tmctl/tmctl_delete/"},{"title":"tmctl delete","text":"<p>Delete components by names</p> <pre><code>tmctl delete &lt;component_name_1, component_name_2...&gt; [--broker &lt;name&gt;] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_delete/#tmctl-delete"},{"title":"Examples","text":"<pre><code>tmctl delete foo-httptarget, foo-awss3source\ntmctl delete --broker foo\n</code></pre>","location":"reference/tmctl/tmctl_delete/#examples"},{"title":"Options","text":"<pre><code>      --broker string   Delete the broker\n  -h, --help            help for delete\n</code></pre>","location":"reference/tmctl/tmctl_delete/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_delete/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_delete/#see-also"},{"title":"tmctl describe","text":"","location":"reference/tmctl/tmctl_describe/"},{"title":"tmctl describe","text":"<p>Show broker status</p> <pre><code>tmctl describe [broker] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_describe/#tmctl-describe"},{"title":"Examples","text":"<pre><code>tmctl describe\n</code></pre>","location":"reference/tmctl/tmctl_describe/#examples"},{"title":"Options","text":"<pre><code>  -h, --help   help for describe\n</code></pre>","location":"reference/tmctl/tmctl_describe/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_describe/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_describe/#see-also"},{"title":"tmctl dump","text":"","location":"reference/tmctl/tmctl_dump/"},{"title":"tmctl dump","text":"<p>Generate Kubernetes manifest</p> <pre><code>tmctl dump [broker] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_dump/#tmctl-dump"},{"title":"Examples","text":"<pre><code>tmctl dump\n</code></pre>","location":"reference/tmctl/tmctl_dump/#examples"},{"title":"Options","text":"<pre><code>  -h, --help            help for dump\n      --knative         Use Knative Eventing components\n  -o, --output string   Output format (default \"yaml\")\n</code></pre>","location":"reference/tmctl/tmctl_dump/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_dump/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_dump/#see-also"},{"title":"tmctl send-event","text":"","location":"reference/tmctl/tmctl_send-event/"},{"title":"tmctl send-event","text":"<p>Send CloudEvent to the target</p> <pre><code>tmctl send-event [--eventType &lt;type&gt;][--target &lt;name&gt;] &lt;data&gt; [flags]\n</code></pre>","location":"reference/tmctl/tmctl_send-event/#tmctl-send-event"},{"title":"Examples","text":"<pre><code>tmctl send-event '{\"hello\":\"world\"}'\n</code></pre>","location":"reference/tmctl/tmctl_send-event/#examples"},{"title":"Options","text":"<pre><code>      --eventType string   CloudEvent Type attribute (default \"triggermesh-local-event\")\n  -h, --help               help for send-event\n      --target string      Component to send the event to. Default is the broker\n</code></pre>","location":"reference/tmctl/tmctl_send-event/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_send-event/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_send-event/#see-also"},{"title":"tmctl start","text":"","location":"reference/tmctl/tmctl_start/"},{"title":"tmctl start","text":"<p>Starts TriggerMesh components</p> <pre><code>tmctl start [broker] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_start/#tmctl-start"},{"title":"Examples","text":"<pre><code>tmctl start\n</code></pre>","location":"reference/tmctl/tmctl_start/#examples"},{"title":"Options","text":"<pre><code>  -h, --help      help for start\n      --restart   Restart components\n</code></pre>","location":"reference/tmctl/tmctl_start/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_start/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_start/#see-also"},{"title":"tmctl stop","text":"","location":"reference/tmctl/tmctl_stop/"},{"title":"tmctl stop","text":"<p>Stops TriggerMesh components, removes docker containers</p> <pre><code>tmctl stop [broker] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_stop/#tmctl-stop"},{"title":"Examples","text":"<pre><code>tmctl stop\n</code></pre>","location":"reference/tmctl/tmctl_stop/#examples"},{"title":"Options","text":"<pre><code>  -h, --help   help for stop\n</code></pre>","location":"reference/tmctl/tmctl_stop/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_stop/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_stop/#see-also"},{"title":"tmctl version","text":"","location":"reference/tmctl/tmctl_version/"},{"title":"tmctl version","text":"<p>CLI version information</p> <pre><code>tmctl version [flags]\n</code></pre>","location":"reference/tmctl/tmctl_version/#tmctl-version"},{"title":"Options","text":"<pre><code>  -h, --help   help for version\n</code></pre>","location":"reference/tmctl/tmctl_version/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_version/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_version/#see-also"},{"title":"tmctl watch","text":"","location":"reference/tmctl/tmctl_watch/"},{"title":"tmctl watch","text":"<p>Watch events flowing through the broker</p> <pre><code>tmctl watch [broker] [flags]\n</code></pre>","location":"reference/tmctl/tmctl_watch/#tmctl-watch"},{"title":"Examples","text":"<pre><code>tmctl watch\n</code></pre>","location":"reference/tmctl/tmctl_watch/#examples"},{"title":"Options","text":"<pre><code>  -e, --eventTypes string   Filter events based on type attribute\n  -h, --help                help for watch\n</code></pre>","location":"reference/tmctl/tmctl_watch/#options"},{"title":"Options inherited from parent commands","text":"<pre><code>      --broker string    Optional broker name.\n      --version string   TriggerMesh components version.\n</code></pre>","location":"reference/tmctl/tmctl_watch/#options-inherited-from-parent-commands"},{"title":"SEE ALSO","text":"<ul> <li>tmctl  - A command line interface to build event-driven applications</li> </ul>","location":"reference/tmctl/tmctl_watch/#see-also"},{"title":"AWS CloudWatch source","text":"<p>Consumes events from AWS CloudWatch Metrics.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSCloudWatchSource\nmetadata:\n  name: sample\nspec:\n  region: us-west-2\n  pollingInterval: 2m\n\n  metricQueries:\n  - name: testquery\n    metric:\n      period: 60\n      stat: p90\n      unit: Milliseconds\n      metric:\n        metricName: Duration\n        namespace: AWS/Lambda\n        dimensions:\n        - name: FunctionName\n          value: lambdadumper\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.cloudwatch.metrics.message</code><ul> <li>Schema of the <code>data</code> attribute: com.amazon.cloudwatch.metrics.message.json</li> </ul> </li> <li>type <code>com.amazon.cloudwatch.metrics.metric</code><ul> <li>Schema of the <code>data</code> attribute: com.amazon.cloudwatch.metrics.metric.json</li> </ul> </li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awscloudwatch/"},{"title":"AWS CloudWatch Logs source","text":"<p>Consumes logs from Amazon CloudWatch Logs.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awscloudwatchlogs --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSCloudWatchLogsSource\nmetadata:\n  name: sample\nspec:\n  arn: 'arn:aws:logs:us-west-2:123456789012:log-group:/aws/lambda/lambdadumper:*'\n  pollingInterval: 5m\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.logs.log</code></li> <li>source <code>&lt;arn&gt;</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.logs.log.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awscloudwatchlogs/"},{"title":"AWS CodeCommit source","text":"<p>This event source captures notifications from an AWS CodeCommit repository whenever a specific action, such as a new commit or the creation of a pull request, happens in this repository.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awscodecommit --arn &lt;arn&gt; --branch &lt;branch&gt; --eventTypes pull_request --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSCodeCommitSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:codecommit:us-west-2:123456789012:triggermeshtest\n  branch: master\n\n  eventTypes:\n  - push\n  - pull_request\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>The parameters include the following:</p> <p>Events produced have the following attributes:</p> <ul> <li>types<ul> <li><code>com.amazon.codecommit.push</code></li> <li><code>com.amazon.codecommit.pull_request</code></li> </ul> </li> <li>Schema of the <code>data</code> attribute:<ul> <li>com.amazon.codecommit.push.json</li> <li>com.amazon.codecommit.pull_request.json</li> </ul> </li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awscodecommit/"},{"title":"Prerequisite(s)","text":"<ul> <li>CodeCommit Repository and Branch</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"sources/awscodecommit/#prerequisites"},{"title":"CodeCommit Repository and Branch","text":"<p>If you don't already have an AWS CodeCommit repository, create one by following the instructions at Create an AWS CodeCommit repository. The repository should contain at least one branch. To create one, follow the instructions at Create a branch in AWS CodeCommit.</p> <p></p>","location":"sources/awscodecommit/#codecommit-repository-and-branch"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the AWS CodeCommit repository.</p> <p>The easiest way to obtain the ARN of a CodeCommit repository is by using the AWS CLI. The following command retrieves the information of a repository called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws codecommit get-repository --repository-name triggermeshtest --region us-west-2\n{\n    \"repositoryMetadata\": {\n        \"accountId\": \"123456789012\",\n        \"repositoryId\": \"510acd3d-b96d-473c-bbe4-a8c6799d02a9\",\n        \"repositoryName\": \"triggermeshtest\",\n        \"defaultBranch\": \"main\",\n        \"lastModifiedDate\": \"2020-07-20T20:54:27.806000+02:00\",\n        \"creationDate\": \"2020-07-20T20:49:12.324000+02:00\",\n        \"cloneUrlHttp\": \"https://git-codecommit.eu-central-1.amazonaws.com/v1/repos/triggermeshtest\",\n        \"cloneUrlSsh\": \"ssh://git-codecommit.eu-central-1.amazonaws.com/v1/repos/triggermeshtest\",\n        \"Arn\": \"arn:aws:codecommit:eu-central-1:123456789012:triggermeshtest\"\n    }\n}\n</code></pre> <p>If you don't have the AWS CLI installed on your workstation, you can use the template below to compose a fully qualified ARN of a CodeCommit repository.</p> <pre><code>arn:aws:codecommit:{awsRegion}:{awsAccountId}:{repositoryName}\n</code></pre>","location":"sources/awscodecommit/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon CodeCommit authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh AWS CodeCommit event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"codecommit:GetBranch\",\n                \"codecommit:GetCommit\",\n                \"codecommit:ListPullRequests\",\n                \"codecommit:GetPullRequest\"\n            ],\n            \"Resource\": \"arn:aws:codecommit:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awscodecommit/#api-credentials"},{"title":"AWS Cognito identity","text":"<p>Consumes events from AWS Cognito Identity Pools.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awscognitoidentity --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSCognitoIdentitySource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:cognito-identity:us-west-2:123456789012:identitypool/triggermeshtest\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.cognito-identity.sync_trigger</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.cognito-identity.sync_trigger.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awscognitoidentity/"},{"title":"Amazon Cognito User Pools source","text":"<p>This event source captures messages from an Amazon Cognito User Pool whenever a specific action, such as the creation of a new user, happens in the user identity pool.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awscognitouserpool --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSCognitoUserPoolSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:cognito-idp:us-west-2:123456789012:userpool/us-west-2_abcdefghi\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.cognitouserpool.sync_trigger</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.cognitouserpool.sync_trigger.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awscognitouserpool/"},{"title":"Prerequisite(s)","text":"<ul> <li>Amazon Cognito User Pool</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"sources/awscognitouserpool/#prerequisites"},{"title":"Amazon Cognito User Pool","text":"<p>If you don't already have an Amazon Cognito User Pool, create one by following the instructions in the Getting started with User Pools guide.</p>","location":"sources/awscognitouserpool/#amazon-cognito-user-pool"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon Cognito User Pool.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a User Pool from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:cognito-idp:{awsRegion}:{awsAccountId}:userpool/{poolId}\n</code></pre> <p>Alternatively you can also use the [AWS CLI][aws-cli]. The following command retrieves the ARN of a User Pool in the <code>us-west-2</code> region which has the pool id <code>us-west-2_fak3p001B</code>.</p> <pre><code>$ aws --region us-west-2 cognito-idp describe-user-pool --user-pool-id us-west-2_fak3p001B\n{\n    \"UserPool\": {\n        \"Id\": \"us-west-2_fak3p001B\",\n        ...\n        \"Arn\": \"arn:aws:cognito-idp:us-west-2:043455440429:userpool/us-west-2_fak3p001B\",\n        ...\n    }\n}\n</code></pre>","location":"sources/awscognitouserpool/#amazon-resource-name-arn"},{"title":"API credentials","text":"<p>The TriggerMesh event source for Amazon Cognito User Pools authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon Cognito User Pool event source to list users in any user pool associated with the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSCognitoUserPoolSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"cognito-idp:DescribeUserPool\",\n                \"cognito-idp:ListUsers\"\n            ],\n            \"Resource\": \"arn:aws:cognito-idp:*:*:userpool/*\"\n        }\n    ]\n}\n</code></pre>","location":"sources/awscognitouserpool/#api-credentials"},{"title":"Amazon DynamoDB source","text":"<p>This event source captures changes to items stored in an Amazon DynamoDB Table by reading the time-ordered sequence of item-level modifications from a DynamoDB Stream.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awsdynamodb --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSDynamoDBSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:dynamodb:us-west-2:123456789012:table/triggermeshtest\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.dynamodb.stream_record</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.dynamodb.stream_record.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awsdynamodb/"},{"title":"Prerequisite(s)","text":"<ul> <li>DynamoDB Table and Stream</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"sources/awsdynamodb/#prerequisites"},{"title":"DynamoDB Table and Stream","text":"<p>If you don't already have an Amazon DynamoDB Table, create one by following the instructions at Getting Started with DynamoDB. In order for change notifications to be consumed by the TriggerMesh Amazon DynamoDB event source, it is mandatory to enable a Stream on the DynamoDB Table. To do so, follow the instructions at Enabling a Stream. You are free to select the View type that is the most suitable for your own usage of the event source.</p> <p></p>","location":"sources/awsdynamodb/#dynamodb-table-and-stream"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon DynamoDB Table.</p> <p>This ARN can be obtained directly from the Overview tab after clicking the DynamoDB Table name in the list of existing tables. It typically has the following format:</p> <pre><code>arn:aws:dynamodb:{awsRegion}:{awsAccountId}:table/{tableName}\n</code></pre> <p></p> <p>Alternatively, one can obtain the ARN of a DynamoDB Table by using the AWS CLI. The following command retrieves the information of a table called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws dynamodb describe-table --table-name triggermeshtest --region us-west-2\n{\n    \"Table\": {\n        \"TableName\": \"triggermeshtest\",\n        \"TableStatus\": \"ACTIVE\",\n        \"TableArn\": \"arn:aws:dynamodb:us-west-2:123456789012:table/triggermeshtest\",\n        (...)\n    }\n}\n</code></pre>","location":"sources/awsdynamodb/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon DynamoDB authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh Amazon DynamoDB event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:ListStreams\",\n                \"dynamodb:DescribeStream\",\n                \"dynamodb:GetShardIterator\",\n                \"dynamodb:GetRecords\"\n            ],\n            \"Resource\": \"arn:aws:dynamodb:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awsdynamodb/#api-credentials"},{"title":"Amazon EventBridge source","text":"<p>Consumes events from AWS EventBridge).</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awseventbridge --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSEventBridgeSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:events:us-west-2:123456789012:event-bus/triggermeshtest\n\n  # optional. Defaults to catch-all\n  # https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html\n  eventPattern: |\n    {\n      \"source\": [\"aws.ec2\"],\n      \"detail-type\": [\"EC2 Instance State-change Notification\"],\n      \"detail\": {\n        \"state\": [\"terminated\"]\n      }\n    }\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.events.event</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awseventbridge/"},{"title":"Amazon Kinesis source","text":"<p>This event source acts as a consumer of an Amazon Kinesis Data Stream and forwards all messages it reads after wrapping them in a CloudEvent envelope.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awskinesis --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSKinesisSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:kinesis:us-west-2:123456789012:stream/triggermeshtest\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.kinesis.stream_record</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.kinesis.stream_record.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awskinesis/"},{"title":"Prerequisite(s)","text":"<ul> <li>Kinesis Data Stream</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"sources/awskinesis/#prerequisites"},{"title":"Kinesis Data Stream","text":"<p>If you don't already have an Amazon Kinesis Data Stream, create one by following the instructions at Creating and Updating Data Streams.</p>","location":"sources/awskinesis/#kinesis-data-stream"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon Kinesis Stream.</p> <p>This ARN can be obtained directly from the overview page of the Kinesis Stream. It typically has the following format:</p> <pre><code>arn:aws:kinesis:{awsRegion}:{awsAccountId}:stream/{steamName}\n</code></pre> <p></p> <p>Alternatively, one can obtain the ARN of a Kinesis Stream by using the AWS CLI. The following command retrieves the information of a stream called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws kinesis describe-stream --stream-name triggermeshtest --region us-west-2\n{\n    \"StreamDescription\": {\n        \"StreamARN\": \"arn:aws:kinesis:us-west-2:123456789012:stream/triggermeshtest\",\n        \"StreamName\": \"triggermeshtest\",\n        \"StreamStatus\": \"ACTIVE\",\n        (...)\n    }\n}\n</code></pre>","location":"sources/awskinesis/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon Kinesis authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh Amazon Kinesis event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kinesis:DescribeStream\",\n                \"kinesis:GetShardIterator\",\n                \"kinesis:GetRecords\"\n            ],\n            \"Resource\": \"arn:aws:kinesis:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awskinesis/#api-credentials"},{"title":"Amazon S3 source","text":"<p>This event source subscribes to event notifications from an Amazon S3 bucket. Events are published by S3 to an Amazon SQS queue in order to be consumable by the event source.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awss3 --arn &lt;arn&gt; --eventTypes &lt;eventTypes&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSS3Source\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:s3:::triggermeshtest\n\n  eventTypes:\n  - s3:ObjectCreated:*\n  - s3:ObjectRemoved:*\n\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Parameters:</p> <ul> <li>Bucket ARN: ARN of the S3 bucket, as described in the previous sections.</li> <li>Queue ARN: (optional) ARN of the SQS queue which acts as event destination, in case you prefer to manage   this queue yourself as described in the previous sections.</li> <li>Event types: List of event types to subscribe to.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>types<ul> <li><code>com.amazon.s3.objectcreated</code></li> <li><code>com.amazon.s3.objectremoved</code></li> <li><code>com.amazon.s3.objectrestore</code></li> <li><code>com.amazon.s3.reducedredundancylostobject</code></li> <li><code>com.amazon.s3.replication</code></li> <li><code>com.amazon.s3.testevent</code></li> </ul> </li> <li>Schema of the <code>data</code> attribute: com.amazon.s3.event.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awss3/"},{"title":"Prerequisite(s)","text":"<ul> <li>S3 Bucket</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> <li>SQS Queue (optional)</li> </ul>","location":"sources/awss3/#prerequisites"},{"title":"S3 Bucket","text":"<p>If you didn't already do so, create a S3 bucket by following the instructions at Create your first S3 bucket.</p>","location":"sources/awss3/#s3-bucket"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon S3 bucket.</p>  <p>Note</p> <p>Although not technically required by S3, the ARN provided to this event source may include an AWS region and account ID, in addition to the bucket name. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless a user-managed queue is provided as described in the SQS Queue section of this document.</p> <p>The format of such ARN is:</p> <pre><code>arn:aws:s3:{aws_region}:{aws_account_id}:{bucket_name}\n</code></pre> <p>This information is purely optional and will be determined automatically if not provided.</p>  <p></p>","location":"sources/awss3/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon S3 authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the Amazon S3 event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"S3SourceSetBucketConfig\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetBucketNotification\",\n                \"s3:PutBucketNotification\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*\"\n        },\n        {\n            \"Sid\": \"S3SourceConsumeMessages\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:GetQueueUrl\",\n                \"sqs:ReceiveMessage\",\n                \"sqs:DeleteMessage\"\n            ],\n            \"Resource\": \"arn:aws:sqs:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p>Additionally, the following permissions are also required if you opt for letting the event source manage the SQS queue for you (see next section for more information):</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"S3SourceGetBucketLocation\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*\"\n        },\n        {\n            \"Sid\": \"S3SourceManageQueue\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:CreateQueue\",\n                \"sqs:DeleteQueue\",\n                \"sqs:GetQueueAttributes\",\n                \"sqs:SetQueueAttributes\",\n                \"sqs:GetQueueUrl\",\n                \"sqs:ListQueueTags\",\n                \"sqs:TagQueue\"\n            ],\n            \"Resource\": \"arn:aws:sqs:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awss3/#api-credentials"},{"title":"SQS Queue (optional)","text":"<p>The TriggerMesh event source for Amazon S3 configures the S3 bucket to send event notifications to an Amazon SQS queue.</p> <p>By default, the source creates and manages a SQS queue for that purpose on behalf of the user. An identity-based policy is set on that SQS queue to only accept messages originating from the configured S3 bucket.</p> <p>Alternatively, in case you prefer not to delegate this responsibility to the event source, it is possible to provide your own SQS queue as an event destination. In this scenario, it is your own responsibility to configure the queue according to Amazon's documentation: Configuring a bucket for notifications.</p>","location":"sources/awss3/#sqs-queue-optional"},{"title":"Amazon SNS source","text":"<p>This event source subscribes to messages from a Amazon SNS topic.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;keyID&gt; --auth.credentials.secretAccessKey &lt;key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSSNSSource\nmetadata:\n  name: sample\nspec:\n  arn: arn:aws:sns:us-west-2:123456789012:triggermeshtest\n\n  # For a list of supported subscription attributes, please refer to the following resources:\n  #  * https://docs.aws.amazon.com/sns/latest/api/API_SetSubscriptionAttributes.html\n  #  * https://docs.aws.amazon.com/sns/latest/dg/sns-how-it-works.html\n  subscriptionAttributes:\n    DeliveryPolicy: |\n      {\n        \"healthyRetryPolicy\": {\n          \"numRetries\": 3,\n          \"minDelayTarget\": 20,\n          \"maxDelayTarget\": 20\n        }\n      }\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: aws_access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: aws_secret_access_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Attributes:</p> <ul> <li>AWS ARN: ARN of the SNS topic, as described in the previous sections.</li> <li>DeliveryPolicy: Delivery policy to define how Amazon SNS retries the delivery of messages   to HTTP/S endpoints.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.sns.notification</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.sns.notification.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/awssns/"},{"title":"Prerequisite(s)","text":"<ul> <li>SNS Topic (standard)</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"sources/awssns/#prerequisites"},{"title":"SNS Topic (standard)","text":"<p>If you don't already have an Amazon SNS standard topic, create one by following the instructions in the Getting started with Amazon SNS guide.</p>","location":"sources/awssns/#sns-topic-standard"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon SNS topic.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a SNS topic from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:sns:{awsRegion}:{awsAccountId}:{topicName}\n</code></pre> <p>Alternatively you can also use the AWS CLI. The following command retrieves the ARN of a SNS topic named <code>MyTopic</code> in the <code>us-west-2</code> region.</p> <pre><code>$ aws --region us-west-2 sns list-topics\n{\n    \"Topics\": [\n        ...\n        {\n            \"TopicArn\": \"arn:aws:sns:us-west-2:123456789012:MyTopic\"\n        },\n        ...\n    ]\n}\n</code></pre>","location":"sources/awssns/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon SNS authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon SNS event source to read and delete messages from any topic linked to the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSSNSSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"sns:ConfirmSubscription\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Sid\": \"AWSSNSSourceReconciler\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sns:ListSubscriptionsByTopic\",\n                \"sns:Subscribe\",\n                \"sns:Unsubscribe\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awssns/#api-credentials"},{"title":"Amazon SQS source","text":"<p>Consumes events from an Amazon SQS queue.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source awssqs --arn &lt;arn&gt; --auth.credentials.accessKeyID &lt;access key&gt; --auth.credentials.secretAccessKey &lt;secret key&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSSQSSource\nmetadata:\n  name: sqs-guide\nspec:\n  arn: arn:aws:sqs:us-east-1:123456789012:triggermesh\n  receiveOptions:\n    visibilityTimeout: 30m\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: secret_access_key\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.amazon.sqs.message</code></li> <li>source <code>&lt;arn&gt;</code></li> <li>Schema of the <code>data</code> attribute: com.amazon.sqs.message.json</li> </ul>","location":"sources/awssqs/"},{"title":"Prerequisites","text":"<ul> <li>An SQS Queue</li> <li>The queue's ARN</li> <li>AWS API Credentials</li> </ul>","location":"sources/awssqs/#prerequisites"},{"title":"Create an SQS Queue","text":"<p>If you don't already have an Amazon SQS queue, create one by following the instructions in the Getting started with Amazon SQS guide.</p>","location":"sources/awssqs/#create-an-sqs-queue"},{"title":"Obtain the queue's ARN","text":"<p>A fully qualified Amazon Resource Name (ARN) is required to uniquely identify the Amazon SQS queue.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a SQS queue from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:sqs:{awsRegion}:{awsAccountId}:{queueName}\n</code></pre> <p>Alternatively you can also use the AWS CLI. The following command retrieves the ARN of a SQS queue named <code>MyQueue</code> in the <code>us-west-2</code> region.</p> <pre><code>$ aws --region us-west-2 sqs get-queue-attributes --queue-url $(aws --region us-west-2 sqs list-queues --queue-name MyQueue | jq -r .QueueUrls[0]) --attribute-names QueueArn\n{\n    \"Attributes\": {\n        \"QueueArn\": \"arn:aws:sqs:us-west-2:123456789012:MyQueue\"\n    }\n}\n</code></pre>","location":"sources/awssqs/#obtain-the-queues-arn"},{"title":"Obtain AWS API Credentials","text":"<p>The TriggerMesh event source for Amazon SQS can authenticate calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon SQS event source to read and delete messages from any queue linked to the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSSQSSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:GetQueueUrl\",\n                \"sqs:ReceiveMessage\",\n                \"sqs:DeleteMessage\"\n            ],\n            \"Resource\": [\n                \"arn:aws:sqs:*:*:*\"\n            ]\n        }\n    ]\n}\n</code></pre> <p></p>","location":"sources/awssqs/#obtain-aws-api-credentials"},{"title":"Guide to SQS source on Kubernetes","text":"","location":"sources/awssqs/#guide-to-sqs-source-on-kubernetes"},{"title":"Creating a K8s secret","text":"<p>Create a secret called <code>awscreds</code> which contains your access key and your secret key like so:</p> <pre><code>kubectl create secret generic awscreds \\\n  --from-literal=access_key_id=&lt;ACCESS_KEY_ID&gt; \\\n  --from-literal=secret_access_key=&lt;SECRET_ACCESS_KEY&gt;\n</code></pre>","location":"sources/awssqs/#creating-a-k8s-secret"},{"title":"Writing and applying a YAML manifest","text":"<p>Then, write a YAML manifest for your SQS source similar to the one below. The following sample points to a SQS queue, referenced by its ARN and a secret called <code>awscreds</code>.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSSQSSource\nmetadata:\n  name: sqs-guide\nspec:\n  arn: arn:aws:sqs:us-east-1:123456789012:triggermesh\n  receiveOptions:\n    visibilityTimeout: 30m\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: secret_access_key\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Create this source with the <code>kubectl apply -f</code> command.</p> <p>Verify that your source is ready with:</p> <pre><code>$ kubectl get awssqssource\nNAME          READY   REASON   SINK                                      AGE\nsqs-guide     True             http://sockeye.sebgoa.svc.cluster.local   3m57s\n</code></pre>","location":"sources/awssqs/#writing-and-applying-a-yaml-manifest"},{"title":"Test the flow","text":"<p>You can go to the AWS SQS console and put a message in the queue as shown in the following screenshot:</p> <p></p> <p>The message will get consumed by the source.</p> <p>Below is a screenshot of an example event shown using the Sockeye event display service as a target.</p> <p></p>","location":"sources/awssqs/#test-the-flow"},{"title":"Azure Activity Logs Source","text":"<p>Captures Activity Logs from a given Azure Subscription by routing them through Azure Event Hubs. It does so by registering Diagnostic Settings that automatically send a selected set of log categories to a dedicated Event Hub, then subscribing to the events from that Event Hub.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureactivitylogs --subscriptionID &lt;id&gt; --destination.eventHubs.namespaceID &lt;namespaceID&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureActivityLogsSource\nmetadata:\n  name: sample\nspec:\n  subscriptionID: 00000000-0000-0000-0000-000000000000\n\n  # Available Activity Log categories are documented at\n  # https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-schema#categories\n  categories:\n  - Administrative\n  - Security\n  - Policy\n\n  destination:\n    eventHubs:\n      namespaceID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientSecret:\n        value: some_secret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>  <p>Note</p> <p>The ID of the Azure subscription which Activity Logs are to be subscribed to is inferred from the Event Hub ID parameter below. Therefore, the form does not require providing a subscription ID explicitly.</p>  <ul> <li>categories: (optional) Categories of Activity Logs to collect. All available categories are       selected when the list of categories is left empty.</li> <li>destination.eventHubs.namespaceID or hubName: Resource ID of either<ul> <li>an Event Hubs namespace (Event Hub managed by Azure, defaults to <code>insights-activity-logs</code>)</li> <li>an Event Hubs instance (Event Hub managed by the user)</li> </ul> </li> <li>destination.eventhubs.sasPolicy: (optional) Name of a SAS policy with Manage permissions on the Event Hubs namespace   referenced in the Event Hub ID field. Uses Azure's default \"RootManageSharedAccessKey\" policy if not provided.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.microsoft.azure.monitor.activity-log</code></li> <li>Schema of the <code>data</code> attribute: com.microsoft.azure.monitor.activity-log.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureactivitylogs/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Principal</li> <li>Event Hubs Namespace</li> <li>Event Hubs Instance (optional)</li> <li>Shared Access Policy / Shared Access Signature (SAS)</li> </ul>","location":"sources/azureactivitylogs/#prerequisites"},{"title":"Service Principal","text":"<p>A Service Principal is required in order to authenticate the event source against the Azure tenant that has authority over the Azure Subscription to monitor. You can create a Service Principal by following the instructions at How to: Use the portal to create an Azure AD application and service principal that can access resources.</p> <p>The section called Assign a role to the application describes how to assign permissions to the Service Principal. Make sure you select a role which has at least the following permissions:</p> <ul> <li><code>Microsoft.Insights/DiagnosticSettings/Read</code></li> <li><code>Microsoft.Insights/DiagnosticSettings/Delete</code></li> <li><code>Microsoft.Insights/DiagnosticSettings/Write</code></li> <li><code>Microsoft.EventHub/namespaces/authorizationRules/listkeys/action</code></li> </ul> <p>Additionally, assign the role <code>Azure Event Hubs Data Receiver</code> to the Service Principal to allow it to receive events from Event Hubs.</p> <p>In the example below, we create a custom IAM role that is dedicated to the TriggerMesh Activity Logs event source:</p> <p> </p> <p>The corresponding role JSON is given as a reference which you can replicate to create a similar custom IAM role:</p> <pre><code>{\n    \"properties\": {\n        \"roleName\": \"TriggerMesh Activity logs manager\",\n        \"description\": \"Allows the usage of TriggerMesh event sources for Azure Activity Logs.\",\n        \"assignableScopes\": [\n            \"/subscriptions/d2f958de-93b1-4c73-9ce0-b7e1dc43c4ba\"\n        ],\n        \"permissions\": [\n            {\n                \"actions\": [\n                    \"Microsoft.Insights/DiagnosticSettings/Read\",\n                    \"Microsoft.Insights/DiagnosticSettings/Delete\",\n                    \"Microsoft.Insights/DiagnosticSettings/Write\",\n                    \"Microsoft.EventHub/namespaces/authorizationRules/listkeys/action\"\n                ],\n                \"notActions\": [],\n                \"dataActions\": [],\n                \"notDataActions\": []\n            }\n        ]\n    }\n}\n</code></pre> <p>After the Service Principal is created and assigned suitable roles, take note of the following information:</p> <ul> <li>Tenant ID and Client ID (see Get tenant and app ID values for signing in)</li> <li>Client secret (see Create a new application secret)</li> </ul>","location":"sources/azureactivitylogs/#service-principal"},{"title":"Event Hubs Namespace","text":"<p>Follow the instructions at Quickstart: Create an Event Hub using Azure portal, and create a new Event Hubs namespace. This namespace will contain an Event Hubs instance which will be configured by the event source as the destination of Activity Logs originating from the Azure subscription.</p> <p></p>","location":"sources/azureactivitylogs/#event-hubs-namespace"},{"title":"Event Hubs Instance (optional)","text":"<p>This section can be skipped if you would like to let Azure manage the destination Event Hub. When the Event Hub's name is omitted upon deployment of the event source, Azure creates an Event Hub with the name <code>insights-activity-logs</code> upon reception of the first log entry (which can take a few minutes).</p> <p>If, however, you prefer to provide your own Event Hub for that purpose, follow the instructions at Quickstart: Create an Event Hub using Azure portal to create an Event Hubs instance. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Activity Logs event source.</p> <p>A resource ID for an Event Hub has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventHubs/{eventHubName}\n</code></pre>  <p>Note</p> <p>The resource ID of the corresponding Event Hubs namespace is obtained by simply omitting the <code>/eventHubs/{eventHubName}</code> part of the Event Hub's resource ID.</p>  <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az eventhubs eventhub show --resource-group activitylogs-source-dev --namespace-name triggermesh-event-sources --name my-logs\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/activitylogs-source-dev/providers/Microsoft.EventHub/namespaces/triggermesh-event-sources/eventhubs/my-logs\",\n  \"resourceGroup\": \"activitylogs-source-dev\",\n  \"type\": \"Microsoft.EventHub/Namespaces/EventHubs\",\n  \"name\": \"my-logs\",\n  \"location\": \"East US\",\n  \"status\": \"Active\",\n  ...\n}\n</code></pre>","location":"sources/azureactivitylogs/#event-hubs-instance-optional"},{"title":"Shared Access Policy / Shared Access Signature (SAS)","text":"<p>The TriggerMesh Activity Logs event source requires a reference to the name of a Shared Access Policy (also called Shared Access Signatures). This policy contains a token that can be used to delegate permissions within an Event Hubs namespace, such as the management of Event Hub instances.</p> <p>Open your Event Hubs namespace, then open the Shared access policies panel under the Settings section of the Event Hubs screen. By default, the namespace contains a pre-created policy called <code>RootManageSharedAccessKey</code> with <code>Manage, Send, Listen</code> claims, which is perfectly suitable for the TriggerMesh Activity Logs event source. If you prefer to use your own policy instead, make sure it has the same <code>Manage, Send, Listen</code> claims as the default policy.</p> <p></p>","location":"sources/azureactivitylogs/#shared-access-policy-shared-access-signature-sas"},{"title":"Checking that you're receiving logs","text":"<p>After creating an Azure Activity Logs event source, navigate back to the Event Hubs screen in the Azure Portal. You should see a message count above 0 within the namespace, providing that activity logs are being generated within the Azure Subscription.</p> <p></p>","location":"sources/azureactivitylogs/#checking-that-youre-receiving-logs"},{"title":"Azure Blob Storage source","text":"<p>This event source subscribes to blob events from an Azure Storage Account through an Event Grid subscription. Events are consumed from a dedicated Event Hubs instance.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureblobstorage --storageAccountID &lt;accountID&gt; --endpoint.eventHubs.namespaceID &lt;namespaceID&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureBlobStorageSource\nmetadata:\n  name: sample\nspec:\n  storageAccountID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.Storage/storageAccounts/MyBlobStorage\n\n  endpoint:\n    eventHubs:\n      namespaceID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace\n\n  # Available event types are documented at\n  # https://docs.microsoft.com/en-us/azure/event-grid/event-schema-blob-storage\n  eventTypes:\n  - Microsoft.Storage.BlobCreated\n  - Microsoft.Storage.BlobDeleted\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientSecret:\n        value: some_secret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <ul> <li>Secret: Service Principal authentication credentials, as described in the previous sections.</li> <li>Storage Account ID: Resource ID of the Storage Account.</li> <li>Event Hub ID: Resource ID of either<ul> <li>an Event Hubs namespace (Event Hub managed by the event source)</li> <li>an Event Hubs instance (Event Hub managed by the user)</li> </ul> </li> <li>Event types: (optional) List of event types to subscribe to. <code>BlobCreated</code> and <code>BlobDeleted</code> are   enabled by default when no item is set.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>types<ul> <li><code>Microsoft.Storage.BlobCreated</code></li> <li><code>Microsoft.Storage.BlobDeleted</code></li> <li><code>Microsoft.Storage.BlobRenamed</code></li> <li><code>Microsoft.Storage.DirectoryCreated</code></li> <li><code>Microsoft.Storage.DirectoryDeleted</code></li> <li><code>Microsoft.Storage.DirectoryRenamed</code></li> <li><code>Microsoft.Storage.BlobTierChanged</code></li> <li><code>Microsoft.Storage.AsyncOperationInitiated</code></li> <li><code>Microsoft.Storage.BlobInventoryPolicyCompleted</code></li> </ul> </li> <li>Schema of the <code>data</code> attribute: com.microsoft.azure.blobstorage.event.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureblobstorage/"},{"title":"Prerequisite(s)","text":"<ul> <li>Storage Account</li> <li>Service Principal</li> <li>Event Hubs Namespace</li> <li>Event Hubs Instance (optional)</li> </ul>","location":"sources/azureblobstorage/#prerequisites"},{"title":"Storage Account","text":"<p>If you didn't already do so, create a Storage Account of one of the following supported types: General-purpose V2, BlockBlobStorage or BlobStorage. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Blob Storage event source.</p> <p>A resource ID for a Storage Account has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}\n</code></pre> <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az storage account show --resource-group blobstorage-source-dev --name eventsourcedev\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/blobstorage-source-dev/providers/Microsoft.Storage/storageAccounts/eventsourcedev\",\n  \"resourceGroup\": \"blobstorage-source-dev\",\n  \"type\": \"Microsoft.Storage/storageAccounts\",\n  \"kind\": \"BlobStorage\",\n  \"name\": \"eventsourcedev\",\n  \"location\": \"eastus\",\n  \"provisioningState\": \"Succeeded\",\n  ...\n}\n</code></pre>","location":"sources/azureblobstorage/#storage-account"},{"title":"Service Principal","text":"<p>A Service Principal is required in order to authenticate the event source against the Azure tenant that has authority over the Azure Subscription to monitor. You can create a Service Principal by following the instructions at How to: Use the portal to create an Azure AD application and service principal that can access resources.</p> <p>The section called Assign a role to the application describes how to assign permissions to the Service Principal. Make sure you select a role which has at least the following permissions:</p> <ul> <li><code>Microsoft.EventGrid/eventSubscriptions/read</code></li> <li><code>Microsoft.EventGrid/eventSubscriptions/write</code></li> <li><code>Microsoft.EventGrid/eventSubscriptions/delete</code></li> <li><code>Microsoft.EventHub/namespaces/eventhubs/write</code></li> </ul> <p>The following set of permissions is also required if you decide to delegate the management of the Event Hub to the event source. In case you prefer to use your own Event Hub, these can be safely be omitted. More details on that topic are provided in the Event Hubs Instance section below.</p> <ul> <li><code>Microsoft.EventHub/namespaces/eventhubs/read</code> (optional)</li> <li><code>Microsoft.EventHub/namespaces/eventhubs/delete</code> (optional)</li> </ul> <p>Additionally, assign the built-in role <code>Azure Event Hubs Data Receiver</code> to the Service Principal to allow it to receive events from an Event Hubs instance.</p> <p>In the example below, we create a custom IAM role that is dedicated to the TriggerMesh event source for Azure Blob Storage:</p> <p> </p> <p>The corresponding role JSON is given as a reference which you can replicate to create a similar custom IAM role:</p> <pre><code>{\n    \"properties\": {\n        \"roleName\": \"TriggerMesh Event Grid subscriptions manager\",\n        \"description\": \"Allows the usage of TriggerMesh event sources for Azure Blob Storage.\",\n        \"assignableScopes\": [\n            \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3\"\n        ],\n        \"permissions\": [\n            {\n                \"actions\": [\n                    \"Microsoft.EventGrid/eventSubscriptions/read\",\n                    \"Microsoft.EventGrid/eventSubscriptions/write\",\n                    \"Microsoft.EventGrid/eventSubscriptions/delete\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/read\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/write\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/delete\"\n                ],\n                \"notActions\": [],\n                \"dataActions\": [],\n                \"notDataActions\": []\n            }\n        ]\n    }\n}\n</code></pre> <p>After the Service Principal is created and assigned suitable roles, take note of the following information:</p> <ul> <li>Tenant ID and Client ID (see Get tenant and app ID values for signing in)</li> <li>Client secret (see Create a new application secret)</li> </ul>","location":"sources/azureblobstorage/#service-principal"},{"title":"Event Hubs Namespace","text":"<p>Follow the instructions at Quickstart: Create an Event Hub using Azure portal, and create a new Event Hubs namespace. This namespace will contain an Event Hubs instance which will be configured by the event source as the destination of events originating from the Azure Storage Account.</p> <p></p>","location":"sources/azureblobstorage/#event-hubs-namespace"},{"title":"Event Hubs Instance (optional)","text":"<p>This section can be skipped if you would like to let the event source manage its own Event Hub. In this case, please ensure you granted all necessary permissions to the Service Principal in the previous section.</p> <p>If, however, you prefer to provide your own Event Hub for that purpose, follow the instructions at Quickstart: Create an Event Hub using Azure portal to create an Event Hubs instance. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Blob Storage event source.</p> <p>A resource ID for an Event Hub has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventHubs/{eventHubName}\n</code></pre>  <p>Note</p> <p>The resource ID of the corresponding Event Hubs namespace is obtained by simply omitting the <code>/eventHubs/{eventHubName}</code> part of the Event Hub's resource ID.</p>  <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az eventhubs eventhub show --resource-group blobstorage-source-dev --namespace-name eventsourcedev --name my-event-hub\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/blobstorage-source-dev/providers/Microsoft.EventHub/namespaces/eventsourcedev/eventhubs/my-event-hub\",\n  \"resourceGroup\": \"blobstorage-source-dev\",\n  \"type\": \"Microsoft.EventHub/Namespaces/EventHubs\",\n  \"name\": \"my-event-hub\",\n  \"location\": \"East US\",\n  \"status\": \"Active\",\n  ...\n}\n</code></pre>","location":"sources/azureblobstorage/#event-hubs-instance-optional"},{"title":"Check that everything is in place","text":"<p>This can be confirmed by navigating back to the Azure Portal and ensuring that:</p> <ul> <li>The Storage Account contains a new Event Subscription targeting Event Hubs.</li> <li>The Resource Group contains an Event Grid System Topic with an Event Subscription matching the one from the Storage   Account.</li> </ul> <p> </p>","location":"sources/azureblobstorage/#check-that-everything-is-in-place"},{"title":"Azure EventGrid source","text":"<p>Consumes events from Azure EventGrid.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureEventGridSource\nmetadata:\n  name: sample\nspec:\n  scope: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.Storage/storageAccounts/MyBlobStorage\n\n  eventTypes:\n  - Microsoft.Storage.BlobCreated\n  - Microsoft.Storage.BlobDeleted\n\n  endpoint:\n    eventHubs:\n      namespaceID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientSecret:\n        value: some_secret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureeventgrid/"},{"title":"Azure Event Hubs source","text":"<p>Consumes events from Azure Event Hubs.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureeventhub --eventHubID &lt;hubID&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureEventHubSource\nmetadata:\n  name: sample\nspec:\n  eventHubID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace/eventhubs/MyEvents\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        valueFromSecret:\n          name: azure\n          key: tenantID\n      clientID:\n        valueFromSecret:\n          name: azure\n          key: clientID\n      clientSecret:\n        valueFromSecret:\n          name: azure\n          key: clientSecret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.azure.eventhub.event</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureeventhubs/"},{"title":"Azure IoT Hub source","text":"<p>Consumes events from Azure IoT Hub.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureiothub --auth.sasToken.connectionString.value &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureIOTHubSource\nmetadata:\n  name: sample\nspec:\n  auth:\n    sasToken:\n      connectionString:\n        value: HostName=triggermeshdemo.azure-devices.net;SharedAccessKeyName=demo;SharedAccessKey=&lt;redacted&gt;\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.microsoft.azure.iothub.message</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureiothub/"},{"title":"Azure Queue Storage source","text":"<p>Consumes events from Azure Queue Storage.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azurequeuestorage --accountName &lt;accountName&gt; --accountKey &lt;accountKey&gt; --queueName &lt;queueName&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureQueueStorageSource\nmetadata:\n  name: sample\nspec:\n  accountName: demoaccount\n  queueName: testqueue\n\n  accountKey:\n    valueFromSecret:\n      name: azure-queue-storage\n      key: account_key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.microsoft.azure.queuestorage</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azurequeuestorage/"},{"title":"Azure Service Bus Queue source","text":"<p>Consumes events from Azure Service Bus queues.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureservicebusqueue --queueID &lt;queueID&gt; --auth.sasToken.connectionString.value &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureServiceBusQueueSource\nmetadata:\n  name: sample\nspec:\n  queueID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.ServiceBus/namespaces/MyNamespace/queues/MyQueue\n\n  auth:\n    sasToken:\n      connectionString:\n        value: Endpoint=sb://mynamespace.servicebus.windows.net/;SharedAccessKeyName=ReadOnly;SharedAccessKey=aHpDel7ZCURMDyixudUeciLODz9SxImqqbEXAMPLEKEY;EntityPath=myqueue\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.microsoft.azure.servicebus.message</code></li> <li>Schema of the <code>data</code> attribute: com.microsoft.azure.servicebus.message.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureservicebusqueue/"},{"title":"Azure Service Bus Topic source","text":"<p>Consumes events from Azure Service Bus topics.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source azureservicebustopic --topicID &lt;topicID&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureServiceBusTopicSource\nmetadata:\n  name: sample\nspec:\n  topicID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.ServiceBus/namespaces/MyNamespace/topics/MyTopic\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientID:\n        value: 00000000-0000-0000-0000-000000000000\n      clientSecret:\n        value: some_secret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.microsoft.azure.servicebus.message</code></li> <li>Schema of the <code>data</code> attribute: com.microsoft.azure.servicebus.message.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/azureservicebustopic/"},{"title":"CloudEvents source","text":"<p>The TriggerMesh <code>CloudEventsSource</code> is used to ingest CloudEvents produced from external sources via HTTP. The <code>CloudEventsSource</code> acts as an HTTP server that can receives requests.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source cloudevents\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: CloudEventsSource\nmetadata:\n  name: sample\nspec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type depends on the metadata passed as part of the CloudEvent at runtime, unless overridden</li> <li>Schema of the <code>data</code> attribute is not know by TriggerMesh out of the box</li> </ul> <p>See the Kubernetes object reference for more details.</p> <p>A CloudEvent can be sent to a CloudEventsSource by using <code>curl</code>. The example below includes the optional Basic Authentication and Path.</p>  <p>Calling the CloudEventsSource</p> <pre><code>curl -sSL -u user2:pw2 \"http://cloudeventssource.mycluster.io/mypath\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: json.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Ce-MyAttribute: my value\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Ce-Id: 1234-abcd-x\" \\\n  -d '{\"Hello\":\"world\"}'\n</code></pre>","location":"sources/cloudevents/"},{"title":"Configuring a CloudEventsSource Object","text":"<p>The CloudEventsSource accepts parameters to set authentication, URL path and rate limiter. When succesfuly created it exposes an HTTP endpoint to listen for CloudEvents.</p>","location":"sources/cloudevents/#configuring-a-cloudeventssource-object"},{"title":"Configuring Credentials (Optional)","text":"<p>Credentials can be configured using Basic Authentication using Kubernetes secrets to manage passwords.</p> <p>Credentials are defined as arrays, allowing clients to use multiple user/password items.</p> <p>The credentials are defined under <code>spec.credentials.basicAuths</code>:</p>  <p>Credentials for 2 users</p> <pre><code>spec:\n  credentials:\n    basicAuths:\n    - username: user1\n      password:\n        valueFromSecret:\n          name: password1\n          key: password\n    - username: user2\n      password:\n        valueFromSecret:\n          name: password2\n          key: password\n</code></pre>","location":"sources/cloudevents/#configuring-credentials-optional"},{"title":"Configuring Path (Optional)","text":"<p>The <code>spec.path</code> parameter is used configure the URL path where CloudEvents will be accepted. When specified clients using this component must add the designated <code>path</code> to the URL, obtaining a 404 for any other requested location.</p>  <p>Rate limit at 1000 RPS</p> <pre><code>spec:\n  path: /mypath\n</code></pre>   <p>Using path</p> <p>Path is not usually needed. Configure it when an existing CloudEvents producer is already emitting events using that path and cannot be re-configured.</p>","location":"sources/cloudevents/#configuring-path-optional"},{"title":"Configuring Rate Limiter (Optional)","text":"<p>Rate Limiter is used to filter the quantity of requests per second that an adapter instance can receive. When the configured limit per time window is reached, HTTP code 429 is returned along information on when the client should retry.</p>  <p>Example response when rate limit reached</p> <pre><code>HTTP/1.1 429 Too Many Requests\nretry-after: 1650204469582011930\n</code></pre>  <p>To configure the Rate Limiter use the <code>spec.rateLimiter.requestsPerSecond</code> parameter:</p>  <p>Rate limit at 1000 RPS</p> <pre><code>spec:\n  rateLimiter:\n    requestsPerSecond: 1000\n</code></pre>  <p>It must be noted when configuring the Rate Limiter that:</p>  <p>Rate limiter is per instance</p> <p>The CloudEventsSource component is able to scale under load. The rate limiter value is set individualy per each scaled instance, which means that setting this value does not limit the total ammount of requests that can be received, but protects each instance from receiving more the configured value while informing the caller to re-issue the request.</p>   <p>Rate limiter and scaling</p> <p>A low value of the rate limiter might prevent the adapter from scaling if the configured value is below the scaling rate.</p>","location":"sources/cloudevents/#configuring-rate-limiter-optional"},{"title":"Configuring CloudEvents Sink","text":"<p>The <code>spec.sink</code> parameter is a destination that points to an object or URL that will receive the ingested CloudEvents.</p>  <p>Using a reference</p> <pre><code>spec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>   <p>Using a URL</p> <pre><code>spec:\n  sink:\n    uri: https://mybroker-woodford.triggermesh.io\n</code></pre>","location":"sources/cloudevents/#configuring-cloudevents-sink"},{"title":"Using the CloudEventsSource","text":"<p>Given the CloudEventsSource configuration options depicted in the preceding sections we can create this example CloudEventsSource by creating this object at a TriggerMesh cluster:</p>  <p>Example CloudEventsSource</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: CloudEventsSource\nmetadata:\n  name: sample\nspec:\n  credentials:\n    basicAuths:\n    - username: user1\n      password:\n        valueFromSecret:\n          name: password1\n          key: password\n    - username: user2\n      password:\n        valueFromSecret:\n          name: password2\n          key: password\n  path: /mypath\n  rateLimiter:\n    requestsPerSecond: 1000\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>","location":"sources/cloudevents/#using-the-cloudeventssource"},{"title":"Github source","text":"<p>This event source creates a webhook to listen for incoming Github Events.</p>  <p>Knative source</p> <p>The GitHub source is provided by the Knative project and needs to be installed separately on Kubernetes. This also means it is not currently available in <code>tmctl</code></p>  <p>On Kubernetes:</p> <p>Source</p> <pre><code>apiVersion: sources.knative.dev/v1alpha1\nkind: GitHubSource\nmetadata:\n  name: githubsource-sample\nspec:\n  eventTypes:\n  - pull_request\n  ownerAndRepository: \"&lt;your GitHub org&gt;/&lt;your GitHub repo&gt;\"\n  accessToken:\n    secretKeyRef:\n      name: githubsecret\n      key: accessToken\n  secretToken:\n    secretKeyRef:\n      name: githubsecret\n      key: secretToken\n  sink:\n    ref:\n      apiVersion: messaging.knative.dev/v1alpha1\n      kind: InMemoryChannel\n      name: githubchannel\n</code></pre> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: githubsecret\ntype: Opaque\nstringData:\n  accessToken: \"&lt;your GitHub access token&gt;\"\n  secretToken: \"&lt;your secret token&gt;\"\n</code></pre> <p>The Github event source emits events that begin with <code>dev.knative.source.github.</code> and end in the event type. For example: <code>dev.knative.source.github.pull_request</code>, <code>dev.knative.source.github.create</code>, and <code>dev.knative.source.github.delete</code>.</p>","location":"sources/github/"},{"title":"Prerequisite(s)","text":"<ul> <li>GitHub Tokens</li> </ul>","location":"sources/github/#prerequisites"},{"title":"Create GitHub Tokens","text":"<p>Create a personal access token for GitHub that the GitHub source can use to register webhooks with the GitHub API. Also decide on a secret token that your code will use to authenticate the incoming webhooks from GitHub (secretToken).</p> <p>The token can be named anything you find convenient. The Source requires <code>repo:public_repo</code> and <code>admin:repo_hook</code>, to let it fire events from your public repositories and to create webhooks for those repositories. Copy and save this token; GitHub will force you to generate it again if misplaced.</p> <p>Here's an example for a token named \"GitHubSource Sample\" with the recommended scopes:</p> <p></p>","location":"sources/github/#create-github-tokens"},{"title":"Verify","text":"<p>Verify the GitHub webhook was created by looking at the list of webhooks under the Settings tab in your GitHub repository. A hook should be listed that points to your Knative cluster with a green check mark to the left of the hook URL, as shown below.</p> <p></p>","location":"sources/github/#verify"},{"title":"More Information","text":"<p>More information on the Github Event Source can be found here: https://knative.dev/docs/eventing/samples/github-source/</p>","location":"sources/github/#more-information"},{"title":"Google Cloud Audit Logs source","text":"<p>This event source receives messages from Google Cloud Audit Logs by subscribing to a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source googlecloudauditlogs --serviceName &lt;serviceName&gt; --methodName &lt;methodName&gt; --pubsub.project = &lt;project&gt; --serviceAccountKey $(cat ./key.txt)\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: GoogleCloudAuditLogsSource\nmetadata:\n  name: sample\nspec:\n  serviceName: pubsub.googleapis.com\n  methodName: google.pubsub.v1.Publisher.CreateTopic\n\n  pubsub:\n    project: my-project\n    # Alternatively, provide a pre-existing Pub/Sub topic:\n    # topic: projects/my-project/topics/my-topic\n\n  serviceAccountKey:\n    value: &gt;-\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"0000000000000000000000000000000000000000\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"triggermesh-auditlogs-source@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"000000000000000000000\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/triggermesh-auditlogs-source%40my-project.iam.gserviceaccount.com\"\n      }\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.google.cloud.auditlogs.notification</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/googlecloudauditlogs/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Name: The name of the API service performing the operation. For example, \"pubsub.googleapis.com\".</li> <li>Method Name: The name of the service method or operation. For API calls, this should be                the name of the API method. For example, \"google.pubsub.v1.Publisher.CreateTopic\".</li> <li>Resource Name (Optional): The resource or collection that is the target of the operation. The name is                             a scheme-less URI, not including the API service name. Google Cloud Audit Logs Types</li> </ul>","location":"sources/googlecloudauditlogs/#prerequisites"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Audit Logs.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>logging.sinks.get</code></li> <li><code>logging.sinks.create</code></li> <li><code>logging.sinks.delete</code></li> </ul> <p>The following set of permissions is also required because this source delegates the management of the Pub/Sub subscription to the Pub/Sub Source.</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/logging.admin</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Audit Logs.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Audit Logs event source.</p>","location":"sources/googlecloudauditlogs/#service-account"},{"title":"Google Cloud Billing source","text":"<p>This event source receives messages from a Google Cloud Billing Budget over a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: GoogleCloudBillingSource\nmetadata:\n  name: sample\nspec:\n  billingAccountId: myBillingAccountId\n  budgetId: mybudgetId\n\n  pubsub:\n    project: my-project\n    # Alternatively, provide a pre-existing Pub/Sub topic:\n    # topic: projects/my-project/topics/my-topic\n\n  serviceAccountKey:\n    value: &gt;-\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"0000000000000000000000000000000000000000\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"triggermesh-billing-source@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"000000000000000000000\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/triggermesh-billing-source%40my-project.iam.gserviceaccount.com\"\n      }\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.google.cloud.billing.notification</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/googlecloudbilling/"},{"title":"Prerequisite(s)","text":"<ul> <li>Billing Account ID: The identifier for the Cloud Billing account owning the budget. For example, 01D4EE-079462-DFD6EC.</li> <li>Budget ID: The identifier for the Cloud Billing budget. You can locate the budget's ID in your budget under \"Manage notifications\".              The ID is displayed after you select Connect a Pub/Sub topic to this budget. For example, de72f49d-779b-4945-a127-4d6ce8def0bb.</li> </ul>","location":"sources/googlecloudbilling/#prerequisites"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Billing budget.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>billing.budgets.get</code></li> <li><code>billing.budgets.update</code></li> </ul> <p>The following set of permissions is also required to allow this source to manage the Pub/Sub topic and subscription:</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/billing.costsManager</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Billing.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Billing event source.</p>","location":"sources/googlecloudbilling/#service-account"},{"title":"Known Issues","text":"<p>Because the Google Cloud Billing API doesn't allow disabling a Budget's notifications programmatically, budget notifications will remain enabled even after the deletion of the event source. The destination Pub/Sub topic will nevertheless be deleted, effectively causing the interruption of budget notifications.</p>","location":"sources/googlecloudbilling/#known-issues"},{"title":"Google Cloud Pub/Sub source","text":"<p>This event source subscribes to messages sent to a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source googlecloudpubsub --topic &lt;topic&gt; --serviceAccountKey $(cat ./key.txt)\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: GoogleCloudPubSubSource\nmetadata:\n  name: sample\nspec:\n  topic: projects/my-project/topics/my-topic\n\n  serviceAccountKey:\n    value: &gt;-\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"0000000000000000000000000000000000000000\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"triggermesh-pubsub-source@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"000000000000000000000\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/triggermesh-pubsub-source%40my-project.iam.gserviceaccount.com\"\n      }\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.google.cloud.pubsub.message</code></li> <li>Schema of the <code>data</code> attribute: com.google.cloud.pubsub.message.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/googlecloudpubsub/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Account</li> <li>Pub/Sub Topic</li> <li>Pub/Sub Subscription (optional)</li> </ul>","location":"sources/googlecloudpubsub/#prerequisites"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Pub/Sub. You can create a service account by following the instructions at Creating and managing service accounts.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>pubsub.subscriptions.consume</code></li> <li><code>pubsub.subscriptions.get</code></li> </ul> <p>The following set of permissions is also required if you delegate the management of the Pub/Sub subscription to the event source. In case you prefer to manage the subscription yourself, these can be safely be omitted. More details on that topic are provided in the Pub/Sub Subscription section below.</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> <li><code>pubsub.topics.attachSubscription</code></li> </ul> <p>The predefined <code>roles/pubsub.editor</code> role is one example of role that is suitable for use with the TriggerMesh event source for Google Cloud Pub/Sub.</p> <p></p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Pub/Sub event source.</p>","location":"sources/googlecloudpubsub/#service-account"},{"title":"Pub/Sub Topic","text":"<p>If you don't already have a Pub/Sub topic to subscribe to, create one by following the instructions at Managing topics and subscriptions.</p> <p>Take note of the full topic name, it is a required input to be able to run an instance of the Google Cloud Pub/Sub event source.</p> <p></p>","location":"sources/googlecloudpubsub/#pubsub-topic"},{"title":"Pub/Sub Subscription (optional)","text":"<p>A subscription is required in order to allow the TriggerMesh event source for Google Cloud Pub/Sub to pull messages from a Pub/Sub topic.</p> <p>This section can be skipped if you would like to let the event source manage its own subscription, which is the default behaviour. In this case, please simply ensure you granted all necessary permissions to the service account in the previous section.</p> <p>If, however, you prefer messages to be pulled using a subscription which you manage yourself, please ensure that subscription is a \"pull\" subscription as described in the documentation page Managing topics and subscriptions.</p> <p></p>","location":"sources/googlecloudpubsub/#pubsub-subscription-optional"},{"title":"Google Cloud Source Repositories source","text":"<p>This event source receives messages from a Google Cloud Source Repository over a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: GoogleCloudSourceRepositoriesSource\nmetadata:\n  name: sample\nspec:\n  repository: projects/my-project/repos/my-repo\n\n  publishServiceAccount: pubsub-publisher@my-project.iam.gserviceaccount.com\n\n  serviceAccountKey:\n    value: &gt;-\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"0000000000000000000000000000000000000000\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"triggermesh-repositories-source@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"000000000000000000000\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/triggermesh-repositories-source%40my-project.iam.gserviceaccount.com\"\n      }\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.google.cloud.repositories.notification</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/googlecloudrepositories/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service account</li> <li>Repository</li> <li>Pub/Sub Topic (optional)</li> </ul>","location":"sources/googlecloudrepositories/#prerequisites"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Repositories.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>source.repos.updateRepoConfig</code></li> <li><code>iam.serviceAccounts.actAs</code></li> </ul> <p>The following set of permissions is also required to allow this source to manage the Pub/Sub topic and subscription:</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/source.admin</code>, <code>roles/iam.serviceAccountUser</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Repositories.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Repositories event source.</p>","location":"sources/googlecloudrepositories/#service-account"},{"title":"Repository","text":"<p>Full resource name of the Repository. For example, projects/my-project/repos/my-repo.</p>","location":"sources/googlecloudrepositories/#repository"},{"title":"Pub/Sub Topic (optional)","text":"<p>Full resource name of the Pub/Sub topic where change notifications originating from the configured repo are sent to. If not supplied, a topic is created on behalf of the user, in the GCP project referenced by the 'project' attribute. The expected format is described at https://cloud.google.com/pubsub/docs/admin#resource_names</p>","location":"sources/googlecloudrepositories/#pubsub-topic-optional"},{"title":"Google Cloud Storage source","text":"<p>This event source receives change notifications from a Google Cloud Storage bucket by subscribing to a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source googlecloudstorage --bucket &lt;bucket&gt; --pubsub.project &lt;project&gt; --serviceAccountKey $(cat ./key.txt)\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: GoogleCloudStorageSource\nmetadata:\n  name: sample\nspec:\n  bucket: my-bucket\n\n  pubsub:\n    project: my-project\n    # Alternatively, provide a pre-existing Pub/Sub topic:\n    # topic: projects/my-project/topics/my-topic\n\n  eventTypes:\n  - OBJECT_FINALIZE\n  - OBJECT_DELETE\n\n  serviceAccountKey:\n    value: &gt;-\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"0000000000000000000000000000000000000000\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"triggermesh-storage-source@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"000000000000000000000\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/triggermesh-storage-source%40my-project.iam.gserviceaccount.com\"\n      }\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.google.cloud.storage.notification</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/googlecloudstorage/"},{"title":"Prerequisite(s)","text":"<ul> <li>Event Source for Google Cloud Pub/Sub</li> <li>Storage Bucket</li> <li>Notification Configuration</li> </ul>","location":"sources/googlecloudstorage/#prerequisites"},{"title":"Event Source for Google Cloud Pub/Sub","text":"<p>Change notifications from Cloud Storage buckets can not be consumed directly, but are instead sent to a Google Cloud Pub/Sub topic. Follow the instructions at Event Source for Google Cloud Pub/Sub for setting up a Pub/Sub topic and running an instance of the Pub/Sub event source.</p>  <p>Note</p> <p>As an alternative to a manual creation, the Pub/Sub topic will be created automatically while enabling the Notification Configuration if it doesn't already exist.</p>","location":"sources/googlecloudstorage/#event-source-for-google-cloud-pubsub"},{"title":"Storage Bucket","text":"<p>You can create a Cloud Storage bucket by following the instructions from the Cloud Storage How-To Guides.</p>","location":"sources/googlecloudstorage/#storage-bucket"},{"title":"Notification Configuration","text":"<p>Change notifications need to be enabled in the selected bucket by applying a notification configuration. Follow the instructions at Using Pub/Sub notifications for Cloud Storage to add a new notification configuration using the <code>gsutil</code> command-line tool.</p> <p>Below is an example of command which applies a notification configuration to a bucket called <code>eventsource-dev</code>, with a Pub/Sub topic called <code>triggermesh-storage-source</code> set as event destination.</p> <pre><code>$ gsutil notification create -t triggermesh-storage-source -f json gs://eventsource-dev\nCreated Cloud Pub/Sub topic projects/my-project/topics/triggermesh-storage-source\nCreated notification config projects/_/buckets/eventsource-dev/notificationConfigs/1\n</code></pre> <pre><code>$ gsutil notification list gs://eventsource-dev\nprojects/_/buckets/eventsource-dev/notificationConfigs/1\n        Cloud Pub/Sub topic: projects/my-project/topics/triggermesh-storage-source\n</code></pre>","location":"sources/googlecloudstorage/#notification-configuration"},{"title":"HTTP Poller event source","text":"<p>This event source makes periodic HTTP requests (acting as an HTTP client) to an external HTTP service, and turns the responses into events.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source httppoller --eventType &lt;type&gt; --method GET --endpoint https://example.com --interval 20s\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: HTTPPollerSource\nmetadata:\n  name: sample\nspec:\n  eventType: weather.alerts/kansas\n  eventSource: gov.weather\n\n  endpoint: https://api.weather.gov/alerts/active?area=KS\n  method: GET\n  interval: 20s\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <ul> <li>Name: all TriggerMesh components need a unique name per namespace.</li> <li>Broker: request converted into CloudEvents will be sent to this location.</li> <li>EventType: string that identifies the purpose for all CloudEvent messages produced from this source.</li> <li>EventSource: (optional) string that identifies the origin for all CloudEvent messages produced from this source.</li> <li>Enpoint: URL location for the remote service to be polled.</li> <li>Method: HTTP method.</li> <li>Interval: interval between requests formatted as Go duration.</li> <li>CA Certificate: (optional) CA certificate configured for TLS connection as plain text.</li> <li>Skip Verify: (optional) when set to true skips remote server TLS certificate verification.</li> <li>Basic Auth Username: (optional) HTTP basic authentication username.</li> <li>Basic Auth Password (optional) points to a secret that contains the HTTP basic authentication password.</li> <li>Headers (optional) is a set of key/value pairs that will be set within the HTTP request.</li> </ul> <p><code>Interval</code> is formatted after Go's duration parsing. Most typically this value will contain a number followed by one of \"ns\", \"us\" or \"\u00b5s\", \"ms\", \"s\", \"m\", \"h\". Valid examples are <code>15000ms</code> or <code>15s</code> for 15 seconds, <code>60m</code> or <code>1h</code> for one hour.</p> <p>When using <code>CA Certificate</code> it should be copied into the text area in plain text.</p> <p>Events produced have the following attributes:</p> <ul> <li><code>event-type</code> is set to the source's provided value.</li> <li><code>event-source</code> is set to the source's provided value.</li> <li><code>id</code> is set to a generated UID.</li> <li><code>date</code> is timestamped when generating the CloudEvent at TriggerMesh.</li> </ul> <p>Request response body is used to fill the event payload.</p> <p>See the Kubernetes object reference for more details.</p>","location":"sources/httppoller/"},{"title":"Prerequisite(s)","text":"<ul> <li>An external system that exposes an HTTP endpoint.</li> <li>When using HTTP basic authentication, a secret containing the password.</li> </ul>","location":"sources/httppoller/#prerequisites"},{"title":"IBM MQ source","text":"<p>Consumes events from IBM MQ.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source ibmmq --connectionName &lt;connectionName&gt; --channelName &lt;channelName&gt; --queueManager &lt;queueManager&gt; --queueName &lt;queueName&gt; --credentials.username &lt;username&gt; --credentials.password &lt;password&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: IBMMQSource\nmetadata:\n  name: ibm-mq-source\nspec:\n  connectionName: ibm-mq.default.svc.cluster.local(1414)\n  queueManager: QM1\n  queueName: DEV.QUEUE.1\n  channelName: DEV.APP.SVRCONN\n  delivery:\n    deadLetterQueue: DEV.DEAD.LETTER.QUEUE\n    retry: 3\n  credentials:\n    username:\n      valueFromSecret:\n        name: ibm-mq-secret\n        key: username\n    password:\n      valueFromSecret:\n        name: ibm-mq-secret\n        key: password\n    tls:\n      cipher: TLS_RSA_WITH_AES_128_CBC_SHA256\n      clientAuthRequired: false\n      keyRepository:\n        keyDatabase:\n          valueFromSecret:\n            name: ibm-mq-certificate\n            key: key.kdb\n        passwordStash:\n          valueFromSecret:\n            name: ibm-mq-certificate\n            key: key.sth\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>io.triggermesh.ibm.mq.message</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/ibmmq/"},{"title":"Creating an IBM MQ server for testing on Kubernetes","text":"<p>If you do not have a source for your IBM MQ events, the Kubernetes deployment called mq-server.yaml provided below will deploy an IBM MQ server that you may use for demonstration or testing purposes.</p> <pre><code>kubectl apply -f config/mq-server.yaml\n</code></pre> <p>Forward a port to the IBM MQ Server with</p> <pre><code>kubectl port-forward deployments/ibm-mq-server 9443 -n default\n</code></pre> <p>and then access it at</p> <pre><code>https://localhost:9443/ibmmq/console/\n</code></pre> <p>and login with the user <code>admin</code> and password <code>passw0rd</code>.</p> <p>mq-server.yaml:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibm-mq-server\nspec:\n  selector:\n    matchLabels:\n      app: ibm-mq-server\n  template:\n    metadata:\n      labels:\n        app: ibm-mq-server\n    spec:\n      containers:\n      - name: user-container\n        env:\n        - name: LICENSE\n          value: accept\n        - name: MQ_QMGR_NAME\n          value: QM1\n        - name: MQ_APP_PASSWORD\n          value: mq-app-password\n        image: ibmcom/mq:latest\n        volumeMounts:\n        - mountPath: /etc/mqm/pki/keys/mykey\n          name: certificates\n          readOnly: true\n      volumes:\n      - name: certificates\n        secret:\n          defaultMode: 420\n          secretName: ibm-mq-server-certificate\n\n---\n\n# Self-signed test certificate.\napiVersion: v1\ndata:\n  key.kdb: MIIE2gIBAzCCBKIGCSqGSIb3DQEHAaCCBJMEggSPMIIEizCCBIcGCSqGSIb3DQEHBqCCBHgwggR0AgEAMIIEbQYJKoZIhvcNAQcBMBwGCiqGSIb3DQEMAQMwDgQIVi7QLS6tGicCAgQAgIIEQIQPVq9lFdQEYpSiz7noUzIwLmv2cvG/XM5UefwH/XJapWYLCX98wJGhJTjs7AqOOo2B/tqRuFA5qgItlAfU5cKf3hy74Y4SqA1M4UoFKRBPi86XaFVd79q0TUG0jVai1Sv3QEW6VjLEes0qCXuefcBLgCCzxxM0qVQC6YbS3uSyD66HTZpM4ErLtB+AhhZYQPJ+2QRvOoXEQH4QdaWOsemNZ+qc5goTau43JfgWYH9YtQusvivUuAZUbK6Hs2p0C1N2cdMTP2QvH8khbN8s99M21OSWdfL0WwqjQvjQ8EG/CDxjq2En/rFmzSZugrYHpvNod0vyxfJiIXupMc6yAH884cUMreC5ydhbm6oj78QyixAVyL9Ana6oa8VKw2Or7cOHZ8VbbZhQnYAs3htnu7FlYqEk5rqRQ5hP4dFGr7gq5QBqSKnH1WbIRRarV77520JMW82sWZbqcg3s0CDS2EDC4v3s1lavpcCjwTzibtOyzHSKtaxjLd07JgoU/CSsY68YsDYSBZIreJSde/wi6RYiDiCVkgtgYvp1Wc0B4XpfdJJ+S+EsSGjLBAkx2MFlLD1Dqa1YICtvTV169N+x8dc+50rrfN7QcmYAbNOlqxJfa//kszNX7iQCxCVWS5dTLdIjrTOOAB5sd3k1dgViZH/IrXYy79qNeu2B0koElkdRJd/uzJXZCRmhI75LyqNpTtI2NpG+ZJnZzN8TSoO1bh7gxdXln39+RwhCco7t+Cz0ggGMlZBdUi0CUqDajuB84RcZzVBUrV6rJp3lRv8CiwBtVVLurd5FUTuk4Gt3CY3itHqJ3gB/0SaY0S0IidAxnkDEokWcXZQJAH7mutoWVZitHU6ytgYujiBkRIGEq1KSvTJh5retgto7AqGazkBu+GaEoV4imbZguJnUHJSR6kTb0keBhNcvNwxeFddxW+HXK9Z3gAHbXI+COlqDsroB2+qHWBt0WhUj5oiKqFf85RnJ1wkd4cK7HtazjffzNsjtr0RCVyTOY4CHBRkSxVeQ36aacE0+PmubChvBfp2aKbQSgtdHZ3y67fIsFN4C+tR4wcvX6H4k2XEZUvOdM/BkLftR8hZk0aeu6YNgoRRXc5qQrGTd1tdCPyDZHKj9+QRV0BvYhr7NQcuADAaVAQy+kxyLtj0cau0gGAYyUkN8++2pVzUsEGz7EfvOWVgbd10gizHMLVmJYzuZeFpRkj2miI9LJQLfkK+6Jw8QeEmwvSY46QlGnAYnZEbcUeP+4bcq/1GjwjC9hz03xoVhM78UGiIAXYfWbI3LjsFr9N0Lk1hQQmYoUMS3UI2hcbxjL3Doe1OOZHfKNliD35DlkLOZM8A8Rpg42xgqWioS6TYlzg4ab354TFQwmrRUGBbEcZYOyWppzPLSqAGg+VuhPVolY3PhSIbt9025eG9gz1NdX3ORhq4fr+21I/Nw0L8TcKmnMC8wHzAHBgUrDgMCGgQU6Q5bdomHyflYqzekP7NmZnMb32AECFOjjDNsgNgHAgIEAA==\n  key.sth: sO14BirPhx/Tt/IbiDgCDmXgHv/EC33K0mag+J8LOKMtOHMzfpmuxUM842PT2U6/1xMTBa/dfixAjiZ595kC2CGmglJanoT5UMKH6HJZa88ztDMty+WrYP8YstMWhjs5gq1S8tC6ucUkVl9WXxGnBWHBYJu6wAnGySTReJVZf5GlbKmmeLHQhzLvdFv6kCUeLepbcdw9JLLesIuMWvgPxcxl6I11R5AzBgMZ+lvpcAY9pQz5iInLRrKQB3P+IiCX6w==\nkind: Secret\nmetadata:\n  name: ibm-mq-certificate\ntype: Opaque\n\n---\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: ibm-mq-secret\ndata:\n  username: YXBw\n  password: bXEtYXBwLXBhc3N3b3Jk\ntype: Opaque\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: ibm-mq\nspec:\n  selector:\n    app: ibm-mq-server\n  type: ClusterIP\n  ports:\n  - name: mq\n    port: 1414\n    protocol: TCP\n    targetPort: 1414\n</code></pre>","location":"sources/ibmmq/#creating-an-ibm-mq-server-for-testing-on-kubernetes"},{"title":"Creating an IBM MQ server for testing on Docker","text":"<p>Setup a local IBM MQ with the following commands:</p> <pre><code>docker volume create qmdata\ndocker network create mqnetwork\ndocker run --rm \\\n           --env LICENSE=accept \\\n           --env MQ_QMGR_NAME=QM1 \\\n           --volume qmdata:/mnt/mqm \\\n           --publish 1414:1414 \\\n           --publish 9443:9443 \\\n           --publish 8080:8080 \\\n           --network mqnetwork \\\n           --network-alias qmgr \\\n           --detach \\\n           --env MQ_APP_PASSWORD=password \\\n           --name mq \\\n           ibmcom/mq:latest\n</code></pre> <p>If you face any issues please follow the official tutorial</p> <p>Open the MQ console:</p> <p>Using admin and passw0rd as default development credentials do:</p> <p><code>open https://localhost:9443/ibmmq/console/</code></p> <p>Add messages to <code>DEV.QUEUE.1</code> queue.</p>","location":"sources/ibmmq/#creating-an-ibm-mq-server-for-testing-on-docker"},{"title":"Kafka source","text":"<p>Consumes events from Apache Kafka. Can be used with any Kafka API compatible service such as Confluent Kafka or RedPanda. </p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source kafka --bootstrapServers kafka.example.com:9092 --topic &lt;topic&gt; --groupID &lt;groupID&gt; --auth.username &lt;user&gt; --auth.password.value &lt;pass&gt;  --auth.saslEnable true --auth.tlsEnable true --auth.securityMechanism PLAIN\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: KafkaSource\nmetadata:\n  name: sample\nspec:\n  groupID: test-consumer-group\n  bootstrapServers:\n    - kafka.example.com:9092\n  topic:\n    - test-topic\n  auth:\n    saslEnable: true\n    tlsEnable: false\n    securityMechanism: PLAIN\n    username: admin\n    password:\n      value: admin-secret\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>io.triggermesh.kafka.event</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/kafka/"},{"title":"Kubernetes guide for KafkaSource","text":"<ul> <li>Prerequisites</li> <li>Creating a KafkaSource</li> <li>SASL-PLAIN</li> <li>Kerberos-SSL</li> <li>Status</li> </ul>","location":"sources/kafka/#kubernetes-guide-for-kafkasource"},{"title":"Prerequisites","text":"<p>A running Kafka cluster.</p>","location":"sources/kafka/#prerequisites"},{"title":"Creating a KafkaSource","text":"","location":"sources/kafka/#creating-a-kafkasource"},{"title":"SASL-PLAIN","text":"<p>This section demonstrates how to configure a KafkaSource to use SASL-PLAIN authentication.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: KafkaSource\nmetadata:\n  name: sample\nspec:\n  groupID: test-consumer-group\n  bootstrapServers:\n    - kafka.example.com:9092\n  topic:\n    - test-topic\n  auth:\n    saslEnable: true\n    tlsEnable: false\n    securityMechanism: PLAIN\n    username: admin\n    password:\n      value: admin-secret\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>","location":"sources/kafka/#sasl-plain"},{"title":"Kerberos-SSL","text":"<p>This section demonstrates how to configure a KafkaSource to use Kerberos-SSL authentication.</p> <p>Before creating the <code>KafkaSource</code>, we are going to create some secrets that the <code>KafkaSource</code> will need for the authentication with Kerberos + SSL.</p> <ul> <li>The kerberos config file.</li> <li>The kerberos keytab file.</li> <li>The CA Cert file.</li> </ul> <pre><code>kubectl create secret generic config --from-file=krb5.conf\nkubectl create secret generic keytab --from-file=krb5.keytab\nkubectl create secret generic cacert --from-file=ca-cert.pem\n</code></pre> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: KafkaSource\nmetadata:\n  name: sample\nspec:\n  groupID: test-consumer-group\n  bootstrapServers:\n    - kafka.example.com:9093\n  topic:\n    - test-topic\n  auth:\n    saslEnable: true\n    tlsEnable: true\n    securityMechanism: GSSAPI\n    kerberosAuth:\n      username: kafka\n      kerberosRealm: EXAMPLE.COM\n      kerberosServiceName: kafka\n      kerberosConfig:\n        valueFromSecret:\n          name: config\n          key: krb5.conf\n      kerberosKeytab:\n        valueFromSecret:\n          name: keytab\n          key: krb5.keytab\n    sslAuth:\n      insecureSkipVerify: true\n      sslCA:\n        valueFromSecret:\n          name: cacert\n          key: ca-cert\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>In order to configure the adapter correctly the following fields are mandatory:</p> <ul> <li><code>boostrapservers</code></li> <li><code>topic</code></li> <li><code>salsEnable</code></li> </ul>","location":"sources/kafka/#kerberos-ssl"},{"title":"Status","text":"<p>KafkaSource requires secrets to be provided for the credentials. Once they are present it will start. Controller logs and events can provide detailed information about the process. A Status summary is added to the KafkaSource object informing of the all conditions that the source needs.</p> <p>When ready, the <code>status.ready</code> will be True.</p> <pre><code>kubectl get kafkasource\nNAME     READY   REASON   URL   SINK                                                                              AGE\nsample   True                   http://broker-ingress.knative-eventing.svc.cluster.local/default/default   33s\n</code></pre>","location":"sources/kafka/#status"},{"title":"Oracle Cloud Infrastructure Metrics source (OCIMetrics)","text":"<p>This event source collects metrics data from Oracle Cloud.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>&lt;!-- <pre><code># tmctl create source ocimetrics --oracleApiPrivateKey &lt;oracleApiPrivateKey&gt; --oracleApiPrivateKeyPassphrase &lt;oracleApiPrivateKeyPassphrase&gt; --oracleApiPrivateKeyFingerprint &lt;oracleApiPrivateKeyFingerprint&gt; --oracleTenancy &lt;oracleTenancy&gt; --oracleUser &lt;oracleUser&gt; --oracleRegion &lt;oracleRegion&gt; --metrics &lt;TODO&gt;\n``` --&gt;\n\nOn Kubernetes:\n\n```yaml\napiVersion: sources.triggermesh.io/v1alpha1\nkind: OCIMetricsSource\nmetadata:\n  name: sample\nspec:\n  # required to interact with the Oracle Cloud API\n  oracleApiPrivateKey:\n    value: |-\n      -----BEGIN RSA PRIVATE KEY-----\n      MIXEpAIBACKCAQEA2UM2O2lz4D6gN2sAbxUg6VMnGQlrwNbZX7b/wqW6ZEU0Q0BU\n      ...\n      -----END RSA PRIVATE KEY-----\n  oracleApiPrivateKeyPassphrase:\n    value: replace-me\n  oracleApiPrivateKeyFingerprint:\n    value: 5c:75:c4:67:92:a9:46:2a:01:5b:73:54:6a:b2:74:7d\n\n  oracleTenancy: ocid1.tenancy.oc1..aaaaaaaaswreplaceme\n  oracleUser: ocid1.user.oc1..aaaaaaaaqlocaluser\n  oracleRegion: us-ashburn-1\n\n  # required to enable metrics\n  metrics:\n  - name: cpuUtilization\n    metricsNamespace: oci_computeagent\n    metricsQuery: CPUUtilization[1m].mean()\n\n  # optional. default to 5m\n  metricsPollingFrequency: 3m\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre></p> <p>For the metrics specific information: - <code>metricsNamespace</code>can take values such as <code>oci_computeagent</code> or <code>oci_vcn</code> - <code>metricsQuery</code> is based on MQL</p> <p>For details on how to write a query, consult the Oracle Cloud Monitoring Overview</p> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.oracle.cloud.monitoring</code></li> <li>source is of the form <code>ocimetrics/&lt;namespace&gt;/&lt;source-name&gt;</code> where <code>namespace</code> is your current namespace and <code>source-name</code> is the name specified during creation of the source.</li> <li>Schema of the <code>data</code> attribute: com.oracle.cloud.monitoring.json</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/ocimetrics/"},{"title":"Prerequisite(s)","text":"<ul> <li>Oracle Cloud Account</li> <li>Oracle Cloud Infrastructure (OCI)</li> <li>Oracle Cloud Secret</li> </ul>","location":"sources/ocimetrics/#prerequisites"},{"title":"Oracle Cloud Account","text":"<p>An Oracle Cloud account is required.</p>","location":"sources/ocimetrics/#oracle-cloud-account"},{"title":"Oracle Cloud Infrastructure (OCI)","text":"<p>The Oracle Cloud account needs to have permissions to inspect and read metrics for the Oracle Cloud Infrastructure (OCI) compartment.</p> <p>For additional information on how to create an API key and associate it with your Oracle Cloud user, go to Oracle's Developer Documentation</p>","location":"sources/ocimetrics/#oracle-cloud-infrastructure-oci"},{"title":"Oracle Cloud Secret","text":"<p>Three pieces of information are required for the Oracle Cloud: 1. API Private Key used for signing the request 1. API Private Key passphrase to decrypt the key 1. API Key's fingerprint to identify which key to use on the Oracle Cloud end</p>","location":"sources/ocimetrics/#oracle-cloud-secret"},{"title":"Salesforce source","text":"<p>This event source acts as a consumer of the Salesforce stream API.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source salesforce --auth.clientID &lt;clientID&gt; --auth.server &lt;server&gt; --auth.user &lt;user&gt; --auth.certKey &lt;certKey&gt; --subscription.channel &lt;channel&gt; --subscription.replayID &lt;replayID&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: SalesforceSource\nmetadata:\n  name: sample\nspec:\n  subscription:\n    channel: /data/ChangeEvents\n    replayID: -2\n\n  auth:\n    clientID: salesforce.client_id\n    server: https://login.salesforce.com\n    user: woodford@example.com\n    certKey:\n      value: my-key\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <ul> <li>Broker to send the events to.</li> <li>Client ID as retrieved from Salesforce Connected App.</li> <li>Server for authentication at Salesforce.</li> <li>User for the Salesforce account.</li> <li>Channel as configured at the Salesforce stream.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.salesforce.stream.message</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"sources/salesforce/"},{"title":"Prerequisite(s)","text":"<ul> <li>Salesforce Account</li> <li>Salesforce Stream Channel</li> <li>Certificate Key Secret</li> </ul>","location":"sources/salesforce/#prerequisites"},{"title":"Salesforce Account","text":"<p>Salesforce source uses OAuth JWT credentials for service authentication.</p> <ol> <li> <p>First, you will need to generate an X509 certificate for signing and verifying requests. We will be using <code>OpenSSL</code> but any other certificate generation tool should work.</p> <pre><code>openssl req -x509 -sha256 -nodes -days 36500 -newkey rsa:2048 -keyout tm-sf.key -out tm-sf.crt\n</code></pre> </li> <li> <p>At Salesforce site select <code>Setup &gt; Apps &gt; App Manager</code>, click on <code>New Connected App</code>.</p> <ul> <li>Fill in mandatory fields, then click <code>Enable OAuth Settings</code>.</li> <li>A callback URL is mandatory but can be filled with any HTTPS data.</li> <li>Enable <code>Use digital signatures</code> and upload the public cert (<code>tm-sf.crt</code> in the example above).</li> <li>Add Scopes for <code>api</code> and <code>refresh_token, offline_access</code>.</li> <li>Save.</li> </ul> <p></p> <ul> <li>Select the Connected App from the list and at the click on <code>Manage</code>.</li> <li>Click <code>Edit policies</code>.</li> <li>Set Permitted users to <code>Admin approved users are pre-authorized</code>.</li> <li>Save.</li> </ul> <p></p> <ul> <li>Select the Connected App from the list and at the click on <code>Manage</code>.</li> <li>Click <code>Manage Profiles</code>.</li> <li>Add permissions on the data this user will have access to.</li> <li>Save.</li> </ul> </li> <li> <p>Retrieve OAuth data to configure TriggerMesh Source.</p> </li> <li> <p>Select the Connected App from the list and at the click on <code>View</code>.</p> </li> <li>Copy <code>Consumer Key</code></li> <li>Reveal and copy <code>Consumer Secret</code></li> </ol>","location":"sources/salesforce/#salesforce-account"},{"title":"Salesforce Stream Channel","text":"<p>Refer to Salesforce stream API on how to create stream channels:</p> <ul> <li>Change Data Capture events: <code>/data/ChangeEvents</code></li> <li>PushTopics for streams based on single entity SOQL queries: <code>/topic/TicketsSold</code></li> <li>Standard Platform Events for Salesforce event monitoring: <code>/event/LoginEventStream</code></li> <li>Custom Platform Events for your SOQL platform events: <code>/event/MyCustom__e</code></li> </ul> <p>Each Streaming event type has a distinct set of features</p>","location":"sources/salesforce/#salesforce-stream-channel"},{"title":"Certificate Key Secret","text":"<p>The TriggerMesh Salesforce integration needs the certificate key to sign authentication requests with the Salesforce API. A secret needs to be created at TriggerMesh that contains that certificate key. The file name containing the key will need to be renamed to <code>certKey</code>, then select <code>Secrets</code> &gt; <code>+ ADD SECRET</code>, <code>File Upload</code></p>","location":"sources/salesforce/#certificate-key-secret"},{"title":"Slack source","text":"<p>This event source uses the Slack Events API through a bot user to ingest events into TriggerMesh.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source slack\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: SlackSource\nmetadata:\n  name: sample\nspec:\n  # optional, making sure we are receiving events on behalf of Slack\n  signingSecret:\n    value: XXXXXXXXXXXXXXXXXX\n\n  # optional, making sure the events are being sent for this integration\n  appID: AXXXXXXXXX\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.slack.events</code></li> <li>source <code>Team ID (Slack workspace)</code></li> <li>Schema of the <code>data</code> attribute: com.slack.events.json</li> </ul> <p>Event <code>data</code> example:</p> <pre><code>{\n  \"blocks\": [\n    {\n      \"block_id\": \"ws9ME\",\n      \"elements\": [\n        {\n          \"elements\": [\n            {\n              \"text\": \"waving hello \",\n              \"type\": \"text\"\n            },\n            {\n              \"type\": \"user\",\n              \"user_id\": \"U015NKH6R6G\"\n            }\n          ],\n          \"type\": \"rich_text_section\"\n        }\n      ],\n      \"type\": \"rich_text\"\n    }\n  ],\n  \"channel\": \"C01112A09FT\",\n  \"channel_type\": \"channel\",\n  \"client_msg_id\": \"9fc2ed3e-c823-4dcf-be6b-4d788ab0beea\",\n  \"event_ts\": \"1592732675.009400\",\n  \"team\": \"TA1J7JEBS\",\n  \"text\": \"waving hello \\u003c@U015NKH6R6G\\u003e\",\n  \"ts\": \"1592732675.009400\",\n  \"type\": \"message\",\n  \"user\": \"UT8LFLXR8\"\n}\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"sources/slack/"},{"title":"Prerequisite(s)","text":"<ul> <li>A Slack user that can manage applications is required to configure the source.</li> </ul>","location":"sources/slack/#prerequisites"},{"title":"Create the Slack Source Integration","text":"<p>Deploy the Slack source in 3 steps:</p> <ol> <li>Deploy the Slack source, retrieve exposed endpoint at TriggerMesh.</li> <li>Configure Slack App to send events to the Slack Source endpoint.</li> <li>(optional) Modify the Slack Source to add Signing Secret and AppID from the configured App.</li> </ol>","location":"sources/slack/#create-the-slack-source-integration"},{"title":"Deploy Slack Source","text":"<p>Create an instance of the Slack Source with TriggerMesh.</p> <p>Copy the URL for the exposed service.</p>","location":"sources/slack/#deploy-slack-source"},{"title":"Configure Slack Events API App","text":"<ol> <li>Create a new [Slack App][slack-app]</li> </ol> <p></p> <ol> <li>From Basic Information, Features and functionality, select <code>Event Subscriptions</code></li> </ol> <p></p> <ol> <li>Slide the <code>Enable Events</code> selector to <code>on</code> and write the Slack source exposed URL at the <code>Request URL</code> box. A request with a verification challenge will be sent and when the Slack source adapter answer it will be validated and a green check will be shown.</li> </ol> <p></p> <ol> <li> <p>At the <code>Subscribe to bot events</code> section select the bot events that will be sent on behalf of this integration and then press <code>Save Changes</code> at the bottom of the page.. Refer to Slack documentation on which ones to use, as a hint the we think these 3 could be useful for different scenarios:</p> </li> <li> <p><code>app_mention</code> will send an event when the App is mentioned.</p> </li> <li><code>message.im</code> will send an event when sending a direct message to the App.</li> <li><code>message.channels</code> an event will be sent for each message at a channel where the App is invited.</li> </ol> <p></p> <ol> <li>At <code>Install App</code> section click on <code>Install App to Workspace</code></li> </ol> <p></p> <ol> <li> <p>(Optional)Return to the application's <code>Basic Information</code> and take note of <code>App ID</code> and <code>Signing Secret</code></p> <p></p> </li> </ol> <p>You will now have a working integration. Any Slack action that matches the configured event subscription will be sent to the Slack Source and from there to the sink.</p>","location":"sources/slack/#configure-slack-events-api-app"},{"title":"Twilio source","text":"<p>This event source is to be deployed and then registered as a webhook via a Twilio Proxy.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source twilio\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: TwilioSource\nmetadata:\n  name: sample\nspec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.triggermesh.twilio.sms</code></li> <li>Schema of the <code>data</code> attribute: com.triggermesh.twilio.sms.json</li> </ul> <p>Example event emitted from this source:</p> <pre><code>\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: com.triggermesh.twilio.sms\n  source: io.triggermesh.twilio/jeff/twilio-source\n  id: 6a547451-be05-4da4-a10f-1af92422c7d1\n  time: 2021-01-25T19:18:38.550812939Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2021-01-25T19:18:38.580569695Z\nData,\n  {\n    \"message_sid\": \"ASDFc9ac2663bbeASDFd51a\",\n    \"sms_status\": \"received\",\n    \"from_country\": \"US\",\n    \"num_segments\": \"1\",\n    \"to_zip\": \"99204\",\n    \"num_meda\": \"\",\n    \"account_sid\": \"ADF0610bd2e60abdda72\",\n    \"sms_message_sid\": \"ASKDFb2c9ac26621CADfca1d51a\",\n    \"api_version\": \"2010-04-01\",\n    \"to_country\": \"US\",\n    \"to_city\": \"SPOKANE\",\n    \"from_zip\": \"27707\",\n    \"sms_sid\": \"ASDFc2663bbefcASa\",\n    \"from_state\": \"NC\",\n    \"body\": \"hello world\",\n    \"from\": \"&lt;redacted&gt;\",\n    \"from_city\": \"DURHAM\",\n    \"to\": \"&lt;redacted&gt;\",\n    \"to_state\": \"WA\"\n  }\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"sources/twilio/"},{"title":"Prerequisite(s)","text":"<ul> <li>A Twilio account (trial or paid)</li> </ul>","location":"sources/twilio/#prerequisites"},{"title":"Integrate with Twilio","text":"<p>Retrieve the public URL of the deployed TriggerMesh Twilio source.</p> <p>Navigate to your Twilio dashboard and search for <code>proxy</code></p> <p></p> <p>From the Twilio Proxy dashboard select <code>Create new Service</code> and, in the following pop-up box, assign it a name.</p> <p></p> <p>You should now be on a similar page to this:</p> <p></p> <p>Enter the <code>Domain</code> that was retrieved earlier into the  \"CALLBACK URL\", \"INTERCEPT CALLBACK URL\", and \"OUT OF SESSION CALLBACK URL\" fields. Then select <code>Save</code></p> <p></p> <p>Select <code>Proxy Numbers</code></p> <p></p> <p>Select <code>Add Numbers</code></p> <p></p> <p>Assing an available number</p> <p></p> <p>All done!</p>","location":"sources/twilio/#integrate-with-twilio"},{"title":"Webhook source (HTTP)","text":"<p>This source exposes an HTTP endpoint, meaning it acts as an HTTP server. It can be used as a target endpoint for 3rd-party webhooks from any SaaS app that supports webhooks, or can be used as a generic way to ingest events to TriggerMesh via HTTP. The Webhook source creates an event for each request received.</p> <p>Compared to the CloudEventsSource, the Webhook source can accept arbitrary data (e.g. any JSON) and does not require the request to conform to the CloudEvents specification.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source webhook --eventTypes &lt;my.event.type&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: WebhookSource\nmetadata:\n  name: sample\nspec:\n  eventType: com.example.mysample.event\n  eventSource: instance-abc123\n\n  eventExtensionAttributes:\n    from:\n    - path\n    - queries\n\n  basicAuthUsername: customuser\n  basicAuthPassword:\n    value: abc123secret\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Parameters</p> <ul> <li>Name: all TriggerMesh components need a unique name per namespace.</li> <li>Broker: request converted into CloudEvents will be sent to this location.</li> <li>EventType: string that identifies the purpose for all messages produced from this source.</li> <li>EventSource: string that identifies the origin for all messages produced from this source.</li> <li>Basic Auth Username: (optional) HTTP basic authentication username.</li> <li>Basic Auth Password (optional) points to a secret that contains the HTTP basic authentication password.</li> </ul> <p>Events produced have the following attributes:</p> <ul> <li>type: defined by the user in the WebhookSource configuration, e.g. <code>shopify.user.new</code></li> <li>source: defined by the user in the WebhookSource configuration, e.g. <code>cool-tshirts</code></li> <li>Schema of the <code>data</code> attribute: depends on what the client sends to the Webhook</li> <li><code>datacontenttype</code> is set to the <code>Content-Type</code> received at the incoming request</li> </ul> <p>Cloud Event data example (same as received body):</p> <pre><code>{\n  \"operation\": \"signup\",\n  \"user\": {\n    \"...\":\"...\",\n  },\n}\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"sources/webhook/"},{"title":"Guide: use <code>tmctl</code> to create a Webhook source","text":"<p> Create an HTTP endpoint</p> <p>HTTP is one of the easiest ways to send events to the Broker from whichever HTTP client you prefer (Postman, Curl, API Tester...). To do this, let's create a Webhook Source:</p> <pre><code>tmctl create source webhook --eventType contact.created\n</code></pre> <p>We're declaring that events of type <code>contact.created</code> will be sent to this endpoint. This event type will be part of the event metadata as it flows through TriggerMesh, and can be used later on for routing.</p> <p> Obtain the URL</p> <p>Find the Webhook Source URL:</p> <pre><code>tmctl describe\n</code></pre> <p>The output should look something like this:</p> <pre><code>tmctl % tmctl describe\n\nBroker     Status\nfoo        online(http://localhost:59882)\n\n\nSource                Kind              EventTypes          Status\nfoo-webhooksource     webhooksource     contact.created     online(http://localhost:59936)\n</code></pre> <p>As you can see, <code>tmctl describe</code> displays useful info about your current configuration. It lists all the sources, targets, and other components you've defined, and their properties.</p> <p>Copy the webhooksource URL, in this case <code>http://localhost:59936</code> (this will vary depending on your environment). Do not confuse this with the Broker's URL.</p> <p> Send an event over HTTP</p> <p>We'll use curl here. Remember to replace the endpoint URL with yours.</p> <pre><code>curl http://localhost:59936 -d '{\"http\":\"is easy\"}' -H 'Content-type: application/json'\n</code></pre> <p>The event should show up in <code>tmctl watch</code>:</p> <pre><code>2022/11/09 16:17:38 Watching...\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: contact.created\n  source: local.foo-webhooksource\n  id: 8bce0cd7-74a2-443b-b8ef-825473cc5c51\n  time: 2022-11-09T15:37:00.435002345Z\n  datacontenttype: application/json\nData,\n  {\n    \"http\": \"is easy\"\n  }\n</code></pre>","location":"sources/webhook/#guide-use-tmctl-to-create-a-webhook-source"},{"title":"Zendesk source","text":"<p>This event source registers itself as a notification receiver in Zendesk in order to capture events such as ticket creations.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: ZendeskSource\nmetadata:\n  name: sample\nspec:\n\n  subdomain: example-corp\n\n  email: johndoe@example.com\n  token:\n    value: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\n  webhookUsername: foo\n  webhookPassword:\n    value: secret1234\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>Events produced have the following attributes:</p> <ul> <li>type <code>com.zendesk.ticket.created</code></li> <li>Schema of the <code>data</code> attribute: com.zendesk.ticket.created.json</li> </ul> <p>An Example ticket create event:</p> <pre><code>\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: com.zendesk.ticket.created\n  source: triggermesh.zendesk.com/zdevntsrc\n  id: aeb9d9c9-89a9-468f-b157-015160c03454\n  time: 2021-01-29T15:10:08.500296727Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2021-01-29T15:10:08.522619069Z\nData,\n  {\n    \"current_user\": {\n      \"details\": \"\",\n      \"email\": \"demo@triggermesh.com\",\n      \"external_id\": \"\",\n      \"first_name\": \"Demo\",\n      \"language\": \"English\",\n      \"name\": \"Demo\",\n      \"notes\": \"\",\n      \"organization\": {\n        \"details\": \"\",\n        \"name\": \"\",\n        \"notes\": \"\"\n      },\n      \"phone\": \"\"\n    },\n    \"satisfaction\": {\n      \"current_comment\": \"\",\n      \"current_rating\": \"\"\n    },\n    \"ticket\": {\n      \"account\": \"TriggerMesh\",\n      \"assignee\": {\n        \"email\": \"support@triggermesh.com\",\n        \"first_name\": \"TriggerMesh\",\n        \"last_name\": \"Developer\",\n        \"name\": \"TriggerMesh Developer\"\n      },\n      \"brand_name\": \"TriggerMesh\",\n      \"cc_names\": \"\",\n      \"ccs\": \"[]\",\n      \"current_holiday_name\": \"Liquid error: internal\",\n      \"description\": \"----------------------------------------------\\n\\nDemo, Jan 29, 2021, 11:10\\n\\nhello world\",\n      \"due_date\": \"\",\n      \"external_id\": \"\",\n      \"group_name\": \"Support\",\n      \"id\": 343,\n      \"organization\": {\n        \"details\": \"\",\n        \"external_id\": \"\",\n        \"name\": \"\",\n        \"notes\": \"\"\n      },\n      \"priority\": \"\",\n      \"requester\": {\n        \"details\": \"\",\n        \"email\": \"demo@triggermesh.com\",\n        \"external_id\": \"\",\n        \"field\": \"\",\n        \"first_name\": \"Demo\",\n        \"language\": \"English\",\n        \"last_name\": \"Demo\",\n        \"name\": \"Demo\",\n        \"phone\": \"\"\n      },\n      \"status\": \"Open\",\n      \"tags\": \"oracle\",\n      \"ticket_field_id\": \"\",\n      \"ticket_field_option_title_id\": \"\",\n      \"ticket_type\": \"Ticket\",\n      \"title\": \"hello world\",\n      \"url\": \"triggermesh.zendesk.com/agent/tickets/343\",\n      \"via\": \"Web Form\"\n    }\n  }\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"sources/zendesk/"},{"title":"Prerequisite(s)","text":"<ul> <li>API Token</li> </ul>","location":"sources/zendesk/#prerequisites"},{"title":"API Token","text":"<p>An API token is required in order to let the TriggerMesh Zendesk event source create a corresponding Target and Trigger in your Zendesk account. To create a new API token from the Zendesk Admin interface, follow the instructions at Generating a new API token .</p>","location":"sources/zendesk/#api-token"},{"title":"Deploying an Instance of the Source","text":"<ul> <li>Email: Email address associated with the Zendesk account.</li> <li>Subdomain: Name of the Zendesk subdomain, without the <code>zendesk.com</code> domain or <code>https://</code> scheme.</li> <li>Token: Reference to a [TriggerMesh secret][tm-secret] containing an API token to communicate with the   Zendesk API, as described in the previous section.</li> <li>Webhook username/password: arbitrary user name and password, used to verify event callbacks.</li> </ul>","location":"sources/zendesk/#deploying-an-instance-of-the-source"},{"title":"Verification of External Resources","text":"<p>To verify the successful deployment of the Zendesk event source, navigate to the Targets tab of the Extensions screen in the Zendesk Admin interface, below the Settings section. The event source instance should have created a Target following the naming pattern <code>io.triggermesh.zendesksource.&lt;user namespace&gt;.&lt;source name&gt;</code>.</p> <p></p> <p>The Target is configured to include the webhook username and password defined earlier in each request header.</p> <p></p> <p>The Target is linked to a Trigger, which can be found by navigating to the Triggers screen, below the Business rules section. This Trigger follows the same naming convention as the matching Target.</p> <p></p> <p>The Trigger defines the condition on which a new event is generated and sent to the Target. In the example below, the condition is the creation of a new ticket.</p> <p></p> <p>If the Trigger is marked as <code>active</code>, it will be sending notifications to the HTTP(S) endpoint exposed by the instance of the TriggerMesh Zendesk event source as soon as a corresponding action happens in Zendesk.</p>","location":"sources/zendesk/#verification-of-external-resources"},{"title":"Alibaba OSS target","text":"<p>Sends events to Alibaba OSS, resulting in a new file that contains the event data.</p> <p>The response event type will contain the original event type with <code>.response</code> appended to the end.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target alibabaoss --bucket &lt;bucket&gt; --endpoint &lt;endpoint&gt; --accessKeyID &lt;accessKeyID&gt; --accessKeySecret &lt;accessKeySecret&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: osscreds\ntype: Opaque\nstringData:\n  id: \"&lt;Alibaba Access Key ID&gt;\"\n  secret: \"&lt;Alibaba Secret Access Key&gt;\"\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AlibabaOSSTarget\nmetadata:\n  name: oss\nspec:\n  endpoint: &lt;datacenter-endpoint&gt;\n  bucket: &lt;bucket-name&gt;\n  accessKeyID:\n    secretKeyRef:\n      name: osscreds\n      key: id\n  accessKeySecret:\n    secretKeyRef:\n      name: osscreds\n      key: secret\n</code></pre> <p>This target accepts events of all types and uploads them into a table with the Cloudevent ID as the object key.</p> <p>The response event type will contain the original event type with <code>.response</code> appended to the end, e.g. <code>io.triggermesh.alibaba.oss.response</code>.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v localhost:8080\\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: any.event.type\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"message\":\"Hello from TriggerMesh!\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/alibabaoss/"},{"title":"Prerequisite(s)","text":"<ul> <li>Alibaba Cloud account.</li> <li>The Access Key ID and Secret Access Key associated to the account.</li> </ul> <p>For more information about using Alibaba OSS, please refer to the documentation.</p>","location":"targets/alibabaoss/#prerequisites"},{"title":"Amazon Comprehend target","text":"<p>Send events to Amazon Comprehend</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awscomprehend --region &lt;region&gt; --language &lt;language&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: aws\ntype: Opaque\nstringData:\n  AWS_ACCESS_KEY_ID: \"&lt;AWS Access Key ID&gt;\"\n  AWS_SECRET_ACCESS_KEY: \"&lt;AWS Secret Access Key&gt;\"\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSComprehendTarget\nmetadata:\n  name: triggermesh-aws-comprehend\nspec:\n  region: us-west-1\n  language: en\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>This target accepts events of any type and analyzes each of the key values sentiment. It then combines the scores and returns the analysis in a response event of type <code>io.triggermesh.targets.aws.comprehend.result</code>.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v \"10.1.215.232:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.sendgrid.email.send\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"fromEmail\":\"I LOVE YOU\"}'\n</code></pre> <p>Response: <pre><code>{\"positive\":0.999502420425415,\"negative\":0.00006757258961442858,\"mixed\":0.00005553230221266858,\"result\":\"Positive\"}\n</code></pre> <pre><code>curl -v \"localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.sendgrid.email.send\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"fromEmail\":\"I LOVE YOU\", \"other\":\"you are great\", \"another\":\"awesome job!\"}'\n</code></pre> Response: <pre><code>{\"positive\":2.979724109172821,\"negative\":0.001508750458015129,\"mixed\":0.004781584390002536,\"result\":\"Positive\"}\n</code></pre> <pre><code>curl -v \"localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.sendgrid.email.send\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"fromEmail\":\"you suck\", \"other\":\"hate you\", \"another\":\"go to hell\"}'\n</code></pre> Response: <pre><code>{\"positive\":0.05191964528057724,\"negative\":2.70785391330719,\"mixed\":0.08987980522215366,\"result\":\"Negative\"}\n</code></pre></p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awscomprehend/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret.</li> </ul> <p>For more information about using Amazon Comprehend, please refer to the documentation.</p>","location":"targets/awscomprehend/#prerequisites"},{"title":"AWS DynamoDB target","text":"<p>Sends events to AWS DynamoDB.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target dynamodb --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSDynamoDBTarget\nmetadata:\n  name: triggermesh-aws-dynamodb\nspec:\n  arn: arn:aws:dynamodb:us-west-1:&lt;PROJECT_ID&gt;:table/test\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>Accepts events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.dynamodb.result</code></li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://awstarget-triggermesh-aws-dynamodb.d.svc.cluster.local \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: io.triggermesh.aws.dynamodb.item.put\" \\\n -H \"Ce-Subject: &lt;TABLE_NAME&gt;\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"Message\":\"Hi from TriggerMesh\"}'\n</code></pre> <p>Events can overwrite the default table name set at the spec by providing a table name at the <code>Ce-Source</code> attribute.</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awsdynamodb/"},{"title":"Amazon EventBridge target","text":"<p>Sends events to an Amazon EventBridge partner event bus.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awseventbridge --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSEventBridgeTarget\nmetadata:\n  name: triggermesh-aws-eventbridge\nspec:\n  arn: arn:aws:events:us-west-2:&lt;PROJECT_ID&gt;:event-bus/cab-knative-event-test\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>The Amazon EventBridge event Target can consume events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.eventbridge.result</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awseventbridge/"},{"title":"Prerequisites","text":"<p>Although this event source can immediately start receiving events, those events can only be consumed after associating the TriggerMesh partner event source with a corresponding partner event bus.</p> <p>To associate the TriggerMesh partner event source with a partner event bus:</p> <ol> <li>Navigate to the Partner event sources menu of the Amazon EventBridge Console.</li> <li>Select the \"Pending\" partner event source which name starts with <code>aws.partner/triggermesh.com</code>.</li> <li>Click the <code>Associate with event bus</code> button.</li> </ol> <p></p> <p>On the next screen called Associate with event bus, click the <code>Associate</code> button.</p> <p></p> <p>Back to the Partner event sources page, your partner event source should now show as \"Active\".</p> <p></p> <p>You will also see a custom event bus named after the TriggerMesh partner event source on the Event buses page.</p> <p></p> <p>Your can now start creating rules that trigger on certain events in the Amazon EventBridge console.</p> <p>For more information about using Amazon EventBridge, please refer to the EventBridge user guide.</p>","location":"targets/awseventbridge/#prerequisites"},{"title":"Amazon Kinesis target","text":"<p>Sends events to Amazon Kinesis.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awskinesis --partition &lt;partition&gt; --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSKinesisTarget\nmetadata:\n  name: triggermesh-aws-kinesis\nspec:\n  arn: arn:aws:kinesis:us-west-2:&lt;PROJECT_ID&gt;:stream/cabtest\n  partition: \"test\"\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p><code>partition</code> is the Kinesis partition to publish the events to.</p> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to Kinesis. By default, this is disabled which means only the event payload will be sent.</p> <p>Accepts events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.kinesis.result</code></li> <li>source <code>arn:aws:kinesis:...</code>, the Kinesis ARN value as configured by the target</li> <li>Schema of the <code>data</code> attribute: </li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awskinesis/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the Kinesis stream</li> <li>A Kinesis partition name to publish the events to</li> </ul> <p>For more information about using Amazon Kinesis, please refer to the AWS documentation.</p>","location":"targets/awskinesis/#prerequisites"},{"title":"AWS Lambda target","text":"<p>Sends events to an AWS Lambda function.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awslambda --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSLambdaTarget\nmetadata:\n  name: triggermesh-aws-lambda\nspec:\n  arn: arn:aws:lambda:us-west-2:043455440429:function:snslistener\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to the lambda function. By default, this is disabled which means only the event payload will be sent.</p> <p>Accepts events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.lambda.result</code></li> <li>source <code>arn:aws:lambda:...</code>, the Lambda's ARN value as configured by the target</li> <li>Schema of the <code>data</code> attribute: </li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://triggermesh-aws-lambda.default.svc.cluster.local \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: dev.knative.source.aws\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"greeting\":\"Hi from TriggerMesh\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awslambda/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the Lambda to invoke</li> </ul> <p>For more information about using AWS Lambda, please refer to the AWS documentation.</p>","location":"targets/awslambda/#prerequisites"},{"title":"Amazon S3 target","text":"<p>Sends events to Amazon S3.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awss3 --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSS3Target\nmetadata:\n  name: triggermesh-aws-s3-test\nspec:\n  arn: arn:aws:s3:::bucket\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to S3 bucket. By default, this is disabled which means only the event payload will be sent.</p> <p>Accepts events of any type, with a special rule for <code>io.triggermesh.awss3.object.put</code> for which the target will store the payload body regardless of the <code>Discard CloudEvent context attributes</code> setting.</p> <p>The Amazon S3 bucket key used to store the event is defined by the <code>ce-subject</code> attribute. If <code>ce-subject</code> is not set, the default key will be: ce-type/ce-source/ce-time.</p> <p>Attributes for the <code>put</code>operation are:</p> <ul> <li>type <code>io.triggermesh.awss3.object.put</code></li> <li>subject: <code>string</code>, the key to use with the assigned bucket for the Target</li> <li><code>data</code> contains the payload to store</li> </ul> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.s3.result</code></li> <li>source <code>arn:aws:s3:...</code>, the S3's bucket ARN value as configured by the target</li> <li><code>data</code> contains a JSON response from the Target invocation with the Etag associated with the request</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awss3/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the S3 bucket to store the event</li> </ul> <p>The ARN for the S3 bucket must include the account number and region of a pre-defined access point.</p> <p>For more information about using Amazon S3, please refer to the AWS documentation.</p>","location":"targets/awss3/#prerequisites"},{"title":"Amazon SNS target","text":"<p>Sends event to Amazon SNS.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awssns --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSSNSTarget\nmetadata:\n  name: triggermesh-aws-sns\nspec:\n  arn: arn:aws:sns:us-west-2:&lt;PROJECT_ID&gt;:tmtest\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to SNS. By default, this is disabled which means only the event payload will be sent.</p> <p>Accepts events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.sns.result</code></li> <li>source <code>arn:aws:sns:...</code>, the SNS ARN value as configured by the target</li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awssns/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the SNS topic to invoke</li> </ul> <p>For more information about using AWS Simple Notification Service, please refer to the AWS documentation.</p>","location":"targets/awssns/#prerequisites"},{"title":"Amazon SQS target","text":"<p>Sends events to Amazon SQS.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target awssqs --arn &lt;arn&gt; --awsApiKey &lt;awsApiKey&gt; --awsApiSecret &lt;awsApiSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSSQSTarget\nmetadata:\n  name: triggermesh-aws-sqs\nspec:\n  arn: arn:aws:sqs:us-west-2:&lt;PROJECT_ID&gt;:cab-knative-event-test\n  awsApiKey:\n    secretKeyRef:\n      name: aws\n      key: AWS_ACCESS_KEY_ID\n  awsApiSecret:\n    secretKeyRef:\n      name: aws\n      key: AWS_SECRET_ACCESS_KEY\n</code></pre> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to SQS. By default, this is disabled which means only the event payload will be sent.</p> <p>Accepts events of any type.</p> <p>Responds with events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.targets.aws.sqs.result</code></li> <li>source <code>arn:aws:sqs:...</code>, the SQS ARN value as configured by the target</li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/awssqs/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the SQS queue to invoke</li> </ul> <p>For more information about using AWS Simple Queue Service, please refer to the AWS documentation.</p>","location":"targets/awssqs/#prerequisites"},{"title":"Azure Event Hubs target","text":"<p>Sends events to Azure Event Hubs.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target azureeventhubs --eventHubID &lt;eventHubID&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes, with servicePrincipal authentication:</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AzureEventHubsTarget\nmetadata:\n  name: sample\nspec:\n  eventHubID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace/eventhubs/MyEvents\n\n  auth:\n    servicePrincipal:\n      tenantID:\n        valueFromSecret:\n          name: azure\n          key: tenantID\n      clientID:\n        valueFromSecret:\n          name: azure\n          key: clientID\n      clientSecret:\n        valueFromSecret:\n          name: azure\n          key: clientSecret\n</code></pre> <p>On Kubernetes, with connection string authentication:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AzureEventHubsTarget\nmetadata:\n  name: sample\nspec:\n  eventHubID: /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/MyGroup/providers/Microsoft.EventHub/namespaces/MyNamespace/eventhubs/MyEvents\n\n  auth:\n    sasToken:\n      connectionString:\n        valueFromSecret:\n          name: azure\n          key: connectionString\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/azureeventhubs/"},{"title":"Azure Sentinel target","text":"<p>Sends events to Azure Sentinel.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target azuresentinel --subscriptionID &lt;subscriptionID&gt; --resourceGroup &lt;resourceGroup&gt; --workspace &lt;workspace&gt; --auth.servicePrincipal.tenantID &lt;tenantID&gt; --auth.servicePrincipal.clientID &lt;clientID&gt; --auth.servicePrincipal.clientSecret &lt;clientSecret&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: azure\ntype: Opaque\nstringData:\n  tenantID: &lt;client_secret&gt;\n  clientID: &lt;client_id&gt;\n  clientSecret: &lt;client_secret&gt;\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AzureSentinelTarget\nmetadata:\n  name: hello-sentinel\nspec:\n  # subscriptionID refers to the Azure Subscription ID that the Azure Sentinel instance is associated with.\n  subscriptionID: &lt;subscription_id&gt;\n  # resourceGroup refers to the resource group where the Azure Sentinel instance is deployed.\n  resourceGroup: &lt;resource_group&gt;\n  # workspace refers to the workspace name in Azure Sentinel.\n  workspace: &lt;workspace&gt;\n  auth:\n    servicePrincipal:\n      tenantID:\n        valueFromSecret:\n          name: azure\n          key: tenantID\n      clientID:\n        valueFromSecret:\n          name: azure\n          key: clientID\n      clientSecret:\n        valueFromSecret:\n          name: azure\n          key: clientSecret\n</code></pre> <p>Accepts any payload that the standard Azure Sentinel API Incidents - Create Or Update supports. Specifically, the API expects Request Body as the payload of the events.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://azuresentineltarget-hello-sentinel.default.svc.cluster.local\\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: io.triggermesh.azure.sentinel.incident\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"etag\": \"some-etag\", \"properties\": {\"providerIncidentId\": \"12\", \"status\":\"new\", \"severity\": \"high\", \"title\": \"some-title\", \"description\": \"some-description\", \"owner\":{\"assignedTo\": \"some-owner\"},\"additionalData\": {\"alertProductNames\": [\"some-product\",\"some-other-product\"]}}}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/azuresentinel/"},{"title":"Example using a Transformation","text":"<p>This example shows how you can transform a CSNF event into an Azure Sentinel event.</p> <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: Transformation\nmetadata:\n  name: csnf-sentinel\nspec:\n  sink:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: Target\n      name: hello-sentinel\n  context:\n  - operation: add\n    paths:\n    - key: type\n      value: io.triggermesh.azure.sentinel.incident\n  data:\n  - operation: store\n    paths:\n    - key: $name\n      value: event.name\n    - key: $etag\n      value: event.guid\n    - key: $title\n      value: event.name\n    - key: $incidentID\n      value: event.resource.identifier\n    - key: $description\n      value: event.shortDescription\n  - operation: delete\n    paths:\n    - key:\n  - operation: add\n    paths:\n    - key: etag\n      value: $etag\n    - key: properties.providerIncidentId\n      value: $incidentID\n    - key: properties.status\n      value: new\n    - key: properties.severity\n      value: high\n    - key: properties.title\n      value: $title\n    - key: properties.description\n      value: $description\n    - key: properties.owner.assignedTo\n      value: bob\n</code></pre>","location":"targets/azuresentinel/#example-using-a-transformation"},{"title":"CloudEvents Target","text":"<p>Sends events over HTTP in CloudEvents format.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target cloudevents --endpoint &lt;endpoint&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: CloudEventsTarget\nmetadata:\n  name: sample\nspec:\n  endpoint: https://external.systen/mypath\n  credentials:\n    basicAuth:\n      username: user\n      password:\n        # The ce-target-password secret containing a password key must exist.\n        valueFromSecret:\n          name: ce-target-password\n          key: password\n</code></pre> <p>The <code>spec.endpoint</code> parameter is a destination that points to an HTTP URL that will receive the ingested CloudEvents.</p>  <p>Using a reference</p> <pre><code>spec:\n  endpoint: https://external.systen/mypath\n</code></pre>  <p>If the external system requires Basic Authentication this component can be configured to use credentials by means of Kubernetes secrets.</p> <p>The credentials are defined under <code>spec.credentials.basicAuths</code>:</p>  <p>Credentials</p> <pre><code>spec:\n  credentials:\n    basicAuth:\n      username: user\n      password:\n        valueFromSecret:\n          name: ce-target-password\n          key: password\n</code></pre>  <p>Accepts events of any type.</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/cloudevents/"},{"title":"Confluent target (deprecated)","text":"<p>Deprecated</p> <p>The Confluent Target is deprecated and replaced by the KafkaTarget.</p>  <p>Sends events to a Confluent Kafka cluster.</p>","location":"targets/confluent/"},{"title":"Prerequisite(s)","text":"<ul> <li>Access to a Kafka cluster with appropriate configuration details</li> </ul>","location":"targets/confluent/#prerequisites"},{"title":"Kafka Cluster Details","text":"<p>Depending on the cluster and user permissions, the Kafka topic must exist prior to setting up the target. Otherwise, the Target will attempt to create the topic which will require setting the <code>Topic replication</code> and <code>Topic partition</code>.</p>","location":"targets/confluent/#kafka-cluster-details"},{"title":"Event Types","text":"<p>The Confluent event Target leaves the CloudEvent type definition to the discretion of the implementer. In addition, no events are produced as a response.</p>","location":"targets/confluent/#event-types"},{"title":"Datadog target","text":"<p>Sends events to Datadog.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target datadog --apiKey &lt;apiKey&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: ddapitoken\ntype: Opaque\nstringData:\n  apiKey: __API_KEY__\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: DatadogTarget\nmetadata:\n name: datadogtarget\nspec:\n apiKey:\n  secretKeyRef:\n    name: ddapitoken\n    key: apiKey\n</code></pre> <p>Accepts events with the following attributes:</p> <p><code>io.triggermesh.datadog.metric</code>: events of this type intend to post a metric to Datadog</p> <p><code>io.triggermesh.datadog.event.post</code>: events of this type contain event messages to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     text string The body of the event. Limited to 4000 characters. The text supports markdown. true   title string The event title. Limited to 100 characters. Use msg_title with the Datadog Ruby library. true   alert_type string If an alert event is enabled, set its type. For example, error, warning, info, success, user_update, recommendation, and snapshot. Allowed enum values: error,warning,info,success,user_update,recommendation,snapshot. false   date_happened int64 POSIX timestamp of the event. Must be sent as an integer (i.e. no quotes). Limited to events no older than 7 days. false   device_name string A device name. false   host string Host name to associate with the event. Any tags associated with the host are also applied to this event. false   id int64 Integer ID of the event. false   priority string The priority of the event. For example, normal or low. Allowed enum values: normal,low. false   related_event_id int64 ID of the parent event. Must be sent as an integer (i.e. no quotes). false   source_type_name string The type of event being posted. Option examples include nagios, hudson, jenkins, my_apps, chef, puppet, git, bitbucket, etc. A complete list of source attribute values available here. false   status string A status. false   tags []string A list of tags to apply to the event. false   url string URL of the event. false    <p><code>io.triggermesh.datadog.metric.submit</code>: events of this type consist of a singular metric to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     host string The name of the host that produced the metric. false   interval int64 If the type of the metric is rate or count, define the corresponding interval. false   metric string The name of the timeseries. true   points [][]string Points relating to a metric. All points must be tuples with timestamp and a scalar value (cannot be a string). Timestamps should be in POSIX time in seconds, and cannot be more than ten minutes in the future or more than one hour in the past. true   tags []string A list of tags associated with the metric. false   type string The type of the metric either count, gauge, or rate. false    <p><code>io.triggermesh.datadog.logs.send</code> events of this type consist log data to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     ddsource string The integration name associated with your log: the technology from which the log originated. When it matches an integration name, Datadog automatically installs the corresponding parsers and facets. true   ddtags string Tags associated with your logs. false   hostname string The name of the originating host of the log. true   message string The message reserved attribute of your log. By default, Datadog ingests the value of the message attribute as the body of the log entry. That value is then highlighted and displayed in the Logstream, where it is indexed for full text search. true   service string The name of the application or service generating the log events. It is used to switch from Logs to APM, so make sure you define the same value when you use both products. false    <p>You can test the Target by sending it an event using <code>curl</code>.</p> <p>Example sending an event of type <code>io.triggermesh.datadog.metric.submit</code></p> <pre><code>curl -v \"http://localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.datadog.metric.submit\" \\\n       -H \"Ce-Source: ocimetrics/adapter\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"series\":[{\"metric\":\"five.golang\",\"points\":[[\"1614962026\",\"14.5\"]]}]}'\n</code></pre> <p>Example sending an event of type <code>io.triggermesh.datadog.event.post</code></p> <pre><code>curl -v \"http://localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.datadog.event.post\" \\\n       -H \"Ce-Source: ocimetrics/adapter\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"text\": \"Oh boy2!\",\"title\": \"Did you hear the news today?\"}'\n</code></pre> <p>Example sending an event of type <code>io.triggermesh.datadog.logs.send</code></p> <pre><code>curl -v \"http://localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.datadog.log.send\" \\\n       -H \"Ce-Source: ocimetrics/adapter\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{  \"ddsource\": \"nginx\", \"ddtags\": \"env:staging,version:5.1\", \"hostname\": \"i-012345678\", \"message\": \"2019-11-19T14:37:58,995 INFO Hello World\", \"service\": \"payment\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/datadog/"},{"title":"Prerequisite(s)","text":"<ul> <li>Datadog API token</li> </ul>","location":"targets/datadog/#prerequisites"},{"title":"Elasticsearch target","text":"<p>Sends events to Elasticsearch.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target elasticsearch --connection $(cat ./connection.txt) --indexName &lt;indexName&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: ElasticsearchTarget\nmetadata:\n  name: &lt;TARGET-NAME&gt;\nspec:\n  connection:\n    addresses:\n      - &lt;ELASTICSEARCH-URL&gt;\n    skipVerify: &lt;true|false&gt;\n    caCert: &lt;ELASTICSEARCH-CA-CERTIFICATE&gt;\n    apiKey:\n      secretKeyRef:\n        name: &lt;SECRET-CONTAINING-APIKEY&gt;\n        key: &lt;SECRET-KEY-CONTAINING-APIKEY&gt;\n    username: &lt;ELASTICSEARCH-USERNAME&gt;\n    password:\n      secretKeyRef:\n        name: &lt;SECRET-CONTAINING-PASSWORD&gt;\n        key: &lt;SECRET-KEY-CONTAINING-PASSWORD&gt;\n  indexName: &lt;ELASTICSEARCH-INDEX&gt;\n</code></pre> <p>Connection must include at least one address, including protocol scheme and port.</p> <ul> <li>example: <code>https://elasticsearch-server:9200</code></li> </ul> <p>The connection must be filled with one of:</p> <ul> <li><code>username</code> and <code>password</code></li> <li><code>apiKey</code></li> </ul> <p>If the Elasticsearch cluster is being served using a self-signed certificate the CA can be added, or TLS verify can be skipped:</p> <ul> <li><code>caCert</code> for adding the PEM string for the certificate.</li> <li><code>skipVerify</code> set to true for skip checking certificates.</li> </ul> <p>Received events will be indexed using <code>indexName</code> as the elasticsearch index.</p> <p>Here is an example with real values:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: ElasticsearchTarget\nmetadata:\n  name: es-indexing\nspec:\n  connection:\n    addresses:\n    - https://elasticsearch-host:9200\n    skipVerify: true\n    username: elastic\n    password:\n      secretKeyRef:\n        name: elasticsearch\n        key: password\n  indexName: tmindex\n  eventOptions:\n    payloadPolicy: error\n</code></pre> <p>Accepts events of any type. Elasticsearch Target will forward any valid JSON payload.</p> <p>Ideally, the JSON conforms to the index mapping at elasticsearch.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://elasticsearchtarget-es-indexinge5d0adf0209a48c23fa958aa1b8ecf0b.default.svc.cluster.local \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: something.to.index.type\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"message\":\"thanks for indexing this message\",\"from\": \"TriggerMesh targets\", \"some_number\": 12}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/elasticsearch/"},{"title":"Prerequisites","text":"<p>A Elasticsearch cluster and a set of credentials:</p> <ul> <li>Elastic Cloud on Kubernetes ECK is the simplest way to get started, Elastic Cloud or any other Elasticsearch cluster. Version 7.x is preferred.</li> <li>User and password to the Elasticsearch cluster.</li> <li>An APIKey instead of User and password.</li> <li>CACertificate if using self-signed certificate and <code>SkipVerify</code> is not configured.</li> </ul>","location":"targets/elasticsearch/#prerequisites"},{"title":"Google Cloud Pub/Sub target","text":"<p>Sends events to a Google Cloud Pub/Sub topic.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target googlecloudpubsub --topic &lt;topic&gt; --credentialsJson $(cat ./creds.json) --event-types my.type\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: GoogleCloudPubSubTarget\nmetadata:\n  name: googlecloudpubsub\nspec:\n  topic: &lt;topic&gt;\n  credentialsJson:\n    secretKeyRef:\n      name: googlecloudpubsub\n      key: creds\n</code></pre> <p>This target consumes events of any type.</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/googlecloudpubsub/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google Cloud Console account.</li> <li>A service account and it's associated JSON credentials.</li> <li>a pre-existing Google Cloud Pub/Sub topic.</li> </ul>","location":"targets/googlecloudpubsub/#prerequisites"},{"title":"GoogleCloudStorage target","text":"<p>Sends events to GoogleCloudStorage.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target googlecloudstorage --bucketName &lt;bucketName&gt; --credentialsJson $(cat ./creds.json)\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: googlecloudstorage\ntype: Opaque\nstringData:\n  creds: |-\n    {\n      \"type\": \"service_account\",\n      \"project_id\": \"dev\",\n      \"private_key_id\": \"e1e4ad14a8d234adf4963d398863ad12444df\",\n      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQQWFNBgkqhkiG9w0BAQEFAASCB...R6Y=\\n-----END PRIVATE KEY-----\\n\",\n      \"client_email\": \"tst-27@dev.iam.gserviceaccount.com\",\n      \"client_id\": \"11547922342598721477\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/gstst-27%40dev.iam.gserviceaccount.com\"\n    }\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: GoogleCloudStorageTarget\nmetadata:\n  name: googlecloudstorage\nspec:\n  bucketName: tmdemo\n  credentialsJson:\n    secretKeyRef:\n      name: googlecloudstorage\n      key: creds\n</code></pre> <p>The target accepts events of type <code>com.google.cloud.storage.object.insert</code> to pass payload with the following properties:</p> <ul> <li><code>data</code>: []byte, base64 encoded data</li> <li><code>fileName</code>: string, the file name with type (ex. 'file.png')</li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v \"localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: com.google.cloud.storage.object.insert\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"data\":\"iVBORw0KGgoAAAANSUhEUgAAAIUAAABYCAYAAADbejTNAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAQTSURBVHhe7ZtRjuQ4DEP3Tn3/s/VAH1oQEi3LsVM1yfABBDoiLQdVxHT/zH+/QgRUCpFQKURCpRAJlUIkVAqRUClEQqUQCZVCJFQKkVApREKlEAmVQiS+Xoqfn5//xUC/yolzbJeCfWmVkJlvdDKfgr1LpaeiUizA3qXSU1EpFmDvUumpfLUURuUZ6Fe5T8DepdJTuaUUJ7l7/wp/07vciUqxwN/0Lnfy1VJ0znYyEXbGtMvJnWyXaUaVZ3Oc4dwYea8qBctG7XBiH9sRVTHK7s5RrykFy410ld1d7PxII1guznxusHmcRf2TpTBdYXcPO1+JwXJMDvNmekUpZpmZ32VnDztrcphnirBMFMJ8ExK9W0pRCZn5xiczM9iOSsjMN65mTCM62ei/shSMmBnlKtiOSkjlIbNc9FkG6ebRVykWYDsqOZUXmWVnfqSbR//xpWB+V6uwHZWcyovMsjM/0s2j//g/NJnf1SpXd6ycm2VnfqSbR1+lWODqjpVzs+zMj3Tz6L+yFHdx9a6Vc7PszI908+irFAtcvWvl3Cw78yPdPPqPL4Ux808R71m5q3tulos+yyDdPPqvLAXLnGDnns7ZUxmkm0f/taUwMSpvBu5e3cPOmhzmmSKdDNLNo/+KUhgsV+kKu3vY+UqMbs7p5tF/TSkMlh3pCif2sB0jMbo5p5tH/1WlMFie6Qp37okasZI1unn0X1cKg51x7XByH9tlmrF6pptHf7sU4n2oFCKhUoiESiESKoVIqBQioVKIhEohEiqFSKgUIqFSiIRKIRIqhUioFCKhUoiESiESKoVIqBQioVKIhEohEiqFSKgUIqFSiIRKIRIqhUioFCKhUoiESiESl0uB/yF1xkpWnGHn8976l6J78c4LimvsfObbvz5ml++8nLjOzud+rBTsBSpP3MvO537kD0325bMZgv4sw6i8EX5mdjbmXBGcY85nHap89PDZf8YZMpobeI5ljpTCiBeMLvT5SAibOZUX8SwTwvwohPmoDlU2ev48ElLNRnKOlcIYXYKMPDYfZY3Ki7Csz3DOcg7zfNadM6pc9Pw55ndmRpx/tBSjuRP9Kl95yIkdBstW5ysPWdmxk43PEfSPlsKoLq88I/pVvvKQbo7hZ1EImzmVh6zs2MnG5wj6KkXA8yMhbOZUHrKyYycbnyPoqxSAZ9mZ7sypPGRlx042PkfQ/6dLEb2VrLGaZ6zs2MnG5wj6Hy2FMfLZ3Gfd+YjuDpYzWNYY5Y3KQzwXs2zOZsbOzIjzr5VipAjLoDqwcy6E+VEImzmVF/HsSA7zUEg1G8n5eCkcfJlZnmXx5w54vjpb5WbPSOUxPI/n8GeDeThDRnMDz7HM8VKI+xh9iadRKR6ESiESKoVIqBTiS/z+/gGzfSWEBhuJawAAAABJRU5ErkJggg==\",\"fileName\":\"img4.png\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/googlecloudstorage/"},{"title":"Prerequisites","text":"<ul> <li>Google Storage enabled in Google Cloud Console</li> <li>A Google Cloud Service account with rights to the storage resources and the credentials in JSON format.</li> </ul>","location":"targets/googlecloudstorage/#prerequisites"},{"title":"Google Cloud Workflows target","text":"<p>Sends events to Google Cloud Workflows.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target googlecloudworkflows --credentialsJson $(cat ./creds.json)\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: googlecloudworkflows\ntype: Opaque\nstringData:\n  creds: |-\n    {\n      \"type\": \"service_account\",\n      \"project_id\": \"dev\",\n      \"private_key_id\": \"e1e4ad14a8d234adf4963d398863ad12444df\",\n      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQQWFNBgkqhkiG9w0BAQEFAASCB...R6Y=\\n-----END PRIVATE KEY-----\\n\",\n      \"client_email\": \"tst-27@dev.iam.gserviceaccount.com\",\n      \"client_id\": \"11547922342598721477\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/gstst-27%40dev.iam.gserviceaccount.com\"\n    }\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: GoogleCloudWorkflowsTarget\nmetadata:\n  name: googlecloudworkflows\nspec:\n  credentialsJson:\n    secretKeyRef:\n      name: googlecloudworkflows\n      key: creds\n</code></pre> <p>Accepts events with the following attributes:</p> <ul> <li>type <code>io.trigermesh.google.workflows.run</code></li> </ul> <p>Events of this type contain the data necessary to run a Google Workflow.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     parent string Project and location in which the workflow should be created. Format:  <code>projects/{project}/locations/{location}</code> \"projects/ultra-hologram-297914/locations/us-central1\"   executionName string The resource name of the execution. Format: <code>projects/{project}/locations/{location}/workflows/{workflow}/executions/{execution}</code> \"demowf\"    <p>You can test the Target by sending it an event using <code>curl</code>:</p> <p><code>curl -v http://googlecloudworkflowstarget-googlecloudworkflows.dmo.svc.cluster.local \\  -X POST \\  -H \"Content-Type: application/json\" \\  -H \"Ce-Specversion: 1.0\" \\  -H \"Ce-Type: io.trigermesh.google.workflows.run\" \\  -H \"Ce-Source: some.origin/intance\" \\  -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\  -d '{\"parent\":\"projects/ultra-hologram-297914/locations/us-central1/workflows/demowf\",\"executionName\":\"projects/ultra-hologram-297914/locations/us-central1/workflows/demowf/executions/testex\"}'</code></p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/googlecloudworkflows/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google Cloud Console account.</li> <li>A service account and it's associated JSON credentials.</li> </ul> <p>For more information about using Google Cloud Workflows, please refer to the [documentation][https://cloud.google.com/workflows/docs].</p>","location":"targets/googlecloudworkflows/#prerequisites"},{"title":"Google Firestore target","text":"<p>Sends events to Google Firestore.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target googlecloudfirestore --projectID &lt;projectID&gt; --defaultCollection &lt;defaultCollection&gt; --credentialsJson $(cat ./creds.json)\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: GoogleCloudFirestoreTarget\nmetadata:\n  name: googlecloudfirestore\nspec:\n  defaultCollection: &lt;defaultCollection&gt;\n  projectID: &lt;projectID&gt;\n  discardCloudEventContext: true\n  credentialsJson:\n    secretKeyRef:\n      name: googlecloudfirestore\n      key: creds\n</code></pre> <p>You can test the Target by sending it an arbitrary event using <code>curl</code>. It will upload them into a table with the event ID as the document name:</p> <pre><code>curl -v \"http://googlecloudfirestoretarget-googlecloudfirestore.dmo.svc.cluster.local\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9dsdf7a-a3f162s705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.arbitrary\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"data\":\"hello World\"}'\n</code></pre>","location":"targets/googlefirestore/"},{"title":"io.triggermesh.google.firestore.write","text":"<p>Events of this type contain nuanced data that is used to specify the document, collection, and data on each call to the target.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be written. \"eventtst\"   document string Defines the firebase document name to be written. \"doctestst\"   data map[string]interface{} Defines the items to be written to the document. {\"fromEmail\":\"bob@triggermesh.com\",\"hello\":\"pls\"}    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.write.response</code></p> <p>Sending events of type <code>io.triggermesh.google.firestore.write</code> If it is preferd to specify the collection on each call to the target, an event of type <code>io.triggermesh.google.firestore.write</code> can be sent. The payload body must contain the following attributes:  <code>collection</code> : Defines the firebase collection to be written under  <code>document</code> : Defines the firebase document name to be written  <code>data</code> : Defines the items to be written to the document</p> <pre><code>curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/dmo/default\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.google.firestore.write\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"collection\":\"eventtst\",\"document\":\"doctests1\",\"data\":{\"fromEmail\":\"bob@triggermesh.com\",\"hello\":\"pls\"}}'\n</code></pre>","location":"targets/googlefirestore/#iotriggermeshgooglefirestorewrite"},{"title":"io.triggermesh.google.firestore.query.tables","text":"<p>Events of this type contain nuanced data that is used to return all tables in a provided collection.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be queried. \"eventtst\"    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.query.tables.response</code></p> <p>Sending events of type <code>io.triggermesh.google.firestore.query.tables</code> Return all tables in a provided collection <pre><code>curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/dmo/default\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.google.firestore.query.tables\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"collection\":\"eventtst\"}'\n</code></pre></p>","location":"targets/googlefirestore/#iotriggermeshgooglefirestorequerytables"},{"title":"io.triggermesh.google.firestore.query.table","text":"<p>Events of this type contain nuanced data that is used to specify the document, collection, and data on each call to the target.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be queried. \"eventtst\"   document string Defines the firebase document name to retrieved. \"536808d3-88be-4077-9d7a-a3f162s705f79\"    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.query.table.response</code></p> <p>Sending events of type <code>io.triggermesh.google.firestore.query.table</code> Return a selected table from a collection <pre><code>curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/dmo/default\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.google.firestore.query.table\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"collection\":\"deploydemo\",\"document\":\"536808d3-88be-4077-9d7a-a3f162s705f79\"}'\n</code></pre></p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/googlefirestore/#iotriggermeshgooglefirestorequerytable"},{"title":"Prerequisite(s)","text":"<ul> <li>Google Cloud Console account.</li> <li>A service account and it's associated JSON credentials.</li> </ul>","location":"targets/googlefirestore/#prerequisites"},{"title":"Google Sheets target","text":"<p>Sends events to GoogleSheets.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target googlesheet --id &lt;id&gt; --defaultPrefix &lt;defaultPrefix&gt; --googleServiceAccount $(cat ./creds.json)\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: googlesheet\ntype: Opaque\nstringData:\n  # Replace the example below with a valid Google Credentials JSON string.\n  googleServiceAccount: |-\n    {\n      \"type\": \"service_account\",\n      \"project_id\": \"dev\",\n      \"private_key_id\": \"e1e4ad14a8d234adf4963d398863ad12444df\",\n      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQQWFNBgkqhkiG9w0BAQEFAASCB...R6Y=\\n-----END PRIVATE KEY-----\\n\",\n      \"client_email\": \"tst-27@dev.iam.gserviceaccount.com\",\n      \"client_id\": \"11547922342598721477\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/gstst-27%40dev.iam.gserviceaccount.com\"\n    }\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: GoogleSheetTarget\nmetadata:\n  name: triggermesh-googlesheet\nspec:\n  # Below is an example Spreadsheet ID. Change this.\n  id: 14GKZKWVB2TsYy31cCZ43YwA1LoOlVeL4nB7jlZbgFAk\n  # Static prefix assignment for reciving CloudEvents without prior transformation.\n  defaultPrefix: &lt;Default Prefix&gt;\n  # These values should not change.\n  googleServiceAccount:\n    secretKeyRef:\n      name: googlesheet\n      key: credentials\n</code></pre> <p><code>id</code> is a unique identifier that can be retrieved from the URL path or parameters:   - from path: <code>https://docs.google.com/spreadsheets/d/&lt;SHEET_ID&gt;/edit</code>   - from query string: <code>https://docs.google.com/spreadsheet/ccc?key=&lt;SHEET_ID&gt;</code></p> <p><code>Default Prefix</code> is a string used during new sheet creation when the event does not provide one.</p> <p>GoogleSheets Target accepts any event types and passes the entire event into a new row on the specified Sheet.</p> <p>You can test the Target by sending it an event using <code>curl</code>.</p> <p>Sending arbitrary events:</p> <pre><code>curl -v localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: some.message.type\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"mgs\":\"Hello from TriggerMesh using GoogleSheet!\"}'\n</code></pre> <p>Sending events of type <code>io.triggermesh.googlesheet.append</code>.</p> <p>Accepts the following properties in <code>data</code>:</p>    Name Type Comment Required     sheet_name string The name of the sheet to create and or populate true   rows []string List of data to populate the new row. true   message string A string to append to the sheet row true    <pre><code>curl -v localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: io.triggermesh.googlesheet.append\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"rows\":[\"Hello from TriggerMesh using GoogleSheet!\", \"test\",\"sheet1\"],\"sheet_name\":\"Sheet1\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/googlesheets/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google API credentials</li> <li>GoogleSheets Sheet ID</li> </ul>","location":"targets/googlesheets/#prerequisites"},{"title":"Google API Credentials","text":"<ol> <li>Head to the Google Developers Console and create a new  project (or select the one you have).</li> <li>Under APIs &amp; Services &gt; Library, search for \u201cSheets API\u201d and enable it.</li> <li>Go to APIs &amp; Services &gt; Credentials and choose \u201cCreate credentials &gt; Service account\u201d. Enter a service account name, ID, and description. You can skip optional fields, no additional roles or  user access is required.</li> <li>On the last step of service account creation, download the JSON key file.</li> <li>Use the email from the <code>client_email</code> field within the JSON key file to share the GoogleSheets Sheet you want the Target to have access to. The Notify people checkbox should be unchecked.</li> </ol>","location":"targets/googlesheets/#google-api-credentials"},{"title":"GoogleSheets Sheet ID","text":"<p>In your browser, navigate to the GoogleSheets Sheet you want to use. You can find the Sheet ID in one of two ways:</p> <ul> <li>From path: <code>https://docs.google.com/spreadsheets/d/&lt;SHEET_ID&gt;/edit</code></li> <li>From query string: <code>https://docs.google.com/spreadsheet/ccc?key=&lt;SHEET_ID&gt;</code></li> </ul>","location":"targets/googlesheets/#googlesheets-sheet-id"},{"title":"Hasura target","text":"<p>Send GraphQL queries to Hasura.</p> <p>The Hasura target can handle two types of events: a raw request for Hasura that consists of a JSON payload, and passing a premade query with the parameters in a key/value array.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target hasura --endpoint &lt;endpoint&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: hasuratargetadminsecret\ntype: Opaque\nstringData:\n  token: &lt;REPLACE ME WITH A REAL TOKEN&gt;\n</code></pre> <p>Example with a predefined query</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: HasuraTarget\nmetadata:\n name: hasuratarget\n\nspec:\n  endpoint: 'http://hasura.example.com:8080' # Target Hasura instance\n  queries:\n    - name: MyQuery\n      query: \"query MyQuery($person_id: Int) { foo(where: {id: {_eq: $person_id}} ) { id name } }\"\n</code></pre> <p>If required, the admin token or a JWT token can be specified for queries that require authorized access.  Lastly, if a particular role is required, a <code>defaultRole</code> can be defined.</p> <ul> <li>Admin Token for Hasura: An admin secret or JWT to communicate with Hasura as discussed in Admin Secret or JWT.</li> <li>Hasura Server URL: URL endpoint to communicate with Hasura.</li> <li>Default Role: Specify the Hasura user role to use when querying Hasura.</li> <li>Pre-canned Queries: A key/value pair of predefined queries available for CloudEvents to specify.</li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>.</p> <p>Example of sending a raw query:</p> <pre><code>curl -v http://localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: org.graphql.query.raw\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\n  \"query\": \"query MyQuery { foo { id name } }\",\n  \"operationName\": \"MyQuery\",\n  \"variables\": {}\n}'\n</code></pre> <p>To make use of the pre-defined query, the <code>Ce-Subject</code> will need to specify the specific query, and the <code>Ce-Type</code> must match <code>org.graphql.query</code> or <code>org.graphql.query.raw</code>. The resulting payload must be an object of keys and string values.</p> <p>Example of sending a predefined query:</p> <pre><code>curl -v http://localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: org.graphql.query\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Subject: MyQuery\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"person_id\": \"5\"}'\n</code></pre> <p>The Hasura target accepts the following event types.</p> <p><code>org.graphql.query.raw</code></p> <p>Events of this type are raw GraphQL queries intended to be submitted directly to Hasura.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     query string The GraphQL to run against the Hasura server   operationName string The query name specified in the query attribute   variables map[string]string Key/value pairs of variables with the key defined in the query    <p>The response event will have the <code>ce-type</code> attribute set to <code>org.graphql.query.result</code> and <code>ce-source</code> attribute set to the Target's endpoint.</p> <p><code>org.graphql.query</code></p> <p>Events of this type leverage the pre-defined query defined when the Target is created. In addition to the <code>ce-type</code>, the <code>ce-subject</code> must be set to the name of the pre-defined query, otherwise the event will not be processed by the Target.</p> <p>The JSON payload for this type must consist of a string dictionary where the keys correspond to the variables defined in the query, and key's value is passed as a string.</p> <p>The response event will have the <code>ce-type</code> attribute set to <code>org.graphql.query.result</code> and <code>ce-source</code> attribute set to the Target's endpoint.</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/hasura/"},{"title":"Prerequisites","text":"<p>The Hasura base URL acting as the endpoint is a requirement.  In addition, either an admin token or JWT token may be required to grant permission to the target tables hosted by Hasura.</p> <p>If using JWT, you may choose to add an optional user role to invoke the queries as.</p> <p>Authentication and authorization will be considered out of scope for the target guide, but can be found in the Hasura Guide</p> <p>For more information about using Hasura and GraphQL, please refer to the Hasura and GraphQL documentation.</p>","location":"targets/hasura/#prerequisites"},{"title":"HTTP target","text":"<p>Sends events over HTTP to external services.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target http --endpoint &lt;endpoint&gt; --method &lt;method&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: HTTPTarget\nmetadata:\n  name: triggermesh-http\n  namespace: mynamespace\nspec:\n  response:\n    eventType: triggermesh.http.type\n    eventSource: my.service.com\n  endpoint: 'https://my.service.com/my/path?some_key=&lt;SOME-KEY&gt;'\n  method: 'GET'\n  skipVerify: false\n  caCertificate: |-\n    -----BEGIN CERTIFICATE-----\n    MIIFazCCA1OgAwIBAgIUc6d3XTcIV4Ku7lovbHGuaVwAPqEwDQYJKoZIhvcNAQEL\n    BQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\n    ...\n    L4uCwbnED802y7PXCqNzcDjbRfWcXm2aDVM6Dc++am5NDx+JjTLFgNeiiAyRGI8z\n    5tJeGYFpd4Cxzt92s6ODIZVZZe+vP41Jey23yEgPpyv5F47WegApe73g1y4bBjg=\n    -----END CERTIFICATE-----\n  basicAuthUsername: myuser\n  basicAuthPassword:\n    secretKeyRef:\n      name: myservice\n      key: password\n  headers:\n    User-Agent: TriggerMesh-HTTP\n    Some-header: some-value\n</code></pre> <ul> <li><code>response.eventType</code> event type for the response message. Mandatory</li> <li><code>response.eventSource</code> event source for the response message. Mandatory</li> <li><code>endpoint</code> URL including path and querystring for the remote HTTP service. Mandatory</li> <li><code>method</code> verb for the HTTP rquest. Mandatory</li> <li><code>skipVerify</code> to skip remote server TLS certificate verification. Optional</li> <li><code>caCertificate</code> CA certificate configured for TLS connection. Optional</li> <li><code>basicAuthUsername</code> basic authentication user name. Optional</li> <li><code>basicAuthPassword</code> secret reference to basic authentication password. Optional</li> <li><code>headers</code> string map of key/value pairs as HTTP headers. Optional</li> </ul> <p>Requests from this HTTP Target will verify TLS certificates from the remote server if present. If the CA certificate at the server is self-signed, the public certificate needs to be added to the configuration, or alternatively mark the <code>Skip Verify</code> option.</p> <p>The HTTP Target expects an event whose attributes complement the Target parameters.</p> <p>There is no requirement regarding the <code>type</code> header value.</p> <p>The <code>data</code> attribute can contain the following optional JSON attributes:</p>    Field Description Example     query_string Key/value pairs formatted as query string <code>name=jane&amp;lastname=doe</code>   path_suffix Will be appended to the target's path <code>apparel/tshirts</code>   body String to be set as the request body <code>{\\\"size\\\":\\\"L\\\",\\\"color\\\":\\\"beige\\\"}</code>    <p>Below are two examples of values for the <code>data</code> attribute:</p> <pre><code>{\"path_suffix\":\"world/italy/cities\", \"query_string\":\"top=10&amp;format=csv\"}\n</code></pre> <p>If body is a JSON structure, it will need to be stringified:</p> <pre><code>{\"body\": \"{\\\"records\\\":[{\\\"value\\\":{\\\"this\\\":{\\\"is\\\": \\\"sparta\\\"}}}]}\"}\n</code></pre> <p>Responses from external HTTP endpoints are converted into CloudEvents and sent as a reply to the TriggerMesh Broker. It is important that the HTTP Target only be sent very specific event types, and carefuly handles response event types, so as to avoid events loops in which the response from the external HTTP service is reprocessed by the HTTP Target.</p> <p>As an example:</p> <ul> <li>We configure an HTTP Target to integrate with Workday.</li> <li>A Trigger sends events of type <code>calendar.pto.request</code> to the HTTP Target.</li> <li>The response from Workday will generate a CloudEvent of type <code>workday.pto.response</code> and source <code>workday.instance1</code>.</li> </ul> <p>As long as the Trigger for the HTTP Target is only reacting to events of type <code>calendar.pto.request</code>, the we're guaranteed that responses from Workday won't be sent straight back to Workday.</p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/http/"},{"title":"Tutorial: COVID-19 stats","text":"<p>We will configure an HTTP target that can use the COVID-19 API. Then we will use it to gather information about the world total stats.</p> <p>Create the HTTP Target pointing to the COVID-19 API:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: HTTPTarget\nmetadata:\n  name: corona\n  namespace: mynamespace\nspec:\n  response:\n    eventType: covid.stats\n  endpoint: 'https://api.covid19api.com/'\n  method: 'GET'\n</code></pre> <p>The target will expose an internal URL that can be retrieved using the Kubernetes API.</p> <pre><code>$ kubectl get httptargets.targets.triggermesh.io -n mynamespace\nNAME                        URL                                                                     READY   REASON   AGE\ncorona   http://httptarget-corona-mynamespace.default.svc.cluster.local   True             5d5h\n</code></pre> <p>Run an ephemeral curl container passing the command CloudEvent parameters that will be adding the path suffix to the endpoint that returns the world total stats for the service.</p> <pre><code>$ kubectl run --generator=run-pod/v1 curl-me --image=curlimages/curl -ti --rm -- \\\n  -v -X POST http://httptarget-corona.mynamespace.svc.cluster.local \\\n  -H \"content-type: application/json\" \\\n  -H \"ce-specversion: 1.0\" \\\n  -H \"ce-source: curl-triggermesh\" \\\n  -H \"ce-type: my-curl-type\" \\\n  -H \"ce-id: 123-abc\" \\\n  -d '{\"path_suffix\":\"world/total\"}'\n\n...\n</code></pre>","location":"targets/http/#tutorial-covid-19-stats"},{"title":"Tutorial: Calendarific country calendar","text":"<p>We will configure an HTTP target that uses Calendarify to retrieve wordlwide holidays.</p> <p>Create a Calendarific account and retrieve an API key.</p> <p>Create the HTTP Target using the API key:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: HTTPTarget\nmetadata:\n name: calendarific\n namespace: mynamespace\nspec:\n  response:\n    eventType: calendarific.holidays\n  endpoint: 'https://calendarific.com/api/v2/holidays?api_key=REPLACE-WITH-APIKEY'\n  method: 'GET'\n</code></pre> <p>Retrieve the internal URL.</p> <pre><code>$ kubectl get httptargets.targets.triggermesh.io -n mynamespace\nNAME                        URL                                                                     READY   REASON   AGE\ncalendarific  http://httptarget-calendarific-mynamespace.default.svc.cluster.local   True             5d5h\n</code></pre> <p>Run an ephemeral curl container passing the command CloudEvent parameters that will be adding the querystring to return the US holidays for 2021.</p> <pre><code>$ kubectl run --generator=run-pod/v1 curl-me --image=curlimages/curl -ti --rm -- \\\n  -v -X POST http://httptarget-calendarific.mynamespace.svc.cluster.local \\\n  -H \"content-type: application/json\" \\\n  -H \"ce-specversion: 1.0\" \\\n  -H \"ce-source: curl-triggermesh\" \\\n  -H \"ce-type: my-curl-type\" \\\n  -H \"ce-id: 123-abc\" \\\n  -d '{\"query_string\":\"country=US&amp;year=2020\"}'\n\n...\n</code></pre>","location":"targets/http/#tutorial-calendarific-country-calendar"},{"title":"IBM MQ target","text":"<p>Sends events to IBM MQ.</p> <p>With <code>tmctl</code>:</p> <pre><code>--connectionName &lt;connectionName&gt; --channelName &lt;channelName&gt; --queueManager &lt;queueManager&gt; --queueName &lt;queueName&gt; --credentials.username &lt;username&gt; --credentials.password &lt;password&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: IBMMQTarget\nmetadata:\n  name: ibm-mq-target\nspec:\n  connectionName: ibm-mq.default.svc.cluster.local(1414)\n  queueManager: QM1\n  queueName: DEV.QUEUE.1\n  channelName: DEV.APP.SVRCONN\n  replyTo:\n    queueName: DEV.QUEUE.2\n  credentials:\n    username:\n      valueFromSecret:\n        name: ibm-mq-secret\n        key: username\n    password:\n      valueFromSecret:\n        name: ibm-mq-secret\n        key: password\n</code></pre> <p>Accepts events of any type, and supports a specific <code>io.triggermesh.ibm.mq.put</code> event.</p> <p>Responds with events of type <code>io.triggermesh.ibm.mq.response</code></p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/ibmmq/"},{"title":"Creating an IBM MQ server for testing","text":"<p>Head to the IBM MQ Source documentation for guides on how to run a local IBM MQ server for testing.</p>","location":"targets/ibmmq/#creating-an-ibm-mq-server-for-testing"},{"title":"Jira target","text":"<p>Sends events to Jira, allowing you to create and retrieve Jira tickets or perform custom actions using the Jira API.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target jira --url &lt;url&gt; --auth.user &lt;user&gt; --auth.token &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: jiratoken\ntype: Opaque\nstringData:\n  token: \"jira-api-token\"\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: JiraTarget\nmetadata:\n  name: tmjira\nspec:\n  auth:\n    user: woodford@triggermesh.com\n    token:\n      secretKeyRef:\n        name: jira\n        key: token\n  url: https://tmtest.atlassian.net\n</code></pre> <p>Jira fields <code>user</code>, <code>token</code> and <code>url</code> are required.</p> <p>The Jira target accepts a number of different event types which result in different interactions with Jira.</p>","location":"targets/jira/"},{"title":"<code>com.jira.issue.create</code>","text":"<p>The Jira event Target will create an issue when receiving this event type. The CloudEvent data must contain a Jira issue JSON formatted as defined in this schema.</p> <p>Reply contains a partially filled Jira issue with updated data.</p> <pre><code>curl -v -X POST http://jiratarget-tmjira.default.svc.cluster.local \\\n-H \"content-type: application/json\" \\\n-H \"ce-specversion: 1.0\" \\\n-H \"ce-source: curl-triggermesh\" \\\n-H \"ce-type: io.triggermesh.jira.issue.create\" \\\n-H \"ce-id: 123-abc\" \\\n-d '{\n    \"fields\": {\n       \"project\":\n       {\n          \"key\": \"IP\"\n       },\n       \"labels\": [\"alpha\",\"beta\"],\n       \"summary\": \"Day 30.\",\n       \"description\": \"Issue created using TriggerMesh Jira Target\",\n       \"issuetype\": {\n          \"name\": \"Task\"\n       },\n       \"assignee\": {\n          \"accountId\": \"5fe0704c9edf280075f188f0\"\n       }\n   }\n}'\n</code></pre>","location":"targets/jira/#comjiraissuecreate"},{"title":"<code>com.jira.issue.get</code>","text":"<p>The Jira event Target will retrieve an issue when receiving this event type. The CloudEvent data must contain a Jira issue <code>GET</code> request JSON formatted as defined in this schema.</p> <p>Reply data contains a Jira issue.</p> <pre><code>curl -v -X POST http://jiratarget-tmjira.default.svc.cluster.local \\\n-H \"content-type: application/json\" \\\n-H \"ce-specversion: 1.0\" \\\n-H \"ce-source: curl-triggermesh\" \\\n-H \"ce-type: io.triggermesh.jira.issue.get\" \\\n-H \"ce-id: 123-abc\" \\\n-d '{\"id\":\"IP-9\"}'\n</code></pre>","location":"targets/jira/#comjiraissueget"},{"title":"<code>com.jira.custom</code>","text":"<p>The Jira event Target will send a request to the Jira API when this event type is received. The CloudEvent data expects a generic API request as defined in this schema.</p> <pre><code>curl -v -X POST http://jiratarget-tmjira.default.svc.cluster.local \\\n-H \"content-type: application/json\" \\\n-H \"ce-specversion: 1.0\" \\\n-H \"ce-source: curl-triggermesh\" \\\n-H \"ce-type: io.triggermesh.jira.custom\" \\\n-H \"ce-id: 123-abc\" \\\n-d '{\n    \"method\": \"GET\",\n    \"path\": \"/rest/api/3/user/assignable/search\",\n    \"query\": {\"project\": \"IP\"}\n   }'\n</code></pre> <p>Please, refer to the Jira API on how to fill in values for these requests.</p> <p>See the Kubernetes object reference for more details on the TriggerMesh configuration options.</p>","location":"targets/jira/#comjiracustom"},{"title":"Prerequisites","text":"<ol> <li>Jira instance or Atlassian cloud tenant.</li> <li>User API token.</li> </ol> <p>To create the user API token at Jira:</p> <ul> <li>Open the Account settings &gt; Security &gt; Create and manage API Tokens</li> <li>Press <code>Create API token</code> and fill the token name.</li> <li>Copy the API token and create a secret for the Jira token at TriggerMesh.</li> </ul>","location":"targets/jira/#prerequisites"},{"title":"Kafka target","text":"<p>Sends events to Apache Kafka. Can be used with any Kafka API compatible service such as Confluent Kafka or RedPanda.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create source kafka --bootstrapServers kafka.example.com:9092 --topics &lt;topic&gt;\n</code></pre> <p>On Kubernetes, using SASL-PLAIN authentication:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: KafkaTarget\nmetadata:\n  name: sample\nspec:\n  bootstrapServers:\n  - kafka.example.com:9092\n  topic: test-topic\n  auth:\n    saslEnable: true\n    tlsEnable: false\n    securityMechanism: PLAIN\n    username: admin\n    password:\n      value: admin-secret\n</code></pre> <p>Accepts events of any type.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://kafkatarget-int1-9fg4abc7d44bdd0204bd0a221bea9453k.default.svc.cluster.local\n \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: some.message.type\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 739481h1-34gt-9801-4h0d-g6e048192l23\" \\\n -d '{\"message\":\"Hello from TriggerMesh using Kafka!\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/kafka/"},{"title":"Using KafkaTarget with Kerberos-SSL authentication","text":"<p>This section demonstrates how to configure a KafkaTarget to use Kerberos-SSL authentication on Kubernetes.</p> <p>Before creating the <code>KafkaTarget</code>, we are going to create some secrets that the <code>KafkaTarget</code> will need for the authentication with Kerberos + SSL.</p> <ul> <li>The kerberos config file.</li> <li>The kerberos keytab file.</li> <li>The CA Cert file.</li> </ul> <pre><code>kubectl create secret generic config --from-file=krb5.conf\nkubectl create secret generic keytab --from-file=krb5.keytab\nkubectl create secret generic cacert --from-file=ca-cert.pem\n</code></pre> <p>You can then create the Target: </p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: KafkaTarget\nmetadata:\n  name: sample\nspec:\n  salsEnable: true\n  tlsEnable: true\n  bootstrapServers:\n  - kafka.example.com:9093\n  topic: test-topic\n  securityMechanism: GSSAPI\n  kerberosAuth:\n    username: kafka\n    kerberosRealm: EXAMPLE.COM\n    kerberosServiceName: kafka\n    kerberosConfig:\n      valueFromSecret:\n        name: config\n        key: krb5.conf\n    kerberosKeytab:\n      valueFromSecret:\n        name: keytab\n        key: krb5.keytab\n  sslAuth:\n    insecureSkipVerify: true\n    sslCA:\n      valueFromSecret:\n        name: cacert\n        key: ca-cert\n</code></pre>","location":"targets/kafka/#using-kafkatarget-with-kerberos-ssl-authentication"},{"title":"Logz.io target","text":"<p>Sends events to Logz.io.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target logz --shippingToken &lt;shippingToken&gt; --logsListenerURL &lt;logsListenerURL&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: logz\ntype: Opaque\nstringData:\n  token: my_token  # Update this value with a valid shipping token\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: LogzTarget\nmetadata:\n  name: tmlogz\nspec:\n  logsListenerURL: listener.logz.io\n  shippingToken:\n    secretKeyRef:\n      name: logz\n      key: token\n</code></pre> <ul> <li>Shipping Token: contains the Logz.io shipping token</li> <li>Logs Listener URL: An API endpoint that can be found above your shipping token in the Logz.io dashboard.</li> </ul> <p>The Logz target accepts events of type <code>io.triggermesh.logz.ship</code>, and responds with events of type <code>io.triggermesh.logz.ship.response</code>.</p> <p>The payload contains a JSON structure called <code>message</code>, which is the message to log in Logz.io.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <p><code>cmd curl -v http://logztarget-tmlogz.logz.svc.cluster.local \\  -X POST \\  -H \"Content-Type: application/json\" \\  -H \"Ce-Specversion: 1.0\" \\  -H \"Ce-Type: any.event.type\" \\  -H \"Ce-Source: some.origin/intance\" \\  -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\  -d '{\"message\":\"Hello from TriggerMesh using GoogleSheet!\"}'</code></p> <p>See the Kubernetes object reference for more details.</p>","location":"targets/logz/"},{"title":"Prerequisite(s)","text":"<ul> <li>Logz.io account</li> <li>Logz.io shipping token</li> </ul>","location":"targets/logz/#prerequisites"},{"title":"Logz.io Metrics target","text":"<p>Sends events to Logz.io metrics.</p> <p>With <code>tmctl</code>:</p>  <p>Work in progress</p> <p>This component is not yet available with <code>tmctl</code>.</p>  <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: logzmetrics\ntype: Opaque\nstringData:\n  token: my_token  # Update this value with a valid shipping token\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: LogzMetricsTarget\nmetadata:\n  name: logzmetrics\nspec:\n  connection:\n    listenerURL: http://listener.logz.io:8052\n    token:\n      secretKeyRef:\n        name: logzmetrics\n        key: token\n  instruments:\n  - name: total_requests\n    instrument: Counter\n    number: Int64\n    description: total requests\n  - name: quacking_ducks\n    instrument: UpDownCounter\n    number: Int64\n    description: number of quacking ducks observed\n  - name: request_duration_ms\n    instrument: Histogram\n    number: Float64\n    description: request duration in milliseconds\n</code></pre> <p>Accepts events with the following attributes:</p> <ul> <li>type <code>io.triggermesh.opentelemetry.metrics.push</code></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/logzmetrics/"},{"title":"Oracle Cloud target","text":"<p>Sends events to Oracle Cloud Functions.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target oracle --function &lt;functionOCID&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: oraclecreds\ntype: Opaque\nstringData:\n  apiPassphrase: \"\"\n  apiKeyFingerprint: \"94:d4:c0:2f:6a:18:85:1a:31:a1:85:69:d5:47:fc:5d\"\n  apiKey: |-\n    -----BEGIN RSA PRIVATE KEY-----\n    MIIEogIBAAKCAQEAwRapSZ6+4wS18BkCu70Ic0IMeFksVsIJKZ+8xIZfMeGpW2zn\n    [...]\n    -----END RSA PRIVATE KEY-----\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: OracleTarget\nmetadata:\n  name: triggermesh-oracle-function\nspec:\n  oracleApiPrivateKey:\n    secretKeyRef:\n      name: oraclecreds\n      key: apiKey\n  oracleApiPrivateKeyPassphrase:\n    secretKeyRef:\n      name: oraclecreds\n      key: apiPassphrase\n  oracleApiPrivateKeyFingerprint:\n    secretKeyRef:\n      name: oraclecreds\n      key: apiKeyFingerprint\n  oracleTenancy: ocid1.tenancy.oc1..aaaaaaaaav23f45mqyxmwu4x3s2uhuh4rb2bwdpgb5kbpjqvwiiqufhsq6za\n  oracleUser: ocid1.user.oc1..aaaaaaaacaxtveoy4zx7rsg7lanexmouxjxay6godthrfsocpl6ggrfpbiuq\n  oracleRegion: us-phoenix-1\n  function:\n    function: ocid1.fnfunc.oc1.phx.aaaaaaaaaajrgy4on66e6krko73h2im5qaiiagecg5hmbcqib2kpbzlcy3bq\n</code></pre> <ul> <li>Oracle Secrets: Contains the Oracle API signing key.</li> <li>Oracle Tenancy: The OCID of tenant that holds the service being invoked.</li> <li>Oracle Username: The OCID of the user that owns the API key discussed in the prerequisites, and will be invoking the service.</li> <li>Oracle Region: The Oracle Cloud region hosting the service.</li> <li>Function: The OCID of the Oracle Cloud function being invoked.</li> </ul> <p>The Oracle Cloud Functions event Target is designed to allow for free-form JSON objects to be passed directly to the function and rely on the Oracle Cloud function to perform whatever action is desired.</p> <p>The function itself can return a freeform JSON object that can be processed by another event trigger.  The CloudEvent type will always be <code>functions.oracletargets.targets.triggermesh.io</code> with the function OCID defined as a part of the CloudEvent source and a metadata ID used to uniquify the specific event that called the function.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -vvv http://oracletarget \\\n  -X POST \\\n  -H 'Content-Type: application/json' \\\n  -H 'Ce-Specversion: 1.0' \\\n  -H 'Ce-Id: foo-1' \\\n  -H 'Ce-Type: testfunc.functions.oracle.triggermesh.io' \\\n  -H 'Ce-Source: h2g2.guide' \\\n  -d '{\"message\": \"A new user wants to say something: hello from triggermesh\"}'\n\n[...]\n&lt; HTTP/2 200\n&lt; ce-id: 9ab5e1f0-9713-405e-816c-1ba2739a7358\n&lt; ce-source: ocid1.fnapp.oc1.phx.aaaaaaaaaehdhsmharxvyp4pvnsgsnd35am5u7ckjzivwmsmove37eckjika\n&lt; ce-specversion: 1.0\n&lt; ce-subject: ocid1.fnfunc.oc1.phx.aaaaaaaaaajrgy4on66e6krko73h2im5qaiiagecg5hmbcqib2kpbzlcy3bq\n&lt; ce-time: 2020-08-03T19:04:55.381594978Z\n&lt; ce-type: functions.oracletargets.targets.triggermesh.io\n&lt; content-length: 86\n&lt; content-type: application/json\n&lt; date: Mon, 03 Aug 2020 19:04:55 GMT\n&lt; x-envoy-upstream-service-time: 1497\n&lt; server: istio-envoy\n&lt;\n* Connection #0 to host oracletarget left intact\n{\"processed\":{\"message\": \"A new user wants to say something: hello from triggermesh\"}}\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/oracle/"},{"title":"Prerequisites (Global)","text":"<p>Regardless of what event targets exist currently or in the future, the following is required:   - Tenancy OCID where the target components reside   - User OCID with access to the target components   - User API access tokens:     - API Private Key     - Private Key's passphrase     - Fingerprint of API key   - Oracle Cloud Region where the component resides</p> <p>Setting up an account on the Oracle Cloud and obtaining the prerequisite data is outside the scope of this readme, but obtaining most of the prerequisite data can be found in the Oracle Developer Resources</p>","location":"targets/oracle/#prerequisites-global"},{"title":"Salesforce target","text":"<p>Sends events to Salesforce.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target salesforce --auth.clientID &lt;clientID&gt; --auth.server &lt;server&gt; --auth.user &lt;user&gt; --auth.certKey &lt;certkey&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: salesforce\ntype: Opaque\nstringData:\n  certKey: |-\n    -----BEGIN PRIVATE KEY-----\n    ...certificate...contents...\n    -----END PRIVATE KEY-----\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SalesforceTarget\nmetadata:\n  name: salesforce\nspec:\n  auth:\n    clientID: my.salesforce.client.id\n    server: https://login.salesforce.com\n    user: woodford@triggermesh.com\n    certKey:\n      secretKeyRef:\n        name: salesforce\n        key: certKey\n  apiVersion: v50.0\n  eventOptions:\n    payloadPolicy: always\n</code></pre> <ul> <li>Client ID: The client ID as retrieved from the Salesforce connected app.</li> <li>Server: The server used for Salesforce authentication.</li> <li>User: User for the Salesforce account.</li> <li>Reply Events Policy: Indicates when event responses should be sent back from this target.</li> <li>spec.auth fields are required.</li> <li>Event options include the <code>payloadPolicy</code> which specifies if responses should be sent. Possible values are <code>always</code>, <code>error</code> and <code>never</code>. Default value is <code>always</code>.</li> </ul> <p>The Salesforce target accepts the event type <code>io.triggermesh.salesforce.apicall</code> and returns <code>io.triggermesh.salesforce.apicall.response</code></p> <p>The payload contains a JSON structure with elements to execute the API request:</p> <ul> <li><code>action</code>: is the HTTP verb to use.</li> <li><code>resource</code>: is the object family to use.</li> <li><code>object</code>: is the object type to operate on.</li> <li><code>record</code>: is the object instance.</li> <li><code>query</code>: parametrized key/values for the API request.</li> <li><code>payload</code>: body contents for the request.</li> </ul> <p>All those parameters but payload are put together sequentially to build the request:</p> <pre><code>https://&lt;salesforce-host&gt;/services/data/&lt;version&gt;/&lt;resource&gt;/&lt;object&gt;/&lt;record&gt;?query\n</code></pre> <p>Please, refer to the Salesforce API on how to fill in values to execute requests.</p> <p>When a request is sent using this Target, a response might be produced containing the reply from Salesforce or an error. Depending on if there are other Targets listening to these new events you might want to configure the reply behavior from this component. There are three possible values for the reply events policy:</p> <ul> <li><code>Never</code>: No response will be produced.</li> <li><code>Error</code>: Only errors will be returned from the Target.</li> <li><code>Always</code>: External responses or errors will be produced.</li> </ul> <p>When a response is produced from a Target, the extended attribute <code>category</code> is added which will contain one of two values:</p> <ul> <li><code>Success</code>: For when the request succeeds.</li> <li><code>Error</code>: For when an error occurs.</li> </ul> <p>Returned errors structure is defined in this schema.</p> <p>You can test the Target by sending it an event using <code>curl</code>.</p> <p>The Salesforce target will create an account when receiving this event.</p> <pre><code>curl -v -X POST http://localhost:8080  \\\n    -H \"content-type: application/json\"  \\\n    -H \"ce-specversion: 1.0\"  \\\n    -H \"ce-source: curl-pablo\"  \\\n    -H \"ce-type: io.triggermesh.salesforce.apicall\"  \\\n    -H \"ce-id: 123-abc\" \\\n    -H \"ce-statefulid: my-stateful-12345\" \\\n    -H \"ce-somethingelse: hello-world\" \\\n    -H \"statefulid: hello-world\" \\\n    -d '{\n          \"action\": \"POST\",\n          \"resource\": \"sobjects\",\n          \"object\": \"account\",\n          \"payload\": {\"Name\": \"test\"}\n        }'\n</code></pre> <p>An account can be deleted.</p> <pre><code>curl -v -X POST http://localhost:8080  \\\n  -H \"content-type: application/json\"  \\\n  -H \"ce-specversion: 1.0\"  \\\n  -H \"ce-source: curl-pablo\"  \\\n  -H \"ce-type: my-curl-type\"  \\\n  -H \"ce-id: 123-abc\" \\\n  -H \"ce-statefulid: my-stateful-12345\" \\\n  -H \"ce-somethingelse: hello-world\" \\\n  -H \"statefulid: hello-world\" \\\n  -d '{\n        \"action\": \"DELETE\",\n        \"resource\": \"sobjects\",\n        \"object\": \"account\",\n        \"record\": \"0014x000005Y9SNAA0\"\n      }'\n</code></pre> <p>Specific fields of an account can be retrieved by using the query parameter.</p> <pre><code>curl -v -X POST http://localhost:8080  \\\n  -H \"content-type: application/json\"  \\\n  -H \"ce-specversion: 1.0\"  \\\n  -H \"ce-source: curl-pablo\"  \\\n  -H \"ce-type: my-curl-type\"  \\\n  -H \"ce-id: 123-abc\" \\\n  -H \"ce-statefulid: my-stateful-12345\" \\\n  -H \"ce-somethingelse: hello-world\" \\\n  -H \"statefulid: hello-world\" \\\n  -d '{\n        \"action\": \"GET\",\n        \"resource\": \"sobjects\",\n        \"object\": \"account\",\n        \"record\": \"0014x000005VB1lAAG\",\n        \"query\": {\"fields\": \"AccountNumber,BillingPostalCode\"}\n      }'\n</code></pre> <p>Salesforce uses <code>PATCH</code> to update records</p> <pre><code>curl -v -X POST http://localhost:8080  \\\n  -H \"content-type: application/json\"  \\\n  -H \"ce-specversion: 1.0\"  \\\n  -H \"ce-source: curl-pablo\"  \\\n  -H \"ce-type: my-curl-type\"  \\\n  -H \"ce-id: 123-abc\" \\\n  -H \"ce-statefulid: my-stateful-12345\" \\\n  -H \"ce-somethingelse: hello-world\" \\\n  -H \"statefulid: hello-world\" \\\n  -d '{\n        \"action\": \"PATCH\",\n        \"resource\": \"sobjects\",\n        \"object\": \"account\",\n        \"record\": \"0014x000005Y9SNAA0\",\n        \"payload\": {\"Name\": \"test2\", \"BillingCity\" : \"San Francisco\"}\n      }'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/salesforce/"},{"title":"Prerequisite(s)","text":"<ul> <li>Salesforce account</li> <li>Certificate key secret</li> </ul>","location":"targets/salesforce/#prerequisites"},{"title":"Salesforce Account","text":"<p>Salesforce Target uses OAuth JWT credentials for service authentication.</p> <p>First, you will need to generate an X509 certificate for signing and verifying requests. We will be using <code>OpenSSL</code>, but any other certificate generation tool will work.</p> <pre><code>openssl req -x509 -sha256 -nodes -days 36500 -newkey rsa:2048 -keyout tm-sf.key -out tm-sf.crt\n</code></pre> <ol> <li> <p>On the Salesforce site select Setup &gt; Apps &gt; App Manager, click on New Connected App.</p> <ul> <li>Fill in mandatory fields, then click Enable OAuth Settings.</li> <li>A callback URL is mandatory but can be filled with any HTTPS data.</li> <li>Enable <code>Use digital signatures</code> and upload the public cert (<code>tm-sf.crt</code> in the example above).</li> <li>Add Scopes for <code>api</code>, <code>refresh_token</code>, and <code>offline_access</code>.</li> <li>Click <code>Save</code>.</li> </ul> <p></p> <ul> <li>Select the connected app you just created from the list and then click <code>Manage</code>.</li> <li>Click <code>Edit policies</code>.</li> <li>Set <code>Permitted users</code> to <code>Admin approved users are pre-authorized</code>.</li> <li>Click <code>Save</code>.</li> </ul> <p></p> <ul> <li>Select the connected app from the list and then click <code>Manage</code>.</li> <li>Click <code>Manage Profiles</code>.</li> <li>Add permissions on the data this user will have access to.</li> <li>Click <code>Save</code>.</li> </ul> </li> <li> <p>Retrieve OAuth data to configure TriggerMesh Target.</p> <ul> <li>Select the connected app from the list and then click <code>View</code>.</li> <li>Copy the <code>Consumer Key</code>.</li> <li>Reveal and copy the <code>Consumer Secret</code>.</li> </ul> </li> </ol>","location":"targets/salesforce/#salesforce-account"},{"title":"Certificate Key Secret","text":"<p>The TriggerMesh Salesforce integration needs a certificate key secret to sign requests for the Salesforce API.</p>","location":"targets/salesforce/#certificate-key-secret"},{"title":"SendGrid target","text":"<p>Sends events to SendGrid.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target sendgrid --apiKey &lt;apiKey&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: sendgrid\ntype: Opaque\nstringData:\n  apiKey: ''  # Update this value with a valid Sendgrid API key\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SendGridTarget\nmetadata:\n  name: triggermesh-email\nspec:\n  defaultFromName: Knative\n  defaultToName: bar\n  defaultToEmail: bob@gmail.com\n  defaultFromEmail: bar@gmail.com\n  defaultSubject: Hello World\n  apiKey:\n    secretKeyRef:\n      name: sendgrid\n      key: apiKey\n</code></pre> <ul> <li>Default sender name: Define a default 'name' to be assigned in the <code>From:</code> section of the email to be created, if the received event does not contain a <code>FromName</code> property.</li> <li>Default sender email: Define a default email address to be assigned in the <code>From:</code> section of the email to be created, if the received event does not contain a <code>FromEmail</code> property.</li> <li>Default recipient name: Define a default name to be assigned in the <code>To:</code> section of the email to be created, if the received event does not contain a <code>FromEmail</code> property.</li> <li>Default recipient email: Define a default 'email address' to be assigned in the <code>To:</code> section of the email to be created, if the received event does not contain a <code>ToEmail</code> property.</li> <li>Default subject: Define a default subject to be assigned to the outgoing email to be created, if the received event does not contain a <code>subject</code> property.</li> <li>API Secret: Contains an API token for authenticating requests.</li> </ul> <p>Note: If there is not a default value specified for all of the optional fields, the event received by that deployment MUST contain all of the information noted in the Event Types, except for <code>Message</code>, or the Target will fail.</p> <p>Depending on how the Sendgrid Target is to be used, defaults can be configured for all available parameters and the Target can accept arbitrary events. Or none of the defaults can be set and these parameters can be passed in at runtime via the event payload.</p> <p>The SendGrid event Target accepts a JSON payload with the following properties that will overwrite their respective <code>spec</code> parameters.</p>    Name Type Comment Required     FromName string Sender's name false   FromEmail string Sender's email false   ToName string Recipient's name false   ToEmail string Recipient's email false   Message string Contents of the message body false   Subject string Assigns a subject to the email false    <p>When a Message property is not present, the entire cloud event is passed into the email <code>body</code> by default.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v \"localhost:8080\" \\\n       -X POST \\\n       -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n       -H \"Ce-Specversion: 1.0\" \\\n       -H \"Ce-Type: io.triggermesh.sendgrid.email.send\" \\\n       -H \"Ce-Source: dev.knative.samples/helloworldsource\" \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"fromEmail\":\"richard@triggermesh.com\",\"toEmail\":\"bob@gmail.com\",\"fromName\":\"richard\",\"toName\":\"bob\",\"message\":\"hello\",\"subject\":\"Hello World\"}'\n</code></pre> <p>An example email sent from the Sendgrid Target with the Message parameter omitted from the curl example above will look as follows:</p> <pre><code>from: richard &lt;richard@triggermesh.com&gt;\nto: bob &lt;bob@gmail.com&gt;\ndate:   Sep 12, 2020, 12:41 AM\nsubject: Hello World\n\nValidation: valid Context Attributes, specversion: 1.0 type: dev.knative.samples.helloworld source: dev.knative.samples/helloworldsource id: 536808d3-88be-4077-9d7a-a3f162705f79 time: 2020-09-12T04:41:00.000610299Z datacontenttype: application/json Extensions, knativearrivaltime: 2020-09-12T04:41:00.006331845Z knativehistory: default-kne-trigger-kn-channel.midimansland.svc.cluster.local Data, { \"FromEmail\":\"richard@triggermesh.com\",\"ToEmail\":\"bob@gmail.com\", \\\n         \"FromName\":\"richard\",\"ToName\":\"bob\",\"Subject\":\"Hello World\" }\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/sendgrid/"},{"title":"Prerequisite(s)","text":"<ul> <li>SendGrid account</li> <li>SendGrid API token</li> </ul> <p>For more information about using SendGrid, please refer to the SendGrid documentation.</p>","location":"targets/sendgrid/#prerequisites"},{"title":"Slack target","text":"<p>Sends events to the Slack through the Slack Web API.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target slack --token &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret (using the Slack API token)</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: slack-tm\ntype: Opaque\nstringData:\n  token: xoxb-12345-abcde\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SlackTarget\nmetadata:\n  name: slack-tm\nspec:\n  token:\n    secretKeyRef:\n      name: slack-tm\n      key: token\n</code></pre> <p>Slack target accepts events of the following types:</p> <ul> <li><code>com.slack.webapi.chat.postMessage</code></li> <li><code>com.slack.webapi.chat.scheduleMessage</code></li> <li><code>com.slack.webapi.chat.update</code></li> </ul> <p>These types expect a [JSON][ce-jsonformat] payload with the following properties:</p> <ul> <li>chat.postMessage</li> <li>chat.scheduleMessage</li> <li>chat.update</li> </ul> <p>You can test the Target by sending it an event using <code>curl</code>.</p> <p>Send Message</p> <ul> <li>Slack docs https://api.slack.com/methods/chat.postMessage</li> <li>Needs chat:write</li> </ul> <pre><code>curl -v http://localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: com.slack.webapi.chat.postMessage\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"channel\":\"C01112A09FT\", \"text\": \"Hello from TriggerMesh!\"}'\n</code></pre> <p>Send Scheduled Message</p> <ul> <li>Slack docs https://api.slack.com/methods/chat.scheduleMessage</li> <li>Use with a scheduled future epoch.</li> <li>Needs chat:write</li> </ul> <pre><code>curl -v http://localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: com.slack.webapi.chat.scheduleMessage\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"channel\":\"C01112A09FT\", \"text\": \"Hello from scheduled TriggerMesh!\", \"post_at\": 1593430770}'\n</code></pre> <p>Update Message</p> <ul> <li>Slack docs https://api.slack.com/methods/chat.update</li> <li>Use with an existing message timestamp.</li> <li>Needs chat:write</li> </ul> <pre><code>curl -v http://localhost:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: com.slack.webapi.chat.update\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"channel\":\"C01112A09FT\", \"text\": \"Hello from updated2 TriggerMesh!\", \"ts\":\"1593430770.001300\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/slack/"},{"title":"Prerequisite(s)","text":"<ul> <li>Slack user that can manage applications</li> <li>Pre-existing Slack App</li> <li>Slack API token</li> </ul>","location":"targets/slack/#prerequisites"},{"title":"Configuring Your Slack App","text":"<ol> <li>Create a new Slack App.</li> <li>Go to Basic Information &gt; Add features and functionality and select the <code>Permissions</code> pane.</li> <li>Under Bot Token Scopes add <code>chat:write</code>.</li> <li>From the Install App menu follow steps to deploy to your workspace.</li> <li>Copy the Bot OAuth Access token, it should begin with <code>xoxb-...</code></li> </ol> <p>The application created in Slack for this integration will need to be added to the scopes that satisfy the web API methods used (<code>chat:write</code> shown here). See Sending Slack Operations to determine which scopes will be required per operation.</p>","location":"targets/slack/#configuring-your-slack-app"},{"title":"Slack API token","text":"<p>A Slack API token is required to use this target. From the Install App menu, retrieve the OAuth Access token that begins with <code>xoxb-</code>. For more information on how to obtain one, see the Slack Developer's Guide</p> <p>For more information about using the Slack API, please refer to the Slack API documentation.</p>","location":"targets/slack/#slack-api-token"},{"title":"Splunk target","text":"<p>Sends events to a Splunk HTTP Event Collector (HEC).</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target splunk --endpoint &lt;endpoint&gt; --token &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SplunkTarget\nmetadata:\n  name: sample\nspec:\n  endpoint: https://mysplunk.example.com:8088\n\n  token:\n    valueFromSecret:\n      name: splunk-hec\n      key: token\n</code></pre> <ul> <li>Endpoint: URL of the HTTP Event Collector (HEC). This URL varies depending on the type of Splunk installation   (Enterprise, self-service Cloud, managed Cloud). Only the scheme, hostname, and port (optionally) are evaluated, the   URL path is trimmed if present.</li> <li>Token: Contains a token for authenticating requests against   the HEC, as discussed in the prerequisites.</li> <li>Index: Name of the index to send events to. When undefined, events are sent to the default index defined   in the HEC token's configuration.</li> </ul> <p>Accepts events of any type. See the Kubernetes object reference for more details.</p>","location":"targets/splunk/"},{"title":"Prerequisite(s)","text":"<ul> <li>Enable HTTP Event Collector Input</li> <li>HEC token</li> </ul> <p>Open the Splunk web console, then navigate to Settings &gt; Data &gt; Data inputs.</p> <p></p> <p>In the list of local inputs, click HTTP Event Collector.</p> <p></p> <p>Click New token in order to generate a new token with custom settings, then take note of the value of that token. The default HEC token (<code>splunk_hec_token</code>) is also suitable for use with the TriggerMesh event Target for Splunk.</p> <p></p> <p>This procedure is described in more detail in the Splunk documentation: Set up and use HTTP Event Collector in Splunk Web.</p> <p>To check if you Splunk Target is working, new events should be visible in the Search &amp; Reporting app inside Splunk.</p> <p> </p> <p>For more information about using Splunk, please refer to the Splunk documentation.</p>","location":"targets/splunk/#prerequisites"},{"title":"Tekton target","text":"<p>Sends events to Tekton to create Tekton <code>TaskRun</code> or <code>PipelineRun</code> objects.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target tekton\n</code></pre> <p>On Kubernetes:</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: TektonTarget\nmetadata:\n  name: triggermesh-tekton-target\nspec:\n  reapPolicy:\n    success: 5m  # clean up all successfully completed task runs\n    fail: 1h  # clean up all failed task runs\n</code></pre> <p>Tekton Target accepts events of type <code>io.triggermesh.targets.tekton</code>, which create a new Tekton <code>PipelineRun</code> or <code>TaskRun</code> object.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     buildType string The run object type consisting of <code>task</code> or <code>pipeline</code>   name string The Tekton <code>task</code> or <code>pipeline</code> object to invoke   params map[string]string Dictionary mapping of parameters to pass to the Tekton task or pipeline    <p>No response events are created with this Target type.</p>  <p>NOTE: On Kubernetes, neither of <code>TaskRun</code> and <code>PipelineRun</code> objects nor their associated pods are deleted after execution. It is up to the user to perform the clean-up.</p>  <p>Reaping prior Tekton TaskRuns and PipelineRuns</p> <p>To allow for reaping of old run objects, the <code>TektonTarget</code> Spec supports defining a duration interval (in the form of <code>\\d+[mhd]</code> for minute, hour, or day) for how long to keep the run objects before purging.</p> <ul> <li><code>reapPolicy.success</code> Age of run objects to keep that succeeded</li> <li><code>reapPolicy.fail</code> Age of the run objects to keep that failed</li> </ul> <p>To trigger the reaping, a CloudEvent type of <code>io.triggermesh.tekton.reap</code> must be sent to the target.</p> <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://tektontarget-helloworld5d0adf0209a48c23fa958aa1b8ecf0b.default.svc.cluster.local \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: io.triggermesh.tekton.run\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"buildtype\": \"task\",\"name\": \"tekton-test\",\"params\":{\"greeting\":\"Hi from TriggerMesh\"}}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/tekton/"},{"title":"Prerequisite(s)","text":"<ul> <li>Tekton Task or Pipeline</li> </ul> <p>Refer to the Tekton documentation for information about how to create tasks and pipelines.</p>","location":"targets/tekton/#prerequisites"},{"title":"Twilio target","text":"<p>Sends events to Twilio.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target twilio --sid &lt;sid&gt; --token &lt;token&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: twilio\ntype: Opaque\nstringData:\n  sid: \"&lt;TWILIO-ACCOUNT-SID&gt;\"\n  token: \"&lt;TWILIO-ACCOUNT-TOKEN&gt;\"\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: TwilioTarget\nmetadata:\n  name: &lt;TARGET-NAME&gt;\nspec:\n  defaultPhoneFrom: \"&lt;PHONE-FROM&gt;\"\n  defaultPhoneTo: \"&lt;PHONE-TO&gt;\"\n  sid:\n    secretKeyRef:\n      name: \"&lt;YOUR-SID-SECRET&gt;\"\n      key: \"&lt;YOUR-SID-SECRET-KEY&gt;\"\n  token:\n    secretKeyRef:\n      name: \"&lt;YOUR-TOKEN-SECRET&gt;\"\n      key: \"&lt;YOUR-TOKEN-SECRET-KEY&gt;\"\n</code></pre> <ul> <li>Default source phone number (Optional): Sender's phone number, usually configured to the phone number purchased at   Twilio.</li> <li>Default destination (Optional): Phone number to send messages to by default.</li> <li>SID Secret: Contains the SID of the Twilio account.</li> <li>Token Secret: Contains an API Access token for   authenticating requests against the Twilio API.</li> </ul> <p>Both the Default source phone number and Default destination configurations may be overridden by any the parameters in a CloudEvent sent to Target.</p> <p>Although <code>defaultPhoneFrom</code> is not mandatory it will usually be configured by matching the phone number purchased with Twilio.</p> <p><code>defaultPhoneTo</code> will normally not be informed unless the desire is to send all messages to the same phone number by default.</p> <p>Refer to Twilio docs for number formating.</p> <p>Twilio Target accepts events of type <code>io.triggermesh.twilio.sms.send</code>, and expects a JSON payload from the CloudEvent that includes:</p>    Name Type Description     message string Text to be sent in the body of the SMS message.   media_urls string Array of URLs pointing to JPEG, GIF or PNG resources.   from string Phone number sourcing the communication. Takes precedence over the value from the Twilio Target spec.   to string Phone number of the destination. Takes precedence over the value from the Twilio Target spec.    <p>You can test the Target by sending it an event using <code>curl</code>:</p> <pre><code>curl -v http://twiliotarget-int1-8dc3abc7d44bdd0130bd0a311bea272f.knative-samples.svc.cluster.local\n \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: io.triggermesh.twilio.sms.send\" \\\n -H \"Ce-Source: some.origin/intance\" \\\n -H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n -d '{\"message\":\"Hello from TriggerMesh using Twilio!\",\"to\": \"+1111111111\"}'\n</code></pre> <p>See the Kubernetes object reference for more details.</p>","location":"targets/twilio/"},{"title":"Prerequisite(s)","text":"<ul> <li>Twilio account with access to the Account SID &amp; API Access Token</li> <li>Phone number</li> </ul> <p>A Twilio account is required to run this target:</p> <ul> <li>Register a Twilio account</li> <li>Purchase a phone number with</li> <li>Retrieve from Twilio Dashbard Account SID</li> <li>Retrieve from Twilio Dashbard Auth Token</li> </ul> <p>For more information about using Twilio, please refer to the Twilio documentation.</p>","location":"targets/twilio/#prerequisites"},{"title":"Zendesk target","text":"<p>Sends events to Zendesk, to either create tickets or tag existing tickets.</p> <p>With <code>tmctl</code>:</p> <pre><code>tmctl create target zendesk --subdomain &lt;subdomain&gt; --email &lt;email&gt;\n</code></pre> <p>On Kubernetes:</p> <p>Secret</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: zendesk\ntype: Opaque\nstringData:\n   token: &lt;Zendesk token&gt;\n</code></pre> <p>Target</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: ZendeskTarget\nmetadata:\n  name: triggermesh-zendesk\nspec:\n  #subject provides a default Subject for new Zendesk tickets. Optional\n  subject: '' #Example: tmTickets0\n  subdomain: '' #Example: tmdev1\n  email: '' #Example: jeff@triggermesh.com\n  token:\n     secretKeyRef:\n       name: zendesktargetsecret\n       key: token\n</code></pre> <ul> <li>Default Ticket Subject: An optional ticket subject fallback if one is not provided in an incoming event.</li> <li>Zendesk Subdomain: Name of the Zendesk Subdomain, without the <code>zendesk.com</code> domain or <code>https://</code> scheme.</li> <li>Zendesk Email: Email address associated with the Zendesk account.</li> <li>Zendesk API Token: Contains a token to communicate with the Zendesk API, as discussed in the prerequisites.</li> </ul> <p>A Zendesk Target will ONLY accept CloudEvents with a \"Ce-Type\" of either <code>com.zendesk.ticket.create</code> OR <code>com.zendesk.tag.create</code></p> <ul> <li> <p>Event's of type <code>com.zendesk.ticket.create</code> Expect both a <code>subject</code> and <code>body</code> to be preset.</p> </li> <li> <p>Example of type : <code>com.zendesk.ticket.create</code> <pre><code>curl -v https://zendesktarget-triggermesh-zendesk.jnlasersolutions.dev.munu.io  \\\n-H \"Content-Type: application/json\" \\\n-H \"Ce-Specversion: 1.0\" \\\n-H \"Ce-Type: com.zendesk.ticket.create\" \\\n-H \"Ce-Source: some.origin/intance\" \\\n-H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n-d '{\"subject\": \"Hello\", \"body\" : \"World\"}'\n</code></pre></p> <p>An example response from the Zendesk Target after consuming an event of this type:</p> <pre><code>{\n \"id\":165,\n \"url\":\"https://triggermesh.zendesk.com/api/v2/tickets/165.json\",\n \"subject\":\"Hello\",\n \"raw_subject\":\"Hello\",\n \"description\":\"World\",\n \"status\":\"open\",\n \"requester_id\":412584624334,\n \"submitter_id\":412584624334,\n \"assignee_id\":412584624334,\n \"group_id\":360010761434,\n \"due_at\":\"0001-01-01T00:00:00Z\",\n \"via\":\n   {\n     \"channel\":\"api\",\n     \"source\":{\"from\":{},\"to\":{},\"rel\":\"\"},\n     \"satisfaction_rating\":{\"id\":0,\"score\":\"\",\"comment\":\"\"},\n     \"brand_id\":360004879834,\n     \"allow_attachments\":true,\n     \"is_public\":true,\n     \"created_at\":\"2020-08-05T20:00:11Z\",\n     \"updated_at\":\"2020-08-05T20:00:11Z\",\n     \"collaborators\":{},\n     \"comment\":{\"created_at\":\"0001-01-01T00:00:00Z\"}\n   }\n}\n</code></pre> </li> <li> <p>Event's of type <code>com.zendesk.tag.create</code> Expect both a <code>id</code> and <code>tag</code> to be preset.</p> </li> <li>Example of type : <code>com.zendesk.tag.create</code> <pre><code>curl -v https://zendesktarget-triggermesh-zendesk.jnlasersolutions.dev.munu.io  \\\n-H \"Content-Type: application/json\" \\\n-H \"Ce-Specversion: 1.0\" \\\n-H \"Ce-Type: com.zendesk.tag.create\" \\\n-H \"Ce-Source: some.origin/intance\" \\\n-H \"Ce-Id: 536808d3-88be-4077-9d7a-a3f162705f79\" \\\n-d '{\"id\":81 , \"tag\":\"triggermesh\"}'\n</code></pre></li> </ul> <p>See the Kubernetes object reference for more details.</p>","location":"targets/zendesk/"},{"title":"Prerequisite(s)","text":"<ul> <li>Zendesk API token</li> </ul> <p>You can find the steps to obtain an API token in the Zendesk API Docs.</p> <p>For more information about using Zendesk, please refer to the Zendesk documentation.</p>","location":"targets/zendesk/#prerequisites"},{"title":"Transforming events with TriggerMesh","text":"<p>TriggerMesh makes it easy to transform events as they pass from producers to consumers. This lets you adapt the event metadata or payload for different reasons, such as matching the schema expected by the consumer, or removing sensitive data from events.</p> <p>There are two main ways to transform events in TriggerMesh:</p> <ul> <li>JSON Transformation provides a high-level language called Bumbleebee (like the Transformer) that makes it easy to transform an event without writing code</li> <li>Functions let you transform events in code written in Python, Node, or Ruby, thereby providing extra flexibility</li> </ul> <p>TriggerMesh also includes a number of other transformation options:</p> <ul> <li>JQ transformation</li> <li>XSLT transformation</li> <li>XML to JSON transformation</li> <li>Mulesoft DataWeave transformation</li> </ul>","location":"transformation/"},{"title":"JSON transformation with Bumblebee","text":"","location":"transformation/jsontransformation/"},{"title":"Introduction to the Bumblebee transformation language","text":"<p>A Bumblebee transformation consists of two main parts: \"context\" and \"data\" for corresponding CloudEvents components.</p> <p>Bumblebee supports <code>Delete</code>, <code>Add</code>, <code>Shift</code>, and <code>Store</code> operations.</p> <p>Transformation operations are applied on the event in the order they are listed in the spec with the  exception of <code>Store</code> which runs before the rest to be able to collect variables for the runtime.</p>","location":"transformation/jsontransformation/#introduction-to-the-bumblebee-transformation-language"},{"title":"Delete","text":"<p>Delete CE keys or objects.</p> <p>Delete a key</p> <p>Delete a key.</p> <pre><code>spec:\n  data:\n  - operation: delete\n    paths:\n    - key: foo\n    - key: array[1].foo\n    - key: foo.array[5]\n</code></pre> <p>Delete a key if</p> <p>Delete a \"foo\" key only if its value is equal to \"bar\".</p> <pre><code>spec:\n  data:\n  - operation: delete\n    paths:\n    - key: foo\n      value: bar\n</code></pre> <p>Delete recursively</p> <p>Recursively remove all keys with specified value.</p> <pre><code>spec:\n  data:\n  - operation: delete\n    paths:\n    - value: leaked password\n</code></pre> <p>Delete everything</p> <p>Delete everything. Useful for composing completely new CE using stored variables.</p> <pre><code>spec:\n  data:\n  - operation: delete\n    paths:\n    - key:\n</code></pre>","location":"transformation/jsontransformation/#delete"},{"title":"Add","text":"<p>Add new or override existing CE keys.</p> <p>Override the event type</p> <p>Override Cloud Event type. This operation can be used to implement complex Transformation logic with multiple Triggers and CE type filtering.</p> <pre><code>spec:\n  context:\n  - operation: add\n    paths:\n    - key: type\n      value: ce.after.transformation\n</code></pre> <p>Add a new object</p> <p>Add a new object with nested structure.</p> <pre><code>spec:\n  data:\n  - operation: add\n    paths:\n    - key: The.Ultimate.Questions.Answer\n      value: \"42\"\n</code></pre> <p>Add or modify arrays</p> <p>Add arrays or modify existing ones. \"True\" will be added as a second item of a new array \"array\" in a new object \"newObject\". \"1337\" will be added as a new key \"newKey\" as a first item of an existing array \"commits\".</p> <pre><code>spec:\n  data:\n  - operation: add\n    paths:\n    - key: newObject.array[2]\n      value: \"true\"\n    - key: commits[1].newKey\n      value: \"1337\"\n</code></pre> <p>Add using variables</p> <p>\"Add\" operation supports value composing from variables and static strings.</p> <pre><code>spec:\n  data:\n  - operation: add\n    paths:\n    - key: id\n      value: ce-$source-$id\n</code></pre>","location":"transformation/jsontransformation/#add"},{"title":"Shift","text":"<p>Move existing CE values to new keys.</p> <p>Shift one key's value to another</p> <p>Move value from \"foo\" key to \"bar\"</p> <pre><code>spec:\n  data:\n  - operation: shift\n    paths:\n    - key: foo:bar\n</code></pre> <p>Shift if</p> <p>Move key only if its value is equal to \"bar\".</p> <pre><code>spec:\n  data:\n  - operation: shift\n    paths:\n    - key: old:new\n      value: bar\n</code></pre> <p>Shift nested objects and arrays</p> <p>Shift supports nested objects and arrays:</p> <pre><code>spec:\n  data:\n  - operation: shift\n    paths:\n    - key: array[0].id:newArray[1].newId\n    - key: object.list[0]:newItem\n</code></pre>","location":"transformation/jsontransformation/#shift"},{"title":"Store","text":"<p>Store CE value as a pipeline variable. Useful in combination with the other operations. The variables are shared between the \"context\" and the \"data\" parts of the transformation pipeline.</p> <p>Store and use event type and source</p> <p>Store CE type and source and add them into headers array in a payload. Also set a new CE type and save the original one in context extensions.</p> <pre><code>spec:\n  context:\n  - operation: store\n    paths:\n    - key: $ceType\n      value: type\n    - key: $ceSource\n      value: source\n  - operation: add\n    paths:\n    - key: type\n      value: ce.after.transformation\n    - key: extensions.OriginalType\n      value: $ceType\n  data:\n  - operation: add\n    paths:\n    - key: headers[0].source\n      value: $ceSource\n    - key: headers[1].type\n      value: $ceType\n</code></pre>","location":"transformation/jsontransformation/#store"},{"title":"CloudEvents extensions","text":"<p>CloudEvent's context extensions can be accessed by using the <code>extensions.*</code> key prefix, for example below we show how to add a new CloudEvents extension attribute to the event:</p> <pre><code>context:\n  - operation: add\n    paths:\n    - key: extensions.profile\n      value: something\n</code></pre>","location":"transformation/jsontransformation/#cloudevents-extensions"},{"title":"Kubernetes tutorial","text":"<p>In this Kubernetes guide, we will create a simple Bridge with an event producer and a transformation to see the declarative syntax that is used for modifying events.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <pre><code>$ kubectl get crd transformations.flow.triggermesh.io\nNAME                                  CREATED AT\ntransformations.flow.triggermesh.io   2021-10-06T09:01:40Z\n</code></pre> <p>You can also explore the API specification with: <pre><code>$ kubectl explain transformation\n</code></pre></p>  <p></p> <p>Let's create all the required objects:</p> <ul> <li> The sockeye target which serves as an event display.</li> <li> The <code>PingSource</code> which serves as an event producer.</li> <li> The <code>Transformation</code> to modify the produced events.</li> </ul>","location":"transformation/jsontransformation/#kubernetes-tutorial"},{"title":"Event display","text":"<p>First of all, we need to have a tool to see the transformed events. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL that you find with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"transformation/jsontransformation/#event-display"},{"title":"Events producer","text":"<p>Next, we need to create a PingSource to produce CloudEvents by saving the following YAML manifests in a file and applying it to your Kubernetes cluster with <code>kubectl apply</code>:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-transformation-demo\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n    \"First Name\": \"Alice\",\n    \"Last Name\": \"Wonderland\",\n    \"Date of birth\": {\n      \"year\": 1955,\n      \"month\": 1,\n      \"day\" : 23\n    },\n    \"Married\": true,\n    \"Children\":\n    [\n        {\"Name\": \"Martin\", \"Year of birth\": 1980},\n        {\"Name\": \"Margaret\", \"Year of birth\": 1983}\n    ],\n    \"Mobile phone\": null\n  }'\n  sink:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: Transformation\n      name: trn-transformation-demo\n</code></pre>","location":"transformation/jsontransformation/#events-producer"},{"title":"Transformation","text":"<p>And finally the transformation object that will receive CloudEvents from the PingSource defined above, apply its operations and forward modified events to the <code>sockeye</code> service:</p> <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: Transformation\nmetadata:\n  name: trn-transformation-demo\nspec:\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n\n  context:\n  - operation: store\n    paths:\n    - key: $time\n      value: time\n    - key: $id\n      value: id\n  - operation: add\n    paths:\n    - key: id\n      value: $person-$id\n    - key: type\n      value: io.triggermesh.transformation.pingsource\n\n  data:\n  - operation: store\n    paths:\n    - key: $person\n      value: First Name\n  - operation: add\n    paths:\n    - key: event.ID\n      value: $id\n    - key: event.time\n      value: $time\n  - operation: shift\n    paths:\n    - key: Date of birth:birthday\n    - key: First Name:firstname\n    - key: Last Name:lastname\n  - operation: delete\n    paths:\n    - key: Mobile phone\n    - key: Children[1].Year of birth\n    - value: Martin\n</code></pre> <p>Once created with <code>kubectl apply</code> verify that the transformation is ready:</p> <pre><code>$ kubectl get transformation -w\nNAME                      ADDRESS                                                   READY   REASON\ntrn-transformation-demo   http://trn-transformation-demo.sebgoa.svc.cluster.local   True\n</code></pre> <p>If all the components of the Bridge are ready, the <code>sockeye</code> web interface will start showing modified events shortly:</p> <p></p> <p>You will notice that the CloudEvent attributes have beeen modified according to the <code>context</code> section in the specification of the <code>Transformation</code> object. The event type was modified and the <code>id</code> was prepended with the string <code>Alice</code>.</p> <p>The payload was also transformed according to the <code>data</code> section of the <code>Transformation</code> object. For example the mobile phone was deleted, a key <code>event</code> was added and a few keys were shifted: \"Date of Birth\" became \"birthday\".</p>  <p>Play with your Transformation as Code</p> <p>You can play around by modifying the <code>Transformation</code> object and re-applying it with <code>kubectl</code>. This gives you a declarative event transformer which you can manage with your GitOps workflow.</p>","location":"transformation/jsontransformation/#transformation"},{"title":"Function overview","text":"<p>TriggerMesh functions are used to perform transformations on events using code written in Python, NodeJS, or Ruby. These are not a replacement for full blown FaaS services, but provide a lot of flexibility when transforming events, particularly to those familiar with one of the support languages.</p> <p>For low-code style transformations in JSON, refer to JSON Transformation.</p>  <p>Info</p> <p>TriggerMesh functions with <code>tmctl</code> is a work in progress and not currently supported.</p> <p>Furthermore, note that TriggerMesh Functions are opinionated and simple. They are aimed to be used for event transformation and do not support external dependencies. Functions that may need external dependencies are best served with something like AWS Lambda or Knative Functions.</p>","location":"transformation/functions/"},{"title":"NodeJS functions","text":"","location":"transformation/functions/nodejsfunctions/"},{"title":"NodeJS empty field transformation example on Kubernetes","text":"<pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: inline-node-function\nspec:\n  runtime: node\n  ceOverrides:\n    extensions:\n      type: io.triggermesh.nodejs.sample\n  entrypoint: transformName\n  code: |\n    module.exports.transformName = async (event) =&gt; {\n      if (event.name == \"\") {\n        event.name = \"placeholder\";\n      }\n      return event;\n    };\n</code></pre>","location":"transformation/functions/nodejsfunctions/#nodejs-empty-field-transformation-example-on-kubernetes"},{"title":"Python functions","text":"","location":"transformation/functions/pythonfunctions/"},{"title":"Python function example on K8s","text":"<p>As an example, let's write a Python function which reads a name from an incoming payload and returns a \"Hello\" message.</p> <p>Writing a function requires two steps:</p> <ul> <li> Writing a function manifest</li> <li> Applying the manifest to your Kubernetes cluster</li> </ul> <p>The Function object spec requires a minimal amount of configuration:</p> <ul> <li>The <code>runtime</code>, here we choose <code>python</code></li> <li>Whether the function is publicly accessible or not using the <code>public</code> keyword.</li> <li>The <code>entrypoint</code>, which specifies the name of the function</li> <li>The <code>code</code>, written in-line with the function manifest</li> </ul> <p>Save the YAML manifest below in a file called <code>function.yaml</code></p> <pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: python-function-hello\nspec:\n  runtime: python\n  public: true\n  entrypoint: endpoint\n  code: |\n    def endpoint(event, context):\n      return \"Hello \" + event['name']\n</code></pre> <p>You can then create the function with:</p> <pre><code>kubectl apply -f function.yaml\n</code></pre> <p>You can find the public endpoint of your function and test it:</p> <pre><code>$ kubectl get function\nNAME                    ADDRESS                                                          READY   REASON\npython-function-hello   https://python-function-hello-mvf2bk.sebgoa.dev.triggermesh.io   True\n\n$ curl -ks -d '{\"name\":\"seb\"}' https://python-function-hello-mvf2bk.sebgoa.dev.triggermesh.io |jq\n{\n  \"id\": \"62402f5a-0a82-48e8-8e67-db68d57efdf9\",\n  \"type\": \"io.triggermesh.function.python\",\n  \"source\": \"source.py\",\n  \"specversion\": \"1.0\",\n  \"time\": \"2021-10-11T16:26:49Z\",\n  \"datacontenttype\": \"text/plain\",\n  \"data\": \"Hello seb\"\n}\n</code></pre>  <p>Note</p> <p>The returned event adheres to the CloudEvent specification.</p>","location":"transformation/functions/pythonfunctions/#python-function-example-on-k8s"},{"title":"Python random even/odd events example","text":"<pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: inline-python-function\nspec:\n  runtime: python\n  responseIsEvent: true\n  adapterOverrides:\n    public: true\n  ceOverrides:\n    extensions:\n      type: io.triggermesh.python.sample\n  entrypoint: endpoint\n  code: |\n    from random import randrange\n    def endpoint(event, context):\n      val = randrange(10)\n      if (val % 2) == 0:\n        result = {\n          \"type\" : \"io.triggermesh.klr.even\",\n          \"datacontenttype\" : \"application/json\",\n          \"data\" : {\n            \"value\" : val\n          }\n        }\n      else:\n        result = {\n          \"type\" : \"io.triggermesh.klr.odd\",\n          \"datacontenttype\" : \"application/json\",\n          \"data\" : {\n            \"value\" : val\n          }\n        }\n      return result\n</code></pre>","location":"transformation/functions/pythonfunctions/#python-random-evenodd-events-example"},{"title":"Ruby functions","text":"","location":"transformation/functions/rubyfunctions/"},{"title":"Ruby date and time event example on Kubernetes","text":"<pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: inline-ruby-function\nspec:\n  runtime: ruby\n  ceOverrides:\n    extensions:\n      type: io.triggermesh.ruby.sample\n  entrypoint: endpoint\n  code: |\n    def endpoint(event:, context:)\n    hash = {date: Time.new}\n    { statusCode: 200, body: JSON.generate(hash) }\n    end\n</code></pre>","location":"transformation/functions/rubyfunctions/#ruby-date-and-time-event-example-on-kubernetes"},{"title":"Transforming using DataWeave","text":"<p>The TriggerMesh <code>DataWeaveTransformation</code> API object can be used to process a Cloudevent containing JSON or XML and transform the document using DataWeave.</p> <p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML by parsing it with a DataWeave Spell. It has five steps:</p> <ul> <li>Deploy a Broker that will receive the transformed data.</li> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>DataWeaveTransformation</code> object.</li> <li>Configure the Triggers</li> <li>Deploy a curl pod that will allow us to send events to the broker.</li> </ul>","location":"transformation/other/dataweavetransformation/"},{"title":"How to use a DataWeaveTransformation","text":"<p>A <code>DataWeaveTransformation</code> object can be configured to either reply to the event sender or to send the transformed data to a <code>Sink</code>, if one is provided. In this guide, we will deploy without a <code>Sink</code> and configure the replies from the transformation to route to the <code>EventDisplay</code> service using a <code>Broker</code> and a <code>Trigger</code>.</p> <p>The <code>DataWeaveTransformation</code> can have a pre-defined parameters configured in the YAML but it also allows to send the parameters as part of the request. In this guide we will use both ways; we will configure the pre-defined parameters in the YAML but we will also use other parameters in the request, which is made possible by enabling the <code>allowPerEventDwSpell</code> parameter.</p>","location":"transformation/other/dataweavetransformation/#how-to-use-a-dataweavetransformation"},{"title":"DataWeaveTransformation parameters","text":"<ul> <li><code>allowPerEventDwSpell</code>: Allow to send the DataWeaveSpell as part of the request. (Optional)</li> <li><code>dwSpell</code>: DataWeave spell used to transform incoming CloudEvents. (Optional)</li> <li><code>inputContentType</code>: Content type for transformation ['application/json', 'application/xml']. (Optional)</li> <li><code>outputContentType</code>: Content type for transformation output. ['application/json', 'application/xml']. (Optional)</li> </ul> <p>Below is a sample DataWeave spell that will be used throughout the guide. <pre><code>%dw 2.0\noutput application/json\n---\n{\n    email: payload.order.buyer.email,\n    name: payload.order.buyer.name,\n}\n</code></pre></p> <p>It transforms the following XML: <pre><code>&lt;order&gt;\n    &lt;product&gt;\n        &lt;price&gt;5&lt;/price&gt;\n        &lt;model&gt;Company 2020&lt;/model&gt;\n    &lt;/product&gt;\n    &lt;item_amount&gt;3&lt;/item_amount&gt;\n    &lt;payment&gt;\n        &lt;payment-type&gt;credit-card&lt;/payment-type&gt;\n        &lt;currency&gt;USD&lt;/currency&gt;\n        &lt;installments&gt;1&lt;/installments&gt;\n    &lt;/payment&gt;\n    &lt;buyer&gt;\n        &lt;email&gt;james@hotmail.com&lt;/email&gt;\n        &lt;name&gt;James&lt;/name&gt;\n        &lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;\n        &lt;city&gt;Seattle&lt;/city&gt;\n        &lt;state&gt;CA&lt;/state&gt;\n        &lt;postCode&gt;98101&lt;/postCode&gt;\n        &lt;nationality&gt;USA&lt;/nationality&gt;\n    &lt;/buyer&gt;\n    &lt;shop&gt;main branch&lt;/shop&gt;\n    &lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;\n&lt;/order&gt;\n</code></pre></p> <p>Into this new JSON document: <pre><code>{\n  \"email\": \"james@hotmail.com\",\n  \"name\": \"James\"\n}\n</code></pre></p> <p>Let's go step by step to see how we can deploy this transformation as part of a TriggerMesh Bridge.</p> <p>Below is a diagram of the Bridge we will construct.</p> <p></p>","location":"transformation/other/dataweavetransformation/#dataweavetransformation-parameters"},{"title":"Deploy the Broker","text":"<p>Deploy a Broker by writing the following YAML in a file: <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\n</code></pre></p> <p>Create the Broker with the following command: <pre><code>kubectl apply -f &lt;manifest.yaml&gt;\n</code></pre></p>","location":"transformation/other/dataweavetransformation/#deploy-the-broker"},{"title":"Deploying the <code>EventDisplay</code> Service","text":"<p>Let's now deploy the Sink of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre>","location":"transformation/other/dataweavetransformation/#deploying-the-eventdisplay-service"},{"title":"Deploy the <code>DataWeaveTransformation</code> Object","text":"<p>With the <code>event-display</code> in place, the <code>DataWeaveTransformation</code> object can now be deployed in the same manner using the following manifest. It contains an inline DataWeave spell that will be used by default but can be overridden by passing a spell in the CloudEvent payload.</p> <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: DataWeaveTransformation\nmetadata:\n  name: demo\nspec:\n  allowPerEventDwSpell: true\n  dwSpell:\n    value: |-\n      %dw 2.0\n      output application/json\n      ---\n      {\n          email: payload.order.buyer.email,\n          name: payload.order.buyer.name,\n      }\n  inputContentType: application/xml\n  outputContentType: application/json\n</code></pre>","location":"transformation/other/dataweavetransformation/#deploy-the-dataweavetransformation-object"},{"title":"Configure the Triggers","text":"<p>Next, Triggers need to be configured to route our Cloudevents to the <code>DataWeaveTransformation</code> and <code>EventDisplay</code> objects. This can be done by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>. We have two triggers, one to send events containing XML to the transformation and one to send all events to the event display.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: event-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n---\nkind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: dataweavetransformation-xmldoc\nspec:\n  broker: demo\n  filter:\n    attributes:\n      # setting a filter to process only events of type `xml.document`\n      type: xml.document\n  subscriber:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: DataWeaveTransformation\n      name: demo\n</code></pre>","location":"transformation/other/dataweavetransformation/#configure-the-triggers"},{"title":"Deploy a Curl Pod","text":"<p>Finally, an event source can be deployed that will emit CloudEvents with XML data in the payload. We can do this in two steps:</p> <pre><code>1. Deploy a curl pod that will emit the CloudEvents by writing the following YAML in a file and apply it with `kubectl apply -f &lt;manifest.yaml&gt;`.\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: curl\n  name: curl\nspec:\n  containers:\n  - image: radial/busyboxplus:curl\n    imagePullPolicy: IfNotPresent\n    name: curl\n    stdin: true\n    tty: true\n</code></pre> <pre><code>2. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/xml\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '&lt;?xml version=\"1.0\"?&gt;\n&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;'\n</code></pre>","location":"transformation/other/dataweavetransformation/#deploy-a-curl-pod"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <p><pre><code>kubectl get pods                                                          \nNAME                                                   READY   STATUS    RESTARTS   AGE\ncurl                                                   1/1     Running   0          4m36s\nevent-display-00001-deployment-fb48c8d7c-g7bmv        2/2     Running   0          3s\ndataweavetransformation-demo-00001-deployment-7978655d45-jsfbr   2/2     Running   0          3s\n</code></pre> With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-fb48c8d7c-g7bmv user-container\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/xml\nExtensions,\n  knativearrivaltime: 2022-05-09T10:32:43.32759997Z\nData,\n  &lt;?xml version=\"1.0\"?&gt;\n&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: curl.shell\n  id: 1234-abcd\n  time: 2022-05-09T10:32:44.697405628Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:32:44.699348327Z\nData,\n  {\n    \"email\": \"james@hotmail.com\",\n    \"name\": \"James\"\n  }\n</code></pre> <p>We now see the incoming event and the transformed data, as expected.</p>","location":"transformation/other/dataweavetransformation/#viewing-the-transformations-output-in-the-event-display"},{"title":"Sending the parameters in the request.","text":"<p>Now we can try passing parameters such as the DataWeave spell and input and output content types as part of the Cloud Event.</p> <pre><code>1. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '{\n  \"input_data\": \"&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\",\n  \"spell\": \"{address1:payload.order.buyer.address,city:payload.order.buyer.city,country:payload.order.buyer.nationality,email:payload.order.buyer.email,name:payload.order.buyer.name,postalCode:payload.order.buyer.postCode,stateOrProvince:payload.order.buyer.state}\",\n  \"input_content_type\": \"application/xml\",\n  \"output_content_type\": \"application/json\"\n}'\n</code></pre>","location":"transformation/other/dataweavetransformation/#sending-the-parameters-in-the-request"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<pre><code>kubectl logs event-display-00001-deployment-fb48c8d7c-2h444 user-container\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:39:47.80922913Z\nData,\n  {\n    \"input_data\": \"&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\",\n    \"spell\": \"{address1:payload.order.buyer.address,city:payload.order.buyer.city,country:payload.order.buyer.nationality,email:payload.order.buyer.email,name:payload.order.buyer.name,postalCode:payload.order.buyer.postCode,stateOrProvince:payload.order.buyer.state}\",\n    \"input_content_type\": \"application/xml\",\n    \"output_content_type\": \"application/json\"\n  }\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: curl.shell\n  id: 1234-abcd\n  time: 2022-05-09T10:39:47.852857516Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:39:47.86469464Z\nData,\n  {\n    \"address1\": \"Cocodrile Boulevard 61\",\n    \"city\": \"Seattle\",\n    \"country\": \"USA\",\n    \"email\": \"james@hotmail.com\",\n    \"name\": \"James\",\n    \"postalCode\": \"98101\",\n    \"stateOrProvince\": \"CA\"\n  }\n</code></pre> <p>We now see the incoming event and the transformed data, as expected with the parameters set in the request.</p>","location":"transformation/other/dataweavetransformation/#viewing-the-transformations-output-in-the-event-display_1"},{"title":"JQ Transformation","text":"","location":"transformation/other/jqtransformation/"},{"title":"Kubernetes","text":"<pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: JQTransformation\nmetadata:\n  name: testjqtransform\nspec:\n  query: '.[] | {first: .firstName,last: .lastName}'\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n</code></pre>","location":"transformation/other/jqtransformation/#kubernetes"},{"title":"Transforming XML to JSON","text":"<p>The TriggerMesh <code>XMLToJSONTransformation</code> API object can be used to process a Cloudevent containing XML and return a JSON representation.</p>","location":"transformation/other/xmltojsontransformation/"},{"title":"Configuring an XML to JSON event flow XML","text":"<p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML to their JSON representation. It has four steps:</p> <ul> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>XMlToJSONTransformation</code> object.</li> <li>Deploy a Source that emits XML data.</li> <li>Check the results in the logs of the <code>EventDisplay</code> Pod.</li> </ul> <p>An <code>XMLToJSONTransformation</code> object can be configured to either reply to the event sender or to send the transformed data to a <code>Sink</code> if one is provided. In this guide, we will use a <code>Sink</code> to send the transformed data to a so-called <code>EventDisplay</code> service.</p>","location":"transformation/other/xmltojsontransformation/#configuring-an-xml-to-json-event-flow-xml"},{"title":"Deploying an Event Display","text":"<p>Let's first deploy the end of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing-contrib/cmd/event_display@sha256:46d5a66f300c3ced590835d379a0e9badf413ae7ab60f21a2550ecedbc9eb9d3\n</code></pre>","location":"transformation/other/xmltojsontransformation/#deploying-an-event-display"},{"title":"Deploying an XMLToJSONTransformation Object","text":"<p>With the <code>event-display</code> in place, the <code>XMLToJSONTransformation</code> object can now be deployed in the same manner using the following manifest:</p>  <p>Tip</p> <p>Below we use a <code>Sink</code> to declare where the response go. If you omit the <code>Sink</code> the response will go back to the Sender.</p>  <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: XMLToJSONTransformation\nmetadata:\n  name: demo\nspec:\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n</code></pre>","location":"transformation/other/xmltojsontransformation/#deploying-an-xmltojsontransformation-object"},{"title":"Deploying a <code>PingSource</code> Object.","text":"<p>Finally, we deploy an event source that will emit CloudEvents with XML data in the payload. We can do this with the <code>PingSource</code> which sends Cloudevents on a schedule.</p> <p>The YAML manifest below shows that we will send a note in XML every minute. Write the following YAML in a file and apply it with <code>kubectl apply -f &lt;manifest.yaml&gt;</code>.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: pingxml\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: application/xml\n  data: '&lt;note&gt;&lt;to&gt;Tove&lt;/to&gt;&lt;from&gt;Jani&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Dont forget me this weekend&lt;/body&gt;&lt;/note&gt;'\n  sink:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: XMLToJSONTransformation\n      name: demo\n</code></pre>","location":"transformation/other/xmltojsontransformation/#deploying-a-pingsource-object"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <pre><code>kubectl get pods\nNAME                                                             READY   STATUS    RESTARTS   AGE\nxmltojsontransformation-demo-00001-deployment-7f45697d45-4bngq   2/2     Running   0          5m42s\nevent-display-00001-deployment-5c97f6c58c-ndjhl                  2/2     Running   0          5m2s\n</code></pre> <p>With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-5c97f6c58c-ndjhl user-container\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/t/pingsources/pingxml\n  id: be4a7e9f-a475-4555-895e-84bcf075a85c\n  time: 2022-01-21T17:29:00.426355338Z\n  datacontenttype: application/json\nData,\n  {\n    \"note\": {\n      \"body\": \"Dont forget me this weekend\",\n      \"to\": \"Tove\",\n      \"from\": \"Jani\",\n      \"heading\": \"Reminder\"\n    }\n  }\n</code></pre> <p>We see our beautiful sample note now in JSON format.</p>","location":"transformation/other/xmltojsontransformation/#viewing-the-transformations-output-in-the-event-display"},{"title":"Transforming XML Using XSLT","text":"<p>The Trigermesh <code>XSLTTransformation</code> API object can be used to process a Cloudevent containing XML and transform the document using XSLT.</p>","location":"transformation/other/xslttransformation/"},{"title":"Configuring a XSLT Transformation Event Flow","text":"<p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML by parsing it with an XSLT stylesheet. It has five steps:</p> <ul> <li>Deploy a Broker that will receive the transformed data.</li> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>XSLTTransformation</code> object.</li> <li>Configure the Triggers</li> <li>Deploy a curl pod that will allow us to send events to the broker.</li> </ul> <p></p> <p>An <code>XSLTTransformation</code> object can be configured to either reply to the event sender or to send the transformed data to a <code>Sink</code>, if one is provided. In this guide, we will deploy without a <code>Sink</code> and configure the replies from the transformation to route to the <code>EventDisplay</code> service using a <code>Trigger</code>.</p> <p>The transformation needs to be configured with a valid XSLT document. In this guide we will use the following XSLT:</p> <pre><code>&lt;xsl:stylesheet version=\"1.0\"   xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n  &lt;xsl:template match=\"tests\"&gt;\n    &lt;output&gt;\n      &lt;xsl:apply-templates select=\"test\"&gt;\n        &lt;xsl:sort select=\"data/el1\"/&gt;\n        &lt;xsl:sort select=\"data/el2\"/&gt;\n      &lt;/xsl:apply-templates&gt;\n    &lt;/output&gt;\n  &lt;/xsl:template&gt;\n\n  &lt;xsl:template match=\"test\"&gt;\n    &lt;item&gt;\n      &lt;xsl:value-of select=\"data/el1\"/&gt;\n      &lt;xsl:value-of select=\"data/el2\"/&gt;\n    &lt;/item&gt;\n  &lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n</code></pre> <p>It transforms the following XML: <pre><code>&lt;tests&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;A&lt;/el1&gt;\n      &lt;el2&gt;1&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;B&lt;/el1&gt;\n      &lt;el2&gt;2&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;C&lt;/el1&gt;\n      &lt;el2&gt;3&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n&lt;/tests&gt;\n</code></pre></p> <p>Into this new XML document: <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;output&gt;\n  &lt;item&gt;A1&lt;/item&gt;\n  &lt;item&gt;B2&lt;/item&gt;\n  &lt;item&gt;C3&lt;/item&gt;\n&lt;/output&gt;\n</code></pre></p> <p>Let's go step by step.</p>","location":"transformation/other/xslttransformation/#configuring-a-xslt-transformation-event-flow"},{"title":"Deploy the Broker","text":"<p>Deploy a Broker by writing the following YAML in a file: <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\n</code></pre></p> <p>Create the Broker with the following command: <pre><code>kubectl apply -f &lt;manifest.yaml&gt;\n</code></pre></p>","location":"transformation/other/xslttransformation/#deploy-the-broker"},{"title":"Deploying the <code>EventDisplay</code> Service","text":"<p>Let's now deploy the end of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing-contrib/cmd/event_display@sha256:46d5a66f300c3ced590835d379a0e9badf413ae7ab60f21a2550ecedbc9eb9d3\n</code></pre>","location":"transformation/other/xslttransformation/#deploying-the-eventdisplay-service"},{"title":"Deploy the <code>XSLTTransformation</code> Object","text":"<p>With the <code>event-display</code> in place, the <code>XSLTTransformation</code> object can now be deployed in the same manner using the following manifest:</p>  <p>Note</p> <p>The XSLT is written in-line within the YAML manifest</p>  <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: XSLTTransformation\nmetadata:\n  name: demo\nspec:\n  allowPerEventXSLT: true\n  xslt:\n    value: |\n      &lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n        &lt;xsl:template match=\"tests\"&gt;\n          &lt;output&gt;\n            &lt;xsl:apply-templates select=\"test\"&gt;\n              &lt;xsl:sort select=\"data/el1\"/&gt;\n              &lt;xsl:sort select=\"data/el2\"/&gt;\n            &lt;/xsl:apply-templates&gt;\n          &lt;/output&gt;\n        &lt;/xsl:template&gt;\n\n        &lt;xsl:template match=\"test\"&gt;\n          &lt;item&gt;\n            &lt;xsl:value-of select=\"data/el1\"/&gt;\n            &lt;xsl:value-of select=\"data/el2\"/&gt;\n          &lt;/item&gt;\n        &lt;/xsl:template&gt;\n      &lt;/xsl:stylesheet&gt;\n</code></pre>","location":"transformation/other/xslttransformation/#deploy-the-xslttransformation-object"},{"title":"Configure the Triggers","text":"<p>Next, Triggers need to be configured to route our Cloudevents to the <code>XSLTTransformation</code> and <code>EventDisplay</code> objects. This can be done by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>. We have two triggers, one to send events containing XML to the transformation and one to send all events to the event display.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: event-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n---\nkind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: xslttransformation-xmldoc\nspec:\n  broker: demo\n  filter:\n    attributes:\n      # setting a filter to process only events of type `xml.document`\n      type: xml.document\n  subscriber:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: XSLTTransformation\n      name: demo\n</code></pre>","location":"transformation/other/xslttransformation/#configure-the-triggers"},{"title":"Deploy a Curl Pod","text":"<p>Finally, an event source can be depoyed that will emit CloudEvents with XML data in the payload. We can do this in two steps:</p> <pre><code>1. Deploy a curl pod that will emit the CloudEvents by writing the following YAML in a file and apply it with `kubectl apply -f &lt;manifest.yaml&gt;`.\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: curl\n  name: curl\nspec:\n  containers:\n  - image: radial/busyboxplus:curl\n    imagePullPolicy: IfNotPresent\n    name: curl\n    stdin: true\n    tty: true\n</code></pre> <pre><code>2. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/xml\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '&lt;tests&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;A&lt;/el1&gt;&lt;el2&gt;1&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;B&lt;/el1&gt;&lt;el2&gt;2&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;C&lt;/el1&gt;&lt;el2&gt;3&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;/tests&gt;'\n</code></pre>","location":"transformation/other/xslttransformation/#deploy-a-curl-pod"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <p><pre><code>kubectl get pods                                                          \nNAME                                                   READY   STATUS    RESTARTS   AGE\ncurl                                                   1/1     Running   0          4m36s\nevent-display-00001-deployment-74bf8556b7-t7lxw        2/2     Running   0          3s\nxslttransformation-demo-00001-deployment-7d9fc458b5-6xfbw   2/2     Running   0          3s\n</code></pre> With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-74bf8556b7-t7lxw user-container\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/xml\nExtensions,\n  knativearrivaltime: 2022-01-27T17:36:12.563701467Z\nData,\n  &lt;tests&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;A&lt;/el1&gt;&lt;el2&gt;1&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;B&lt;/el1&gt;&lt;el2&gt;2&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;C&lt;/el1&gt;&lt;el2&gt;3&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;/tests&gt;\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: xslttransform-adapter\n  id: c15e1cf7-ac98-4c3b-8ee6-1d0f5185c7cb\n  time: 2022-01-27T17:36:14.90562873Z\n  datacontenttype: application/xml\nExtensions,\n  category: success\n  knativearrivaltime: 2022-01-27T17:36:14.929243269Z\nData,\n  &lt;?xml version=\"1.0\"?&gt;\n&lt;output&gt;\n  &lt;item&gt;A1&lt;/item&gt;\n  &lt;item&gt;B2&lt;/item&gt;\n  &lt;item&gt;C3&lt;/item&gt;\n&lt;/output&gt;\n</code></pre> <p>We now see the incoming event and the transformed data, as expected.</p>","location":"transformation/other/xslttransformation/#viewing-the-transformations-output-in-the-event-display"}]}